<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">















  <link rel="alternate" href="https://feedity.com/github-io/UlJXUVFQUg.rss" title="Mun*">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.2">



<link rel="canonical" href="https://kiddie92.github.io/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.2">



  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-91728997-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-91728997-1');
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "n8MGlOWz83zS9G0m0PGinErj-gzGzoHsz",
      appKey: "bSOcrmi2W53fTzNXQA3UQ2z3"
    });
  </script>





<script>
  window.config = {"leancloud":{"app_id":"n8MGlOWz83zS9G0m0PGinErj-gzGzoHsz","app_key":"bSOcrmi2W53fTzNXQA3UQ2z3"},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> Mun* </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Mun*</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/Open-source">
        <li class="mobile-menu-item">
          
          
            开源项目
          
        </li>
      </a>
    
      <a href="/links">
        <li class="mobile-menu-item">
          
          
            链接
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Mun*</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/Open-source">
            
            
              开源项目
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/links">
            
            
              链接
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <section id="posts" class="posts">
    
      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/07/03/seq2seq的attention机制/">Seq2Seq-从RNN到LSTM再到Attention</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-07-03
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/07/03/seq2seq的attention机制/" data-title="Seq2Seq-从RNN到LSTM再到Attention">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>Attention自2017年由Google提出至今，在seq2seq（编码解码）的任务表现出色，在NLP领域的应用也都有多项突破。我觉得attention对于深度学习将会产生深远的影响。这篇文章主要会介绍一下基于Attention的seq2seq模型和RNN base的seq2seq模型在算法上的一些区别，此外还顺便简要介绍一下LSTM和GRU算法。<br>
          <div class="read-more">
            <a href="/2019/07/03/seq2seq的attention机制/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </p></blockquote></div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/26/从零开始写NN（下）/">从零开始写NN（下）</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-26
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/06/26/从零开始写NN（下）/" data-title="从零开始写NN（下）">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p><a href="https://kiddie92.github.io/2019/06/24/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%86%99NN%EF%BC%88%E4%B8%8A%EF%BC%89/">上篇博文</a>主要介绍了写一个简单的深度神经网络可能需要注意的细节点，这篇延续上篇内容，将在<strong>算法细节</strong>和<strong>调参</strong>上也写一点经验和想法。<br>
          <div class="read-more">
            <a href="/2019/06/26/从零开始写NN（下）/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </p></blockquote></div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/24/从零开始写NN（上）/">从零开始写NN（上）</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-24
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/06/24/从零开始写NN（上）/" data-title="从零开始写NN（上）">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>从零开始写NN (neural network) 系列第一篇，本篇博文将会从代码结构上介绍一下怎么写一个简单的<code>神经网络算法</code>，下篇打算使用一个示例介绍一下如何调整参数细节。当然，这里的所谓从0开始，其实还是使用了<code>numpy</code>，有点像使用<code>matlab</code>的感觉。<br>
          <div class="read-more">
            <a href="/2019/06/24/从零开始写NN（上）/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </p></blockquote></div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/22/反向传播/">反向传播算法（BP）</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-22
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/06/22/反向传播/" data-title="反向传播算法（BP）">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>人工智能领域的算法真是日新月异啊，最近CMU和Google Brain又提出了XLNet。<br>这篇博文还是从基础算法入手，介绍一下Back Propagation（简称BP），主要分为两个部分：反向传播的基本原理和RNN的反向传播算法，最后给出代码实现。<br>
          <div class="read-more">
            <a href="/2019/06/22/反向传播/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </p></blockquote></div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/15/分层softmax/">分层softmax</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-15
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/06/15/分层softmax/" data-title="分层softmax">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>入坑自然语言处理，论文<a href="https://arxiv.org/pdf/1411.2738.pdf" target="_blank" rel="noopener">word2vec Parameter Learning Explained</a>基本是必读的，这篇论文中的<strong>Hierarchical Softmax</strong>，中文叫做分层softmax/层次softmax是比较让人头大的内容，这篇博文试图阐述Hierarchical Softmax算法在word2vec中的应用。<br>
          <div class="read-more">
            <a href="/2019/06/15/分层softmax/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </p></blockquote></div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/10/Matrix-Factorization简介/">基于矩阵分解的推荐算法</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-10
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/06/10/Matrix-Factorization简介/" data-title="基于矩阵分解的推荐算法">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>Matrix Factorization算法是推荐系统（Recommendation System）的基础，本篇文章仅介绍一下基于<strong>矩阵分解</strong>的推荐系统是如何工作的以及Matrix Factorization算法，最后给出一个算法示例。内容比较浅显，深入算法原理还需要阅读更多的论文和资料。<br>
          <div class="read-more">
            <a href="/2019/06/10/Matrix-Factorization简介/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </p></blockquote></div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/09/Logistic-Regression/">Logistic Regression</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-09
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/06/09/Logistic-Regression/" data-title="Logistic Regression">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>对数几率回归/逻辑回归/逻辑斯蒂回归/最大熵模型也即Logistic Regression是深度学习的基础，算法的重要性不言而喻。Logistic Regression虽然叫“Rgression”，但其实与之前介绍的<a href="https://kiddie92.github.io/2019/05/10/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89/">SVM分类（svc）方法</a>一样，同属<strong>分类算法</strong>。本篇博文对该算法的介绍流程基本参考了李宏毅老师的机器学习课程，文章后半部分主要以问答的形式给出了关于逻辑斯蒂回归的部分理解。<br>
          <div class="read-more">
            <a href="/2019/06/09/Logistic-Regression/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </p></blockquote></div>

    

    

  </article>

      
      
  <nav class="pagination">
    
    
      <a class="next" href="/page/2/">
        <span class="next-text">下一页</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


    
  </section>

          </div>
          

        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:kiddiezzh@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
        
          <a href="https://twitter.com/kiddiezzh" class="iconfont icon-twitter" title="twitter"></a>
        
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/kiddie92" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      <a href="https://feedity.com/github-io/UlJXUVFQUg.rss" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2018 - 
    
    2019

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">kiddie92</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    


    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.2"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  </body>
</html>

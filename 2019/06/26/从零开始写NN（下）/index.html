<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="从零开始写NN（下）">




  <meta name="keywords" content="算法, 深度学习, 神经网络, Mun*">










  <link rel="alternate" href="https://feedity.com/github-io/UlJXUVFQUg.rss" title="Mun*">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.2">



<link rel="canonical" href="https://kiddie92.github.io/2019/06/26/从零开始写NN（下）/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.2">



  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-91728997-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-91728997-1');
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "n8MGlOWz83zS9G0m0PGinErj-gzGzoHsz",
      appKey: "bSOcrmi2W53fTzNXQA3UQ2z3"
    });
  </script>





<script>
  window.config = {"leancloud":{"app_id":"n8MGlOWz83zS9G0m0PGinErj-gzGzoHsz","app_key":"bSOcrmi2W53fTzNXQA3UQ2z3"},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> 从零开始写NN（下） - Mun* </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Mun*</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/Open-source">
        <li class="mobile-menu-item">
          
          
            开源项目
          
        </li>
      </a>
    
      <a href="/links">
        <li class="mobile-menu-item">
          
          
            链接
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Mun*</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/Open-source">
            
            
              开源项目
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/links">
            
            
              链接
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          从零开始写NN（下）
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-26
        </span>
        
          <span class="post-category">
            
              <a href="/categories/人工智能/">人工智能</a>
            
          </span>
        
        
        <span class="post-visits" data-url="/2019/06/26/从零开始写NN（下）/" data-title="从零开始写NN（下）">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#算法细节"><span class="toc-text">算法细节</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#调参"><span class="toc-text">调参</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <blockquote>
<p><a href="https://kiddie92.github.io/2019/06/24/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%86%99NN%EF%BC%88%E4%B8%8A%EF%BC%89/">上篇博文</a>主要介绍了写一个简单的深度神经网络可能需要注意的细节点，这篇延续上篇内容，将在<strong>算法细节</strong>和<strong>调参</strong>上也写一点经验和想法。<br><a id="more"></a></p>
</blockquote>
<h2 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h2><p>显然，自己去写一个神经网络算法与流行的算法框架（<code>tensorflow/pytorch/mxnet</code>等）还是有巨大的差距的，因为一些算法细节的地方并没有实现，下面简单清点一下值得关注的几个地方（可能有遗漏，发现后会更新博客）。</p>
<p><strong>Epoch &amp; Batch Size</strong><br>train函数的代码中，我给<code>epoch</code>和<code>batch_size</code>之间做了一个<strong>shuffle</strong>，主要是为了每次学习的时候会有不同的数据分布进入学习，防止每次数据出现相同的分布，被神经网络抽象成了一个feature，这样一来，模型的泛化能力可能会受到影响。我在这里使用的随机数生成方法是：先随机得到一个<code>seed</code>再产生随机数来打乱<code>x</code>以及<code>y</code>的序列，但倘若每次产生的种子相同，那随机序列也就被重复了，所以最好是每次产生的种子不要重复。</p>
<p><strong>Activation function</strong><br>代码里只提供了三种激活函数：<code>sigmoid</code> <code>tanh</code> <code>relu</code>，可以扩展更多。</p>
<p><strong><code>y-a_s</code>别写反了</strong><br>这个其实没什么值的说的，不过因为我之前写反了，导致loss一直不能下降，学了半天学出了下图的样子，查了半天才发现是自己写成了<code>a_s-y</code>；所以说计算梯度的时候千万别搞错了正负号。<br><img src="./failed-fit.png" alt="Alt text"></p>
<p>上面几点其实都是很容易就可以改好的，而算法框架还有很多厉害之处：</p>
<p><strong>loss函数</strong><br>loss函数针对不同的问题，会有不同的定义，比如分类问题常用的是<code>cross entropy</code>（关于cross entropy的介绍可以查看<a href="https://kiddie92.github.io/2019/06/09/Logistic-Regression/#%E4%BA%A4%E5%8F%89%E7%86%B5%EF%BC%88Cross-Entropy-and-KL-divergence">我之前的博客</a>）；回归问题<strong>可能</strong>会使用<code>1范数甚至0范数</code>+<code>正则项</code>；另外明确所使用的loss函数也会让代码变的一目了然，而上篇所述的<a href="https://github.com/kiddie92/Learning_Tech/blob/master/BP/NeuralNetwork.py" target="_blank" rel="noopener">代码</a>则没有将loss函数解耦出来。</p>
<p><strong>优化器optimizer</strong><br>优化算法有很多中，之前的博客介绍过<a href="https://kiddie92.github.io/2019/03/17/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95/">牛顿迭代法</a>，上篇所述代码中使用的则是简单的<code>梯度下降法</code>，其中学习率/步长都是固定的；此外，还有很多启发式的优化算法，这里就不得不提大名鼎鼎的<code>adam</code>算法了，这个算法本身的实现都得好好研究一番了，集成到神经网络的算法框架中是非常值得尝试的。</p>
<p><strong>Dropout</strong><br>一般认为构建神经网络最好是deep一下，表达能力才会提高（现在也有人提出wide&amp;deep了）。如果两层神经元之间采用全连接往往会造成过拟合，这里可以设置每一层神经元都有一定比例随机的丢弃部分神经元，这便是Dropout的做法，其实就是一个正则化的方法，增加了模型的泛化能力。这一点也是值得尝试增加的功能。</p>
<blockquote>
<p>理论上有了BN层就<strong>可以不需要</strong>Dropout了，在博客<a href="https://kiddie92.github.io/2019/03/09/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AWhy%EF%BC%9F/">卷积神经网络之Batch-Normalization（二）：Why？</a>中我也给过一点分析。</p>
</blockquote>
<p><strong>Batch Normalization</strong><br>之前写过<a href="https://kiddie92.github.io/2019/03/06/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AHow%EF%BC%9F/">两篇关于Batch Normalization的博客</a>，这里不再赘述了；这个算法点相对来说是比较容易实现并且很容易和源代码解耦的。</p>
<p><strong>CNN、ResNet、attention等</strong><br>上面列举的几个相对特殊的网络，实现起来都不得不修改源码了；然而一个优秀的深度学习算法框架最好能够实现几乎所有流行的神经网络架构，而未来可能会出现很多新的算法，从架构师的角度来看，算法框架必须要有非常好的<strong>扩展性能</strong>。依我个人的愚见，算法框架应该有一个“完备性”，所有的已经实现的算法都可以用最基础的几个定义来实现，这里就不得不吹一波基于<a href="https://kiddie92.github.io/2019/03/02/TensorFlow-%E7%89%B9%E6%80%A7-Graph-%E5%92%8C-Sessions/#%E8%AE%A1%E7%AE%97%E5%9B%BE%EF%BC%88Graph%EF%BC%89">计算图</a>的算法框架了。</p>
<h2 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h2><p>首先来看一下怎么调用上篇所述的类：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> NeuralNetwork <span class="keyword">import</span> NeuralNetwork</span><br><span class="line"></span><br><span class="line"><span class="comment"># 造一个sin函数&lt;x,y&gt;作为labeled数据</span></span><br><span class="line">X = <span class="number">2</span>*np.pi*np.random.rand(<span class="number">1000</span>) </span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line">nn = NeuralNetwork([<span class="number">1</span>,<span class="number">100</span>,<span class="number">80</span>,<span class="number">1</span>],activations=[<span class="string">'tanh'</span>,<span class="string">'tanh'</span>,<span class="string">'tanh'</span>])</span><br><span class="line">nn.train(X, y, epochs=<span class="number">1000</span>, batch_size=<span class="number">10</span>, lr = <span class="number">0.01</span>) <span class="comment"># 得到最终的模型参数w,b</span></span><br><span class="line"></span><br><span class="line">xx=X.reshape(<span class="number">1</span>, <span class="number">-1</span>)  </span><br><span class="line">yy=y.reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">_, a_s = nn.feedforward(xx) <span class="comment"># 使用全新的模型进行拟合</span></span><br><span class="line"></span><br><span class="line">plt.scatter(xx.flatten(), yy.flatten(),color=<span class="string">'blue'</span>)</span><br><span class="line">plt.scatter(xx.flatten(), a_s[<span class="number">-1</span>].flatten(),color=<span class="string">'red'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p>从上面的代码来看，可以调整的参数其实不多，下面从数据开始逐个做一点简单的分析：<br><strong>数据归一化 (normalization)</strong><br>这里<code>y</code>恰好是sin函数的值，大小都在[-1, 1]内，算是已经进行了归一化了。</p>
<p><strong>网络架构</strong><br>网络架构<strong>一般不会</strong>作为优先调整的参数，如果认为网络加深可以提升网络质量，可以在现有架构下达到最优参数后再尝试增加网络层数，因为如果最后一层不需要，那么也是可以学出来该层对应的权重都是1这样；同样，神经元个数也是这个道理。</p>
<p><strong>激活函数的选取</strong><br>这里需要注意的是最后一层输出需要在[-1, 1]内，所以这里只能用<code>tanh</code>了。</p>
<p><strong>batch_size</strong><br>一般建议batch_size先定，再定<code>epochs</code>，这<code>里batch_size</code>给的是10，如果效果不好可以再增加或者减少。</p>
<p><strong>epochs</strong><br>如果数据足够多，甚至有冗余，<code>epochs</code>就没有必要设置太大，一般建议从小数往上加，更具最终的学习效果来看是否需要增加。</p>
<p><strong>Learning rate</strong><br>学习率的调整一般会和<code>batch_size</code>有一定的关联，当<code>batch_size</code>比较大的时候，学习率可以适当给大一点，不过太大不太容易陷入局部极小值也不太容易找到全局极小值；学习率比较小的话则比较容易陷入局部极小值；总之，太大太小都有可能造成计算资源的浪费。所以还是<code>adam</code>大法好 : )</p>
<p>拟合效果：</p>
<p><img src="./tanhX3.png" alt="Alt text"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上篇实现了一个简单的神经网络算法，但是很多有利于提高网络能力的方法并没有被集成进来，此外，算法的可扩展性并不是很强；这篇博文主要是对上篇所述的代码进行一个补充说明，增加一些改进点的分析，分享一点使用上的心得；最后，顺便赞扬一番TensorFlow/PyTorch/MXNet这些非常优秀的深度学习算法框架。</p>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://kiddie92.github.io">kiddie92</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://kiddie92.github.io/2019/06/26/从零开始写NN（下）/">https://kiddie92.github.io/2019/06/26/从零开始写NN（下）/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用4.0国际许可协议</a>
    </p>
  </div>



      
      
  <div class="post-reward">
    <input type="checkbox" name="reward" id="reward" hidden>
    <label class="reward-button" for="reward">赞赏支持</label>
    <div class="qr-code">
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="/images/reward/wechat.png" title="微信打赏">
        </label>
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="/images/reward/alipay.png" title="支付宝打赏">
        </label>
      
    </div>
  </div>

    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/算法/">算法</a>
            
              <a href="/tags/深度学习/">深度学习</a>
            
              <a href="/tags/神经网络/">神经网络</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2019/07/03/seq2seq的attention机制/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">seq2seq-从RNN到LSTM再到attention</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2019/06/24/从零开始写NN（上）/">
        <span class="next-text nav-default">从零开始写NN（上）</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:kiddiezzh@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
        
          <a href="https://twitter.com/kiddiezzh" class="iconfont icon-twitter" title="twitter"></a>
        
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/kiddie92" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      <a href="https://feedity.com/github-io/UlJXUVFQUg.rss" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2018 - 
    
    2019

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">kiddie92</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  <script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'https://kiddie92.github.io/2019/06/26/从零开始写NN（下）/';
        this.page.identifier = '2019/06/26/从零开始写NN（下）/';
        this.page.title = '从零开始写NN（下）';
    };
    (function() {
    var d = document, s = d.createElement('script');

    s.src = '//https-kiddie92-github-io.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();  
  </script>

  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.2"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  </body>
</html>

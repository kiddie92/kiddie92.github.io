<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mun*</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://kiddie92.github.io/"/>
  <updated>2019-03-17T14:11:53.394Z</updated>
  <id>https://kiddie92.github.io/</id>
  
  <author>
    <name>Mun*</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据采集之Python爬虫实验</title>
    <link href="https://kiddie92.github.io/2019/03/11/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPython%E7%88%AC%E8%99%AB%E5%AE%9E%E9%AA%8C/"/>
    <id>https://kiddie92.github.io/2019/03/11/数据分析之Python爬虫实验/</id>
    <published>2019-03-11T14:20:32.000Z</published>
    <updated>2019-03-17T14:11:53.394Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>如果说算法是程序的灵魂，那么数据就是算法的灵魂。数据采集是数据工程的第一步，为了提高效率，目前在互联网上采集数据比较高效的方法就是爬虫了。今天就来爬一下《惊奇队长》豆瓣上的影评/review。<br><a id="more"></a></p></blockquote><h1 id="爬虫简介"><a href="#爬虫简介" class="headerlink" title="爬虫简介"></a>爬虫简介</h1><p>数据可以挖掘潜在的价值，但是在挖掘之前需要有数据，否则再牛的算法也不会work。在一些具体的问题上，比如，我们可以收集各大网站上观众对于该电影的评价来判断电影的火热程度，结合其他的数据还可以估计票房等信息；又或者根据社交网络上人们对于股票市场行情的态度以及相关新闻，通过NLP处理来预测股价。那么，首先需要解决的问题就是如何获取数据。网络爬虫就是获取数据的一个重要手段，爬虫就好像一个全自动的机器人一直在浏览网页并将重要的信息收集起来，并按照一定的规则存储在相应的数据库或者文件内。数据收集好了，算法设计人员才可以做进一步的工作。</p><blockquote><p>如果有网站数据的API接口，就不用写爬虫了；<br>爬虫获取的数据都是公开的数据，很多有价值的数据还是需要花重金购买。</p></blockquote><h1 id="开始实践"><a href="#开始实践" class="headerlink" title="开始实践"></a>开始实践</h1><p>本次内容就是编写一个最简单的爬虫，实现豆瓣上电影的影评（或者叫做review），思路就是使用<code>urllib库</code>去模拟浏览器访问相关网页，再利用<code>re库</code>和<code>正则表达式</code>提取关键信息。</p><h2 id="URL分析"><a href="#URL分析" class="headerlink" title="URL分析"></a>URL分析</h2><p>首先，看一下豆瓣影评页的<code>URL</code>是否存在<strong>规律</strong>：浏览器打开豆瓣电影，逐个点击《惊奇队长》—&gt; 惊奇队长的影评 · · · · · · ( 全部 1160 条 )，查看网址为：<code>https://movie.douban.com/subject/26213252/reviews</code>，网址中出现的数字应该是电影的编号，但是没有页码的信息，点击”后页”按钮，网址变成了<code>https://movie.douban.com/subject/26213252/reviews?start=20</code>，所以猜测<code>start=20</code>这个参数是控制页码的，多试几次，发现确实是这个规律。<br>那么，在代码中设置翻页的操作就可以通过<code>for循环</code>来写了:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urlorg = <span class="string">"https://movie.douban.com/subject/26213252/reviews?start="</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(0, 100, 20):</span><br><span class="line">    url = urlorg + str(i)  <span class="comment"># 这里的url即为下一页的url了</span></span><br></pre></td></tr></table></figure><h2 id="网页源码分析"><a href="#网页源码分析" class="headerlink" title="网页源码分析"></a>网页源码分析</h2><p>查看《惊奇队长》影评页的网页源码，发现每一个影评都对应了一个<code>id</code>，而且每个<code>id</code>都对应了一个新的<code>URL</code>，想要查看完整的影评内容需要跳转到这个新的网页上进行查看；这些新的<code>URL</code>的构造也很有<strong>规律</strong>：<code>https://movie.douban.com/review/10034121/</code>最后的数字<code>10034121</code>就是这个review的<code>id</code>。通过网页源码的搜索（如下所示），可以发现<code>data-rid=&quot;9371928&quot; title=&quot;有用&quot;&gt;</code>可以唯一对应这个<code>id</code>，我们可以据此来设置正则表达式。</p><p>html 源码：</p><figure class="highlight htmlbars"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;a href="javascript:;" class="action-btn up" data-rid="9371928" title="有用"&gt;</span><br></pre></td></tr></table></figure><p>使用python 的<code>re包</code>接收正则表达式，(.*?)表示匹配项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pat = <span class="string">'data-rid="(.*?)" title="有用"'</span>   <span class="comment">#(.*?)部分即为id</span></span><br></pre></td></tr></table></figure><p>得到了每一个review的id之后，把它存在一个list内，我们就可以构造出每一个review的URL：<code>https://movie.douban.com/review/</code>+<code>str(id)</code>，打开其中一个review继续分析（我们的目标是把影评的内容拿到）；再次查看影评的网页源码，可以发现影评的题目可以通过<code>&lt;meta name=&quot;description&quot; content=&quot;影评题目&quot; /&gt;</code>唯一确定，而影评的内容则在<code>data-original=&quot;1&quot;&gt;</code>和<code>&lt;div class=&quot;copyright&quot;&gt;</code>之间，如下所示：<br><figure class="highlight htmlbars"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;meta name="description" content="影评题目" /&gt;</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">data-original="1"&gt;</span><br><span class="line">  &lt;p&gt;内容....</span><br><span class="line">     ....内容&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">  &lt;div class="copyright"&gt;</span><br></pre></td></tr></table></figure></p><p>如此以来，我们便可以设置正则将这两个主要内容提取出来。python的<code>re包</code>接收正则表达式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pat2 = <span class="string">'&lt;meta name="description" content="(.*?)" /&gt;'</span>      <span class="comment">#影评的题目</span></span><br><span class="line">pat3 = <span class="string">'data-original="1"&gt;(.*?)&lt;div class="copyright"&gt;'</span>   <span class="comment">#影评的内容</span></span><br></pre></td></tr></table></figure><h2 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h2><p>根据上面的信息，爬虫的主要代码部分已经呼之欲出了，完整代码请点击<a href="https://github.com/kiddie92/Learning_Tech/blob/master/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPython%E7%88%AC%E8%99%AB%E5%AE%9E%E9%AA%8C/spder_douban_movie.py" target="_blank" rel="noopener">这里</a>查看，爬取之前可以做一下浏览器模拟请求，最后爬下来的影评内容存放在一个文件中，以供后续使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">urlorg = <span class="string">"https://movie.douban.com/subject/26213252/reviews?start="</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#每页显示20个评论，所以间隔20算作一页</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">100</span>, <span class="number">20</span>):   <span class="comment">#如果需要爬取所有影评可以将100设置为更大的数字</span></span><br><span class="line">    url = urlorg + str(i)  </span><br><span class="line">    every_page = ur.urlopen(url).read().decode(<span class="string">"utf-8"</span>)</span><br><span class="line">    pat = <span class="string">'data-rid="(.*?)" title="有用"'</span></span><br><span class="line">    review_id = re.compile(pat).findall(every_page)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">20</span>):</span><br><span class="line">        review_url = <span class="string">"https://movie.douban.com/review/"</span> + str(review_id[j])</span><br><span class="line">        review = ur.urlopen(review_url).read().decode(<span class="string">"utf-8"</span>)</span><br><span class="line">        pat2 = <span class="string">'&lt;meta name="description" content="(.*?)" /&gt;'</span></span><br><span class="line">        pat3 = <span class="string">'data-original="1"&gt;(.*?)&lt;div class="copyright"&gt;'</span></span><br><span class="line">        review_title = re.compile(pat2).findall(review)</span><br><span class="line">        review_content = re.compile(pat3, re.S).findall(review)</span><br><span class="line">        print(review_title)</span><br><span class="line">        print(<span class="string">"-----------------------------"</span>)</span><br><span class="line">        print(review_content)</span><br></pre></td></tr></table></figure><h1 id="高级爬虫"><a href="#高级爬虫" class="headerlink" title="高级爬虫"></a>高级爬虫</h1><p>这里所谓的高级爬虫就是网络爬虫在遇到各种各样的问题时，依旧可以正常工作。下图表示一个爬虫的工作流程，首先进行网页的源码分析，看看是否存在规律，接着编写爬虫代码，最后将爬取的数据（适合存在在数据库的数据）保存在数据库内。下面简单的分析几个问题，以下问题都是有解的。</p><p><img src="archtech.png" alt="spyder"></p><ul><li><strong>网页抓包分析</strong><br>静态网页直接查看网页源码就可以爬取内容了，而动态网页则是利用一些前端技术（比如<code>js</code>、<code>css</code>等）进行动态展示。此时需要对浏览器进行抓包分析，将真正的网址抓取出来，得到关键信息。抓包的工具有<code>Fiddler</code>等。</li><li><strong>网站数据的加密、验证码</strong><br>很多网站采取了防爬虫的措施，比如对网页源码进行加密（典型的例子：网易云音乐的评论）、访问过频繁需要填写验证码等。对于网页加密，需要仔细的对网站进行抓包分析，将加密方式破解就可以了（一般还是<code>js</code>文件在搞事情）；对于填写验证码，可以让爬虫在爬取时加一个sleep时间（或者使用图片识别技术）。</li><li><strong>异常处理</strong><br>爬虫的工作依赖网络，所以网络万一出现问题，爬虫得有相应的处理机制，例如尝试连接某个网页未果后要及时爬取下一个，而不是异常退出了；再比如爬虫异常推出重启后得在重启之前得位置接着爬取数据，而不是重头再来。</li><li><strong>多线程</strong><br>对于爬虫这种io密集型的操作，多线程确实会提高效率，但是python的<code>GIL设计</code>使其多线程其实是假的多线程，所以如果比较在乎效率，这里比较推崇的做法是go语言写的爬虫。</li><li><strong>使用框架</strong><br>使用框架的好处是可以省去很多麻烦的设置，少考虑一些简单的问题，相互传阅代码也比较通俗易懂，python中的<code>scrapy框架</code>使用的比较多。</li><li><strong>数据库表的设计</strong><br>如果数据需要存入数据库，则需要设计一下数据库、表；这样做的好处是后续的数据供大家使用非常方便快捷。</li></ul><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><ol><li>网络上有很多数据值得深入的挖掘，获取数据是数据挖掘的第一步；</li><li>爬虫可以对网络的资源进行自动化获取，爬取数据之前需要对资源的获取进行仔细分析；</li><li>高级/工业级的爬虫需要考虑更多的问题，如：对加密网页内容的破解、抓包分析、爬虫的异常处理、数据存库等。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;如果说算法是程序的灵魂，那么数据就是算法的灵魂。数据采集是数据工程的第一步，为了提高效率，目前在互联网上采集数据比较高效的方法就是爬虫了。今天就来爬一下《惊奇队长》豆瓣上的影评/review。&lt;br&gt;
    
    </summary>
    
      <category term="数据工程" scheme="https://kiddie92.github.io/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="爬虫" scheme="https://kiddie92.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="数据采集" scheme="https://kiddie92.github.io/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络之Batch-Normalization（二）：Why？</title>
    <link href="https://kiddie92.github.io/2019/03/09/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AWhy%EF%BC%9F/"/>
    <id>https://kiddie92.github.io/2019/03/09/卷积神经网络之Batch-Normalization（二）：Why？/</id>
    <published>2019-03-09T13:17:35.000Z</published>
    <updated>2019-03-11T14:12:03.481Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>上一篇主要介绍了Batch-Normalization（下面简称BN）是如何工作的，即在连接层和激活函数之间加了一个BN层，这些参数参与了整个网络的正向和反向传播。这篇博文主要介绍为什么BN算法可以work，内容主要参考了两篇论文，包括18年的一篇NIPS论文。<br><a id="more"></a></p></blockquote><h2 id="问题的提出和解决"><a href="#问题的提出和解决" class="headerlink" title="问题的提出和解决"></a>问题的提出和解决</h2><p>在引入BN之前，以前的model training有一些系统性的问题，导致很多算法收敛速度都非常慢，甚至根本就不能工作，尤其在使用sigmoid激活函数时。其中一个比较著名的问题就是每层神经元是会受到它之前所有神经元影响的，因为每一层的输出都是下一层的输入，所以一个神经元输出的数据分布发生改变一定会使其他神经元跟着改变，这样相互影响的调参很容易使调参过程乱套，这个被称作Internal Covariate shift（ICS）。此外，还有其他问题，比如仿射层的输出值太大或太小，其经过sigmoid激活函数时会落在饱和区域，反向传播会有梯度消失的问题。这里先试图说明一下ICS问题及其解决方法。</p><h3 id="Internal-Covariate-shift-ICS"><a href="#Internal-Covariate-shift-ICS" class="headerlink" title="Internal Covariate shift (ICS)"></a>Internal Covariate shift (ICS)</h3><p>关于ICS，有个形象的比喻：当你有个射击目标时，如果这个目标是静止的，它就会比较容易击中；而当这个<strong>目标是在不停的移动时</strong>，它就很难被击中。深度学习的训练过程中就类似于后者：</p><ol><li>训练数据被输入到神经网络时，一般会先被normalization一下，因为输入的数据的每个维度的<strong>量纲</strong>可能会不一样，通过normalization可以消除量纲不一致的问题；</li><li>数据经过{Wx+b}和activation后，进入hidden layer，<strong>数据集的分布</strong>（均值和标准差）就会发生变化，而且每经过一层，输出数据集的分布都会变化；</li><li>由于每一层都发现自己的input数据集的分布在不停的变化，而反向传播更新参数时，想要适应训练数据集的分布就是一件非常困难的事情。</li></ol><p><img src="ICS.png" alt="Alt text"></p><p><strong>如果上面的理解是正确的</strong>，那么训练过程收敛速度非常慢就很容易理解了，尤其是对于深度较深的网络（隐含层比较多）。</p><h3 id="ICS问题的解决"><a href="#ICS问题的解决" class="headerlink" title="ICS问题的解决"></a>ICS问题的解决</h3><p>虽然ICS的问题很棘手，但也不是无解的。</p><ul><li>其中一个比较常见的解法就是<strong>减小learning rate</strong>，因为学习率一旦降低，学习训练数据集分布的过程就能够通过<strong>持续微小的调整</strong>来慢慢接近目标；但是，这也带来了一个问题，学习率太小容易使学习/训练的速度变慢，此外，还可能使学习过程陷入局部极小值。</li><li>BN算法之所以work的比较好，最主要的原因一直被认为是其解决了ICS的问题。Batch Normalization将每一层的输出都经过了“变换”，每一层的输出数据集（batch）都会重新将数据集的分布归一化到标准的分布形态上（均值为0，标准差为1）。这样一来，“目标分布” 在每一层的传递过程中变化就不会很大了，也即<strong>目标被固定住了</strong>。</li></ul><p><img src="BN.png" alt="Alt text"></p><p>下图对比了使用BN和不使用BN时，训练收敛的变化趋势，可以看到使用BN可以在更少的训练步数内达到同等的准确率，此外使用BN还可以达到更高的准确率，也即训练收敛速度更快，效果更佳。</p><p><img src="BN.VS.NOBN.png" alt="BN.VS.Stand"></p><h2 id="BN算法的有效性分析"><a href="#BN算法的有效性分析" class="headerlink" title="BN算法的有效性分析"></a>BN算法的有效性分析</h2><p>除了ICS的问题，BN算法还一并解决了深度学习训练过程中遇到的各种小问题。下面以问答的形式，说明一下几个小问题的解决。</p><h3 id="Q1-为什么先做BN再做activation？"><a href="#Q1-为什么先做BN再做activation？" class="headerlink" title="Q1: 为什么先做BN再做activation？"></a>Q1: 为什么先做BN再做activation？</h3><p>其实仅仅考虑ICS的问题，先做activation再做BN也不是不可以；但是，先做BN还是有好处的，BN将仿射层的输出标准化后，数值基本分布在0附近，对于sigmoid激活函数来说，值大都落在<strong>非饱和区</strong>了，就不太会造成梯度消失的现象了。</p><h3 id="Q2-mini-batch的大小设置多大比较合适？"><a href="#Q2-mini-batch的大小设置多大比较合适？" class="headerlink" title="Q2: mini-batch的大小设置多大比较合适？"></a>Q2: mini-batch的大小设置多大比较合适？</h3><p>mini batch的大小稍微大一点其实会比较合理，因为算法中需要使用mini-batch内的数据去估计整个样本的<strong>均值</strong>和<strong>方差</strong>，所以大一点会比较接近总体样本的分布；但是，太大又会导致training比较慢，所以，batch的大小和算力需要去权衡一下。</p><h3 id="Q3-scale和shift参数的加入有什么作用？"><a href="#Q3-scale和shift参数的加入有什么作用？" class="headerlink" title="Q3: scale和shift参数的加入有什么作用？"></a>Q3: scale和shift参数的加入有什么作用？</h3><p>scale、shift是两个独立的参数，也即和数据是没有依赖关系的，它们完全有可能将BN的作用给抵消掉，然而这恰好也是这个方法的优势，可以根据具体情况由网络自身在训练过程中来决定需不需要BN。</p><h3 id="Q4-训练好的模型如何使用，因为已经没有batch的概念了？"><a href="#Q4-训练好的模型如何使用，因为已经没有batch的概念了？" class="headerlink" title="Q4: 训练好的模型如何使用，因为已经没有batch的概念了？"></a>Q4: 训练好的模型如何使用，因为已经没有batch的概念了？</h3><p>一种方法是真的去估计整个样本在每一层的输出值的均值和方差，这个计算量太大。另一种比较常用的方法是，对训练集数据中的每一个均值和方差都保留下来，最后做移动平均来估计总体样本的均值和方差。</p><h2 id="新的理解"><a href="#新的理解" class="headerlink" title="新的理解"></a>新的理解</h2><p>这是一篇投稿于NeurIPS 2018的会议论文（参考文献2），文章以<strong>新的观点</strong>阐述了BN算法的有效性。主要涉及了两个实验（公式太多，没有细看）：</p><h3 id="在BN层之后添加Noise"><a href="#在BN层之后添加Noise" class="headerlink" title="在BN层之后添加Noise"></a>在BN层之后添加Noise</h3><p>在BatchNorm层之后加上一个随机噪音，噪音的分布异于BatchNorm层的输出（均值非0，方差非1），并且每次传播的时候，噪音都不一样。也就是说，在BatchNorm层之后故意加了一个ICS，结果发现训练并没有因此而明显变差（如下图粉红色所示），虽然隐含层的输出分布会随着迭代次数的增加（时间的推移）而变得不太稳定。</p><p><img src="why.jpg" alt="Alt text"></p><h3 id="梯度更新前后的Loss和其梯度的变化"><a href="#梯度更新前后的Loss和其梯度的变化" class="headerlink" title="梯度更新前后的Loss和其梯度的变化"></a>梯度更新前后的Loss和其梯度的变化</h3><p>作者使用量化的方式定量的说明了BN算法并不能减少ICS。实际上，作者认为BN算法减少了Lipschitz常数（也即loss函数变得更加连续/光滑），使得梯度变得跟加”可预测”（如下图所式），才是BN算法有效性的关键。</p><blockquote><p>这里”<strong>可预测</strong>“我的理解是表示变量的变化范围比较小，更加可控。</p></blockquote><p><img src="landscapes.jpg" alt="Alt text"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>ICS问题的解决使深度神经网络的收敛速度变快，另外，此时的learning rate也可以设置大一些，则加快了学习的速率；</li><li>BN的引入极大的降低了sigmoid和tanh这样的激活函数梯度消失的风险；</li><li>使用了Batch Normalization，初始化参数对神经网络的影响减小；</li><li>BN算法降低了过拟合的风险，训练过程不需要太多的正则化，也可以不需要drop out了；</li><li>新的观点认为ICS的解决并非BN算法有效的根本原因，loss变得平滑了才是主要原因；</li><li>国外发表的论文还做了一个几分钟的小视频放在youtube上，我觉得国内也可以校仿一下。</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Ioffe, S., &amp; Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.</li><li>Santurkar, S., Tsipras, D., Ilyas, A., &amp; Madry, A. (2018). How does batch normalization help optimization?. In Advances in Neural Information Processing Systems (pp. 2488-2498).</li><li><a href="https://mc.ai/batch-normalization-speed-up-neural-network-training/" target="_blank" rel="noopener">Batch Normalization — Speed up Neural Network Training</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;上一篇主要介绍了Batch-Normalization（下面简称BN）是如何工作的，即在连接层和激活函数之间加了一个BN层，这些参数参与了整个网络的正向和反向传播。这篇博文主要介绍为什么BN算法可以work，内容主要参考了两篇论文，包括18年的一篇NIPS论文。&lt;br&gt;
    
    </summary>
    
      <category term="算法" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络之Batch Normalization（一）：How？</title>
    <link href="https://kiddie92.github.io/2019/03/06/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AHow%EF%BC%9F/"/>
    <id>https://kiddie92.github.io/2019/03/06/卷积神经网络之Batch-Normalization（一）：How？/</id>
    <published>2019-03-06T11:51:29.000Z</published>
    <updated>2019-03-11T14:11:40.207Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍深度学习里的一个常用的trick，主要用于加速收敛算法，这篇主要介绍一下怎么做的（How），下篇再介绍Why和该算法的一些好处，本来想着根据自己的理解写一下，看了大神写的之后我就决定”抄袭了”，（大神就是大神啊…）。原文使用MXNet实现的算法（原文查看文末的<strong>原文链接</strong>），这里改成使用TensorFlow实现一下这个例子。<br><a id="more"></a></p></blockquote><h1 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h1><p>这一节我们介绍批量归一化（batch normalization）层，它能让较深的神经网络的训练变得更加容易。在“实战 Kaggle 比赛：预测房价”一节里，我们对输入数据做了标准化处理：处理后的任意一个特征在数据集中所有样本上的均值为 0、标准差为 1。标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。</p><p>通常来说，数据标准化预处理对于浅层模型就足够有效了。随着模型训练的进行，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化。但对于深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。</p><p>批量归一化的提出正是为了应对深度模型训练的挑战。在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使得整个神经网络在各层的中间输出的数值更稳定。批量归一化和下一节将要介绍的残差网络为训练和设计深度模型提供了两类重要思路。</p><h2 id="批量归一化层"><a href="#批量归一化层" class="headerlink" title="批量归一化层"></a>批量归一化层</h2><p>对全连接层和卷积层做批量归一化的方法稍有不同。下面我们将分别介绍这两种情况下的批量归一化。</p><h3 id="对全连接层做批量归一化"><a href="#对全连接层做批量归一化" class="headerlink" title="对全连接层做批量归一化"></a>对全连接层做批量归一化</h3><p>我们先考虑如何对全连接层做批量归一化。通常，我们将<strong>批量归一化层置于全连接层中的仿射变换和激活函数之间</strong>。设全连接层的输入为$\boldsymbol{u}$，权重参数和偏差参数分别为 <script type="math/tex">\boldsymbol{W}</script> 和 <script type="math/tex">\boldsymbol{b}</script>，激活函数为 <script type="math/tex">\phi</script>。设批量归一化的操作符为 <script type="math/tex">\text{BN}</script>。那么，使用批量归一化的全连接层的输出为</p><script type="math/tex; mode=display">\phi(\text{BN}(\boldsymbol{x})),</script><p>其中批量归一化输入 <script type="math/tex">\boldsymbol{x}</script> 由仿射变换</p><script type="math/tex; mode=display">\boldsymbol{x} = \boldsymbol{W\boldsymbol{u} + \boldsymbol{b}}</script><p>得到。考虑一个由 <script type="math/tex">m</script> 个样本组成的小批量，仿射变换的输出为一个新的小批量 <script type="math/tex">\mathcal{B} = \{\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)} \}</script>。它们正是批量归一化层的输入。对于小批量 <script type="math/tex">\mathcal{B}</script> 中任意样本 <script type="math/tex">\boldsymbol{x}^{(i)} \in \mathbb{R}^d, 1 \leq  i \leq m</script>，批量归一化层的输出同样是 <script type="math/tex">d</script> 维向量</p><script type="math/tex; mode=display">\boldsymbol{y}^{(i)} = \text{BN}(\boldsymbol{x}^{(i)}),</script><p>并由以下几步求得。首先，对小批量 <script type="math/tex">\mathcal{B}</script> 求均值和方差：</p><script type="math/tex; mode=display">\boldsymbol{\mu}_\mathcal{B} \leftarrow \frac{1}{m}\sum_{i = 1}^{m} \boldsymbol{x}^{(i)},</script><script type="math/tex; mode=display">\boldsymbol{\sigma}_\mathcal{B}^2 \leftarrow \frac{1}{m} \sum_{i=1}^{m}(\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B})^2,</script><p>其中的平方计算是按元素求平方。接下来，我们使用按元素开方和按元素除法对 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 标准化：</p><script type="math/tex; mode=display">\hat{\boldsymbol{x}}^{(i)} \leftarrow \frac{\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B}}{\sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}},</script><p>这里 <script type="math/tex">\epsilon > 0</script> 是一个很小的常数，保证分母大于 0。在上面标准化的基础上，<strong>批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数 <script type="math/tex">\boldsymbol{\gamma}</script> 和偏移（shift）参数 <script type="math/tex">\boldsymbol{\beta}</script></strong>。这两个参数和 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 形状相同，皆为 <script type="math/tex">d</script> 维向量。它们与 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 分别做按元素乘法（符号 <script type="math/tex">\odot</script>）和加法计算：</p><script type="math/tex; mode=display">{\boldsymbol{y}}^{(i)} \leftarrow \boldsymbol{\gamma} \odot \hat{\boldsymbol{x}}^{(i)} + \boldsymbol{\beta}.</script><p>至此，我们得到了 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 的批量归一化的输出 <script type="math/tex">\boldsymbol{y}^{(i)}</script>。<br>值得注意的是，可学习的拉伸和偏移参数保留了不对 <script type="math/tex">\hat{\boldsymbol{x}}^{(i)}</script> 做批量归一化的可能：此时只需学出 <script type="math/tex">\boldsymbol{\gamma} = \sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}</script> 和 <script type="math/tex">\boldsymbol{\beta} = \boldsymbol{\mu}_\mathcal{B}</script>。我们可以对此这样理解：<strong>如果批量归一化无益，理论上学出的模型可以不使用批量归一化。</strong></p><h3 id="对卷积层做批量归一化"><a href="#对卷积层做批量归一化" class="headerlink" title="对卷积层做批量归一化"></a>对卷积层做批量归一化</h3><p>对卷积层来说，批量归一化<strong>发生在卷积计算之后、应用激活函数之前</strong>。如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数，且均为标量。设小批量中有 <script type="math/tex">m</script> 个样本。在单个通道上，假设卷积计算输出的高和宽分别为 <script type="math/tex">p</script> 和 <script type="math/tex">q</script>。我们需要对该通道中 <script type="math/tex">m \times p \times q</script> 个元素同时做批量归一化。对这些元素做标准化计算时，我们使用相同的均值和方差，即该通道中 <script type="math/tex">m \times p \times q</script> 个元素的均值和方差。</p><h3 id="测试-预测时的批量归一化"><a href="#测试-预测时的批量归一化" class="headerlink" title="测试/预测时的批量归一化"></a>测试/预测时的批量归一化</h3><p>使用批量归一化训练时，我们<strong>可以将批量大小设的大一点</strong>，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用来预测/测试时，我们希望模型对于任意输入都有确定的输出。因此，单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差。一种常用的方法是<strong>通过移动平均估算整个训练数据集的样本均值和方差</strong>，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，批量归一化层在训练模式和预测模式下的计算结果也是不一样的。</p><h1 id="tensorflow调用"><a href="#tensorflow调用" class="headerlink" title="tensorflow调用"></a>tensorflow调用</h1><p>根据上面的讲解，运算流程应该是，输入神经元（neural）的数据先做<script type="math/tex">w \cdot u+b</script>得到<script type="math/tex">x_i</script>，再按照上面的公式对一个batch内的<script type="math/tex">x_i</script>进行normalization并接着scale和shift，之后再对其进行激活得到<script type="math/tex">z_i</script>。</p><script type="math/tex; mode=display">u_{i} -仿射变换-> x_i -标准化-> \hat{x_i} -拉伸和偏移-> y_i --> activation --> z_i</script><p>下面，使用mnist手写数字识别为例，按照这个流程走一遍吧，在tensorflow中调用使用的是<code>tf.layers.batch_normalization</code>，完整代码请看<a href="https://github.com/kiddie92/Learning_Tech/tree/master/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AHow%EF%BC%9F" target="_blank" rel="noopener">这里</a>(<strong>使用jupter-notebook查看</strong>)：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">epsilon = <span class="number">0.001</span></span><br><span class="line">Wx_plus_b = tf.layers.batch_normalization(Wx_plus_b, mean, var, shift, scale, epsilon)</span><br><span class="line"><span class="comment"># similar with this two steps:</span></span><br><span class="line"><span class="comment"># Wx_plus_b = (Wx_plus_b - fc_mean) / tf.sqrt(fc_var + 0.001)</span></span><br><span class="line"><span class="comment"># Wx_plus_b = Wx_plus_b * scale + shift</span></span><br></pre></td></tr></table></figure></p><p><strong>转载自：</strong>动手学深度学习<br><strong>原文网址：</strong><a href="https://zh.gluon.ai/chapter_convolutional-neural-networks/batch-norm.html" target="_blank" rel="noopener">https://zh.gluon.ai/chapter_convolutional-neural-networks/batch-norm.html</a><br><strong>作者：</strong>阿斯顿·张、<strong>李沐</strong>、扎卡里 C. 立顿、亚历山大 J. 斯莫拉</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文主要介绍深度学习里的一个常用的trick，主要用于加速收敛算法，这篇主要介绍一下怎么做的（How），下篇再介绍Why和该算法的一些好处，本来想着根据自己的理解写一下，看了大神写的之后我就决定”抄袭了”，（大神就是大神啊…）。原文使用MXNet实现的算法（原文查看文末的&lt;strong&gt;原文链接&lt;/strong&gt;），这里改成使用TensorFlow实现一下这个例子。&lt;br&gt;
    
    </summary>
    
      <category term="算法" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>go语言为网站生成二维码</title>
    <link href="https://kiddie92.github.io/2019/03/05/go%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%BD%91%E5%9D%80%E4%BA%8C%E7%BB%B4%E7%A0%81/"/>
    <id>https://kiddie92.github.io/2019/03/05/go语言生成网址二维码/</id>
    <published>2019-03-05T13:40:49.000Z</published>
    <updated>2019-03-05T16:04:31.034Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>二维码有点意思，想着把俺的博客地址用二维码展示出来，比较来看还是go语言比较强大啊…<br><a id="more"></a></p></blockquote><h1 id="搭建golang环境"><a href="#搭建golang环境" class="headerlink" title="搭建golang环境"></a>搭建golang环境</h1><h2 id="安装go"><a href="#安装go" class="headerlink" title="安装go"></a>安装go</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ubuntu</span></span><br><span class="line">sudo apt install golang-go</span><br><span class="line"><span class="comment"># CentOS</span></span><br><span class="line">sudo yum install go</span><br></pre></td></tr></table></figure><h2 id="设置GOPATH"><a href="#设置GOPATH" class="headerlink" title="设置GOPATH"></a>设置GOPATH</h2><p>将GOPATH添加至环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="built_in">export</span> GOPATH=/root/go &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="comment"># 设置当前终端生效</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc </span><br><span class="line"><span class="comment"># 查看GOPATH</span></span><br><span class="line">go env</span><br></pre></td></tr></table></figure></p><p>创建所需文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/go</span><br><span class="line">mkdir bin &amp;&amp; mkdir pkg &amp;&amp; mkdir src</span><br></pre></td></tr></table></figure><p>GOPATH的目录结构:</p><ul><li>bin 编译后生成的可执行文件</li><li>pkg 编译后生成的文件（比如：.a）</li><li>src 存放源代码（比如：.go .c .h .s等）</li></ul><h2 id="运行代码"><a href="#运行代码" class="headerlink" title="运行代码"></a>运行代码</h2><p>导入第三方包：<code>go get -u github.com/yeqown/go-qrcode</code></p><p>新建文件夹<code>makeqrcode</code>，进入该文件夹后，新建文件 <code>makeqrforwebsite.go</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">        <span class="string">"fmt"</span></span><br><span class="line">        qrcode <span class="string">"github.com/yeqown/go-qrcode"</span> <span class="comment">// 给后面的包一个简称</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">        qrc, err := qrcode.New(<span class="string">"https://kiddie92.github.io/"</span>)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span>&#123;</span><br><span class="line">                fmt.Printf(<span class="string">"could not generate QRCode: %v"</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 保存二维码</span></span><br><span class="line">        <span class="keyword">if</span> err := qrc.Save(<span class="string">"."</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">                fmt.Printf(<span class="string">"could not save image: %v"</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>直接运行：<code>go run makeqrforwebsite.go</code>，生成本博客地址对应的二维码，扫描一下试试。</p><p><img src="./kiddie92.jpeg" width="30%" height="30%"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/yeqown/go-qrcode/" target="_blank" rel="noopener">https://github.com/yeqown/go-qrcode/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;二维码有点意思，想着把俺的博客地址用二维码展示出来，比较来看还是go语言比较强大啊…&lt;br&gt;
    
    </summary>
    
      <category term="go" scheme="https://kiddie92.github.io/categories/go/"/>
    
      <category term="Just for Fun" scheme="https://kiddie92.github.io/categories/go/Just-for-Fun/"/>
    
    
      <category term="go" scheme="https://kiddie92.github.io/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>浅谈深度学习算法 -- 能不能学物理定律?</title>
    <link href="https://kiddie92.github.io/2019/03/03/%E6%B5%85%E8%B0%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E8%83%BD%E4%B8%8D%E8%83%BD%E5%AD%A6%E7%89%A9%E7%90%86%E5%AE%9A%E5%BE%8B/"/>
    <id>https://kiddie92.github.io/2019/03/03/浅谈深度学习算法-能不能学物理定律/</id>
    <published>2019-03-03T12:37:49.000Z</published>
    <updated>2019-03-05T13:00:06.918Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本篇博客以一个物理问题为出发点，试图从数学的角度来理解一下深度学习算法。主要围绕着深度学习算法（未讨论非监督学习）能否学习出物理定律这个问题进行阐述。<br><a id="more"></a></p></blockquote><h1 id="先看一个物理问题"><a href="#先看一个物理问题" class="headerlink" title="先看一个物理问题"></a>先看一个物理问题</h1><p><img src="picture1.png" alt="示意图"></p><p>如上图所示，使用一个锤子敲击地面，会给地面造成一个冲击力，冲击造成的<strong>震源</strong>可以大致表示成图中<strong>（a）</strong>所显示的信号，震源使地面开始震动形成波场，<strong>（a）</strong>信号随着地面震动而传播，位于远处的<strong>检测器</strong>（倒三角形所示）感受到检测器所在位置的地面震动，并记录下来就得到了途中<strong>（b）</strong>所示的信号。这个问题可以简单理解成声音的传播，<strong>(a)</strong>是声源，经过大地传播之后（滤波作用），使接收声波的一方接收到信号<strong>（b）</strong>。</p><p>显然，不同的地质环境，大地的”材质”也会不同，那么一定会影响到<strong>（b）</strong>信号的最终形态。这就好像，人在水里说话和在空气中说话听到的声音肯定也会不一样。那么，如何描述材料的性质和接收信号<strong>（b）</strong>的关系呢？（<em>我们把这一关系表达为以下映射，在物理中称为正演问题</em>）下面给出两种解法。<br>$公式$</p><script type="math/tex; mode=display">Model Parameterts --> Data</script><h2 id="物理方法"><a href="#物理方法" class="headerlink" title="物理方法"></a>物理方法</h2><p>物理学家根据力学定律以及材料的弹性性质、密度等参数推导出<script type="math/tex">Model</script>和<script type="math/tex">Data</script>之间有着定量的关系，可以描述成下图的物理方程，有了这个方程，我们就可以建立这两者之间的关系了。</p><p><img src="phy_law.png" alt="物理方法"></p><h2 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h2><p>如今，我们还可以使用深度学习方法建立<script type="math/tex">Model</script>和<script type="math/tex">Data</script>之间的定量关系。首先我们建立一个网络架构，比如用几个卷积层、几个全链接层等，每一个神经元还有一组参数<script type="math/tex">[W]，[b]</script>通过给定<script type="math/tex">Model</script>和<script type="math/tex">Data</script>的数据对，不断的改进神经元的参数，最终在function set里面找到一个相对令人满意的函数，其可以表示<script type="math/tex">Model</script>和<script type="math/tex">Data</script>之间的映射关系。</p><p><img src="NN.png" alt="深度学习"></p><h1 id="问题的提出和回答"><a href="#问题的提出和回答" class="headerlink" title="问题的提出和回答"></a>问题的提出和回答</h1><p>上面给出了两种方法来解这个问题，我们可以看到如果两种方法都能解这个正演问题（<strong><em>深度学习实际上是在从数据反推回模型的过程中逐步给出正演函数的</em></strong>），那么是不是深度学习学习到的模型等价于物理定律呢，换句话说深度学习可以学到物理定律？</p><p>这个问题我给它拆成两个：</p><ol><li><strong>深度学习建立<script type="math/tex">Model</script>到<script type="math/tex">Data</script>的映射这件事情能不能做？</strong><br>肯定能，因为有人已经证明了深度学习算法可以拟合任何复杂的函数，参见<a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" target="_blank" rel="noopener">Universal approximation theorem</a>。相关问题也可以看看这里<a href="https://www.zhihu.com/question/268384579" target="_blank" rel="noopener">神经网络为什么可以拟合任意函数？</a>。也就是说，<script type="math/tex">Model</script>到<script type="math/tex">Data</script>的映射再复杂，深度学习也可以给你找个函数来逼近它。</li><li><strong>建立的映射好不好用？或者说模型的泛化能力会很强吗？</strong><br>虽说神经网络有万能逼近的性质，但是逼近的好不好就另说了，因为毕竟没有拿所有的数据集去训练，而一个物理问题的数据集几乎可以说是无限大的。那有没有可能深度学习学习出来的模型恰好和物理定律一致呢？那就得把深度学习模型当作一个函数来研究了，看看它是不是化简完恰好就是物理方程，不过，几万甚至上亿个参数的函数，研究起来应该很头疼吧，一般人肯定会疯掉的，所以说这个问题还是交给科学家去解决吧。<blockquote><p>这里和胡师兄讨论的时候，发现我们的理解基本一致（难道是因为大家都学地球物理的吗…）</p></blockquote></li></ol><p>其实，一个非线性的物理问题也可以线性化，比如使用泰勒展开就可以做到；从另外一个角度去理解就是<script type="math/tex">G(m)=d</script>转化成<script type="math/tex">Gm=d</script>的问题。但是，由于数据有限，这里的<script type="math/tex">G</script>存在<script type="math/tex">0</script>空间，所以会有<script type="math/tex">G_0m=0</script>，也就是说有限的数据集几乎是不可能约束<script type="math/tex">G</script>的。</p><h1 id="其他策略"><a href="#其他策略" class="headerlink" title="其他策略"></a>其他策略</h1><p>为了让深度学习学到的模型/函数/映射更加接近”理论事实”，我们可以加一些约束，比如先做特征提取、结合比较好解释的机器学习和深度学习算法来学习出一个泛化能力更强的模型/函数/映射。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>深度学习算法一般来说只能学习到数据集中已有的知识，它比较<strong>擅长于归纳，而不擅长演绎</strong>。对于<strong>非监督学习</strong>，情况可能比较复杂，暂不讨论。此外，世界是复杂的，但是伟大的理论通常在数学表达上都是简单优美的，这恐怕是<strong>现阶段</strong>人工智能所不能企及的。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本篇博客以一个物理问题为出发点，试图从数学的角度来理解一下深度学习算法。主要围绕着深度学习算法（未讨论非监督学习）能否学习出物理定律这个问题进行阐述。&lt;br&gt;
    
    </summary>
    
      <category term="算法" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="知识理解" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E7%90%86%E8%A7%A3/"/>
    
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 特性--Graph 和 Sessions</title>
    <link href="https://kiddie92.github.io/2019/03/02/TensorFlow-%E7%89%B9%E6%80%A7-Graph-%E5%92%8C-Sessions/"/>
    <id>https://kiddie92.github.io/2019/03/02/TensorFlow-特性-Graph-和-Sessions/</id>
    <published>2019-03-02T14:14:11.000Z</published>
    <updated>2019-03-03T12:53:31.617Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>深度学习框架有很多，Google的TensorFlow市场占有率居高不下，本文的小目标是说清楚tensorflow的<strong>“图（Graph）”</strong>和<strong>“会话（Session）”</strong>机制及其优缺点，最后以一个回归问题为例实践一下。文中顺便回答一下<strong>动态图（Dynamic computation graphs）</strong>和<strong>静态图（Static computational graphs）</strong>框架的区别。<br><a id="more"></a></p></blockquote><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p><strong>深度学习</strong>是目前人工智能领域备受推崇的算法种类，其在计算机视觉（Computer vision）、自然语言处理（NLP）领域有比较广泛的应用，这里先挖个坑，<a href="https://kiddie92.github.io/2019/03/03/%E6%B5%85%E8%B0%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E8%83%BD%E4%B8%8D%E8%83%BD%E5%AD%A6%E7%89%A9%E7%90%86%E5%AE%9A%E5%BE%8B/">下一篇</a>将谈谈我对深度学习算法的理解。</p><p>目前开源市场的深度学习框架有很多，如<code>tensorflow</code>、<code>pytorch</code>、<code>mxnet</code>等，而tensorflow的市场占有率相对较高，那么为什么会有如此多的深度学习框架，tensorflow又有什么异于常人的地方呢？为了回答这个问题，本文首先尝试说明一下tensorflow的<code>Graph+Session</code>机制。</p><p>市面上的各种深度学习框架：</p><p><img src="DL-framework.png" alt="DeepLearning frameworks"></p><h2 id="计算图（Graph）"><a href="#计算图（Graph）" class="headerlink" title="计算图（Graph）"></a>计算图（Graph）</h2><p>简单来说，计算图是由tensor和opration组成的一张工程图纸。先上图（从图中来看，这是一个分类问题…），文末还附了一张PyTorch的动态图，有兴趣可以对比一下。</p><p><img src="tensors_flowing.gif" alt="Tensor and Flow"></p><h3 id="张量（Tensor）"><a href="#张量（Tensor）" class="headerlink" title="张量（Tensor）"></a>张量（Tensor）</h3><p>先把力学里面的张量忘掉，这里的张量概念包括标量、矢量和线性算子，或者简单理解成高维矩阵。输入的数据、参数大多是高维矩阵，统一被称为tensor，此外，tensor之间经过各种计算得到的结果依然是一个张量。</p><ul><li>输入<code>tf.placeholder</code></li><li>参数<code>tf.Variable</code></li><li>算子<code>tf.matmul</code>、<code>tf.sqrt()</code>等</li></ul><h3 id="算子（Operation）"><a href="#算子（Operation）" class="headerlink" title="算子（Operation）"></a>算子（Operation）</h3><p>Tensor之间的各种运算统称为operation，如加减乘除、开根号等。tensor进入operation进行各种计算，输出结果到下一个operation继续计算，像是tensor在流动，TensorFlow由此得名。</p><h2 id="会话-（Session）"><a href="#会话-（Session）" class="headerlink" title="会话 （Session）"></a>会话 （Session）</h2><p>当<code>tf.graph</code>定义好后，打开一个<code>tf.session</code>执行Graph，简单来说，会话是指机器根据工程图纸打开计算资源进行施工。Session提供了Operation执行和Tensor求值的环境，此外其还拥有物理资源（GPUs和网络连接）。当我们不再需要该session的时候，需要调用<code>sess.close()</code>关闭会话，将这些资源释放。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a default in-process session.</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a remote session.</span></span><br><span class="line"><span class="keyword">with</span> tf.Session(<span class="string">"grpc://example.org:2222"</span>):</span><br><span class="line">  <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><h2 id="数据流-（Dataflow）"><a href="#数据流-（Dataflow）" class="headerlink" title="数据流 （Dataflow）"></a>数据流 （Dataflow）</h2><p>Dataflow是一个常见的并行计算编程模型。在一个dataflow图中（如上gif图所示），节点表示计算单元，边界则表示计算单元对数据的生产和消费。dataflow模式有几个比较大的优势：</p><ul><li><strong>Parallelism</strong>：知道了各个operation之间的依赖关系，系统就可以比较好的使用并行计算了，比如：矩阵相乘可以并行计算、A算子的输入与B算子的输出没有依赖关系也可以并行计算。</li><li><strong>Distributed execution</strong>：同样利用每个operation之间的依赖关系，tensorflow好让一些计算被调度到不同机器的多个设备上（CPUs, GPUs, TPUs），tensorflow还会提供必要的机器之间的通信。</li><li><strong>Compilation</strong>：tensorflow的 XLA 编译器利用dadaflow图编译更快的机器码。</li><li><strong>Portability</strong>：datdaflow图使模型表示是语言无关的。<code>tf.saved_model</code>保存的模型可以在其他语言中使用，非常便携。</li></ul><h2 id="实践-—-回归问题"><a href="#实践-—-回归问题" class="headerlink" title="实践 — 回归问题"></a>实践 — 回归问题</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ol><li><p>构造一个函数/映射，<script type="math/tex">y_{data} = f(x_{data})</script>，其中 <script type="math/tex">x_{data}</script>是一个随机输入的<script type="math/tex">2\times100</script>矩阵，<script type="math/tex">y_{data}</script>是一个<script type="math/tex">1\times100</script>矩阵，由一个参数矩阵<script type="math/tex">W=\begin{bmatrix} 0.1 & 0.2 \end{bmatrix}</script> 和 <script type="math/tex">x_{data}</script>点乘后加上一个常数<script type="math/tex">b=0.3</script>构造出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用Numpy生成假数据(phony data),总共100个点.</span></span><br><span class="line">x_data = np.float32(np.random.rand(<span class="number">2</span>, <span class="number">100</span>))      <span class="comment"># 随机输入</span></span><br><span class="line">print(x_data)</span><br><span class="line">y_data = np.dot([<span class="number">0.100</span>, <span class="number">0.200</span>], x_data) + <span class="number">0.300</span>  <span class="comment">#输出的y为[[]]的list</span></span><br><span class="line">print(y_data)</span><br></pre></td></tr></table></figure></li><li><p>使用<script type="math/tex">x_{data}</script>和<script type="math/tex">y_{data}</script>数据来反演/学习出参数矩阵<script type="math/tex">W</script>和常量参数<script type="math/tex">b</script>，该问题等价于<strong>由100个方程求解三个参数问题</strong>，显然是一个<strong>超定问题</strong>，求解过程就是一个<strong>优化</strong>过程。</p><script type="math/tex; mode=display">\begin{pmatrix}     W_1X_{1,1} + W_2X_{2,1} +b = y_1 \\     W_1X_{1,2} + W_2X_{2,2} +b = y_2 \\      ... \\     W_1X_{1,100} + W_2X_{2,100} +b =y_{100} \\\end{pmatrix}</script></li><li><p>假设我们已经知道这个函数式了$Wx+b=y$，仅仅不知道给定的参数<script type="math/tex">W</script>和<script type="math/tex">b</script>是什么，根据函数式，可以使用初始化参数来构造<script type="math/tex">y</script>，并计算<script type="math/tex">y</script>和<script type="math/tex">y_{data}</script>之间的<em>“距离”</em>，并使用梯度下降的方式找到一个最优参数组使<strong>距离</strong>尽量减少。见代码部分10-13行。</p></li></ol><blockquote><p><strong>注意</strong>：</p><ol><li>现实世界中往往是不知道两个随机变量之间的确切关系的</li><li>这里”距离”是指向量之间的空间距离，常用的距离有欧几里得距离（2-范数）曼哈顿距离（1-范数）等。本例中使用2-范数作为距离，也即最小方差/最小二乘/Least Square方法。</li></ol></blockquote><h3 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h3><p>由于tensorflow和cuda版本（9.0.176）兼容问题，选择安装V1.12.0GPU版本，本机tensorflow环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[conan@localhost ~]$ conda list | grep tensor</span><br><span class="line">tensorboard               1.12.0                    &lt;pip&gt;</span><br><span class="line">tensorflow-gpu            1.12.0                    &lt;pip&gt;</span><br><span class="line">tensorflow-tensorboard    0.4.0                     &lt;pip&gt;</span><br></pre></td></tr></table></figure><h3 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h3><p>这里使用一个简单的平面拟合问题来实践一下，完整代码请看<strong><a href="https://github.com/kiddie92/Learning_Tech/blob/master/TensorFlow%20%E7%89%B9%E6%80%A7--Graph%20%E5%92%8C%20Sessions/Demo1_tensor.py" target="_blank" rel="noopener">这里</a></strong></p><ul><li>拟合时主要关注的参数为：<code>tf.train.GradientDescentOptimizer(0.2)</code>里的学习率（或者叫做步长）、和迭代次数<code>for step in range(0, 51):</code>，减小学习率增加迭代次数理论上会使拟合效果更好，但是会有过拟合（over fitting）的危险，并且模型的泛化能力（generalization）会比较差，控制这种风险的算法也很多，比如给目标函数加正则化（regularization）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个线性模型</span></span><br><span class="line"><span class="comment"># 实际问题中如果没有确切的物理关系,很难知道是否是线性模型, 也很难知道解在哪个范围</span></span><br><span class="line"></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">W = tf.Variable(tf.random_uniform([<span class="number">1</span>, <span class="number">2</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">y = tf.matmul(W, x_data) + b   <span class="comment"># y is synthetic data</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面开始构建Graph</span></span><br><span class="line"><span class="comment"># 最小化方差(Least Square) 定义目标函数/损失函数/misfit function</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line"><span class="comment"># 优化器就使用最原始的梯度下降方法，参数为learning rate/步长</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>)   </span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"><span class="comment"># 启动会话</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合平面/反演参数/回归分析</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">51</span>):</span><br><span class="line">    sess.run(train)   <span class="comment"># 参数train就是前面定义的dataflow graph</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        print(step, sess.run(W), sess.run(b))</span><br><span class="line">W = sess.run(W)</span><br><span class="line">b = sess.run(b)</span><br><span class="line">sess.close()  </span><br><span class="line"><span class="comment"># 最终反演出来的方程</span></span><br><span class="line">y_pred = np.dot(W, x_data) + b</span><br><span class="line">print(<span class="string">'----------------'</span>)</span><br><span class="line">print(y_pred[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 得到最佳拟合结果 W: [[0.100 0.200]]\, b: [0.300]</span></span><br></pre></td></tr></table></figure><p>得到的y和y_data的对比：<br><img src="Comparation.jpg" alt="Comparation"></p><h1 id="静态图和动态图"><a href="#静态图和动态图" class="headerlink" title="静态图和动态图"></a>静态图和动态图</h1><p>回到最开始的问题，TensorFlow异于常人的地方：其实就是“<strong>静态图</strong>”框架。引用“hackernoon”上看到的一句话：</p><blockquote><p>TensorFlow is a <strong>“Define-and-Run”</strong> framework where one would define conditions and iterations in the graph structure whereas in comparison Chainer, DyNet, PyTorch are all <strong>“Define-by-Run”</strong> frameworks.</p></blockquote><p><strong>动态计算图框架</strong>使用起来就像做工程时一边设计一边施工，TensorFlow使用起来就没有“<strong>动态图</strong>”框架那样灵活、直接，容易调试，而这也是其入门门槛高的一个原因。但是，<strong>“静态图”</strong>的优点也是明显的—计算会更加高效，因为所有的步骤都定义好了再进行计算使计算机资源的调配更加合理、高效。所以说，“动态图”和“静态图”是优势互补的。</p><blockquote><p>TensorFlow 2.0 推出了Eager Execution，开始支持“动态图”了</p></blockquote><p><img src="dynamic_graph_pytorch.gif" alt="Dynamic Graph of PyTorch"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.tensorflow.org/guide/graphs?hl=en" target="_blank" rel="noopener">Graphs and Sessions</a></li><li><a href="https://hackernoon.com/how-is-pytorch-different-from-tensorflow-2c90f44747d6" target="_blank" rel="noopener">How is PyTorch different from Tensorflow?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;深度学习框架有很多，Google的TensorFlow市场占有率居高不下，本文的小目标是说清楚tensorflow的&lt;strong&gt;“图（Graph）”&lt;/strong&gt;和&lt;strong&gt;“会话（Session）”&lt;/strong&gt;机制及其优缺点，最后以一个回归问题为例实践一下。文中顺便回答一下&lt;strong&gt;动态图（Dynamic computation graphs）&lt;/strong&gt;和&lt;strong&gt;静态图（Static computational graphs）&lt;/strong&gt;框架的区别。&lt;br&gt;
    
    </summary>
    
      <category term="tensorflow" scheme="https://kiddie92.github.io/categories/tensorflow/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/categories/tensorflow/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="https://kiddie92.github.io/tags/tensorflow/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes 性能测试方法简介</title>
    <link href="https://kiddie92.github.io/2019/01/23/kubernetes-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E7%AE%80%E4%BB%8B/"/>
    <id>https://kiddie92.github.io/2019/01/23/kubernetes-性能测试方法简介/</id>
    <published>2019-01-23T06:41:43.000Z</published>
    <updated>2019-03-02T15:48:28.793Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍kubernetes（以下简称k8s）在性能测试中的主要关注指标以及涉及的辅助测试工具。由于各企业在私有云建设过程中使用的技术标准不尽相同，文中尽可能介绍可能涉及的通用性测试项，由于作者水平有限，以下内容仅供参考，欢迎讨论以及指正。<br><a id="more"></a> </p><h2 id="部署环境简要"><a href="#部署环境简要" class="headerlink" title="部署环境简要"></a>部署环境简要</h2><p>企业级k8s集群需要达到生产可用（GA），在部署上常采用高可用方案（HA），也即多台master节点和多台node节点的组合形式。生产上，k8s集群通常搭建在私有云或公有云IaaS之上，且需要较高的硬件资源支持。</p></blockquote><h3 id="集群资源"><a href="#集群资源" class="headerlink" title="集群资源"></a>集群资源</h3><p>从k8s集群部署需求的角度来说，集群资源应该明确给出，包括CPU、内存、系统、存储、网络以及相关的性能指标，而这些都可以由IaaS层提供，这里简单声明如下：</p><ul><li>集群存储：采用NAS作为后端持久化存储方案</li><li>集群网络：VMware提供的NSX-T容器网络方案</li><li>集群系统、CPU、内存资源列表：</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">角色</th><th style="text-align:center">角色说明</th><th style="text-align:center">节点数</th><th style="text-align:center">cpu</th><th style="text-align:center">内存</th><th style="text-align:center">系统</th><th style="text-align:center">存储大小</th></tr></thead><tbody><tr><td style="text-align:center">master</td><td style="text-align:center">k8s master节点</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">16</td><td style="text-align:center">CentOS 7.5</td><td style="text-align:center">100G</td></tr><tr><td style="text-align:center">node</td><td style="text-align:center">k8s计算节点</td><td style="text-align:center">2</td><td style="text-align:center">8</td><td style="text-align:center">16</td><td style="text-align:center">CentOS 7.5</td><td style="text-align:center">100G</td></tr></tbody></table></div><h3 id="集群部署架构"><a href="#集群部署架构" class="headerlink" title="集群部署架构"></a>集群部署架构</h3><p>企业级集群部署架构需要考虑很多因素，其中最主要的是需要有<strong>管理平面</strong>和<strong>业务平面</strong>，核心则是降低平台的使用复杂度和运维复杂度，所以部署上我们不仅仅需要有高可用的业务集群，还需要有相应的配套服务机制，其中包括监控（metrics）、日志（Logs）、网络管控、存储管控、负载均衡、私有云场景还需要提供yum源和镜像仓库服务等。</p><blockquote><p>这里，我们的监控采用单个集群使用<code>Prometheus</code>作为TSDB+<code>grafana</code>作为数据展示，而日志方面则以<code>ElasticSearch</code>集群部署的方式进行存储收集。</p></blockquote><p>业务集群的部署架构图则如下所示（图片来自<a href="https://elastisys.com/2018/01/25/setting-highly-available-kubernetes-clusters/" target="_blank" rel="noopener">这里</a>）<br><img src="k8sHA.jpg" alt="HA部署架构"></p><h2 id="容器网络测试"><a href="#容器网络测试" class="headerlink" title="容器网络测试"></a>容器网络测试</h2><h3 id="容器网络简介"><a href="#容器网络简介" class="headerlink" title="容器网络简介"></a>容器网络简介</h3><p>k8s的最小调度单位为<code>Pod</code>，而Pod“内部”的容器会通过Linux namespace机制与infra容器共享网络栈，所以<a href="https://www.nginx.com/resources/library/container-networking-docker-kubernetes/" target="_blank" rel="noopener">容器网络</a>就是指Pod之间通信的网络，kubernetes以开放插件接口的形式（Container Network Interface）让第三方插件提供Pod间网络通信的能力。</p><blockquote><p>目前主流的k8s容器网络插件有开源的Weave、Calico、Flannel-HostGW、Flannel-VxLAN、MacVLAN、IpVLAN…以及未开源的VMware NSX-T。</p></blockquote><h3 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h3><p>从容器网络性能测试的角度来说，关注点主要在于不同场景下带宽、计算资源消耗的情况。下面简单介绍一下相关的测试场景和测试策略以及涉及的测试工具：</p><blockquote><p>由于k8s网络插件在工作过程中存在Linux的<code>User Space</code>和<code>Kernel Space</code>的交互（封包解包），这是性能损耗的主要来源之一；<br>如果考虑网络安全，需要加上网络插件的限制隔离机制（Network Policies）的测试。</p></blockquote><ul><li>场景一：同主机Pod间通信</li><li>场景二：跨主机Pod间通信</li><li>场景三：集群内主机和主机间通信</li><li>场景四：Pod与宿主机间通信</li><li>场景五：Pod与非宿主机间通信</li><li>测试策略：固定网络带宽，固定网络类型，测试不同数据包大小对网络吞吐量的影响，例如可以测试获取文件传输量超过10G，系统在文件传输高峰时对局域网的<strong>带宽要求</strong>，并对比容器网络传输和非容器网络（Bare Metal）传输之间的<strong>CPU消耗</strong>以及<strong>内存消耗</strong>情况。</li><li>测试工具：<a href="https://iperf.fr/iperf-doc.php#3doc" target="_blank" rel="noopener">iperf3</a>，容器化运行在k8s集群上</li></ul><blockquote><p>相关的测试可以参考<a href="https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560" target="_blank" rel="noopener">这里</a>。</p></blockquote><h3 id="网络延迟"><a href="#网络延迟" class="headerlink" title="网络延迟"></a>网络延迟</h3><p>造成容器网络延迟的主要原因是传输延迟及处理延迟，这里的测试关注点在于不同CNI插件下，不同场景的网络延迟。</p><ul><li>场景一：通过Service的VIP或DNS进行集群内部访问</li><li>场景二：通过NodePort进行集群外部访问</li><li>场景三：通过IaaS层提供的LoadBalancer进行访问</li><li>测试策略：容器化运行<code>qperf</code>，依据场景的不同，通过设置yaml文件为qperf添加不同的Service访问方式，测试其在访问过程中的网络延迟。</li><li>涉及工具：<a href="https://linux.die.net/man/1/qperf" target="_blank" rel="noopener">qperf</a></li></ul><blockquote><p>需要注意的是：由于容器网络是基于IaaS层网络搭建，而IaaS层网络通常又是一个跨数据中心的“大二层”网络，虚拟机本身的物理位置对k8s集群来说已经是无感知的了，如此一来，容器网络的测试指标与IaaS网络其实是耦合在一起的，那么容器网络的测试实际上也是包含了IaaS层网络性能考量。</p></blockquote><h2 id="容器存储测试"><a href="#容器存储测试" class="headerlink" title="容器存储测试"></a>容器存储测试</h2><p>针对有状态应用的数据持久化以及容器日志存储需求，k8s设计了容器存储接口（CSI）并辅以PV、PVC的机制实现分布式应用的持久化存储，目前支持CSI实现容器持久化存储的方案有<a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/" target="_blank" rel="noopener">很多</a>。存储的测试主要考量的指标是容器对数据卷的读写IO，除此之外，还需要考虑容器迁移是否依然能够实现数据持久化。</p><ul><li>场景一：多容器实例跨主机部署，数据持久化</li><li>场景二：单个容器对数据卷进行读写IO</li><li>测试策略：k8s上使用deployment部署多个应用实例，每个Pod使用同一个PVC挂载同一个目录（Pod一般会分布在不同的主机上），再查看多个应用实例的数据是否同步写入同一后端存储；此外，在单容器内部使用<code>dd</code>命令在挂载目录下（本地存储或分布式存储）进行读、写以及读写测试，并使用参数<code>iflag=direct</code>，观察输出的平均读写时间。</li><li>涉及工具：<a href="https://linux.die.net/man/1/dd" target="_blank" rel="noopener">dd</a></li></ul><h2 id="k8s-并发测试"><a href="#k8s-并发测试" class="headerlink" title="k8s 并发测试"></a>k8s 并发测试</h2><p>对于使用go编写的k8s来说，并发能力理论上很强。性能测试上，可以使用多线程执行创建、删除、查询各类资源，由于k8s的最小调度单元为Pod，测试时可以仅使用创建deployment作为场景，主要的关注指标为<strong>错误率</strong>和<strong>平均响应时间</strong>以及<strong>硬件资源消耗</strong>：</p><ul><li>场景一：多线程并发创建deployment，再并发删除deployment</li><li>测试策略：使用Jmeter多线程方式发送创建不同name的deployment资源的json文件至<code>kube-apiserver</code>，删除亦如此；同时通过<code>Prometheus</code>和<code>Grafana</code>对集群的资源和相关组件的资源使用进行监控。 </li><li>涉及工具：<code>Jmeter</code> <code>curl</code> <code>Prometheus</code> <code>Grafana</code></li></ul><h3 id="kube-apiserver-api-规范"><a href="#kube-apiserver-api-规范" class="headerlink" title="kube-apiserver api 规范"></a>kube-apiserver api 规范</h3><p>使用curl测试一下kube-apiserver的api规范：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">-d @filename.json -H <span class="string">"Content-Type: application/json"</span> \</span><br><span class="line">-H <span class="string">"Authorization: Bearer <span class="variable">$&#123;token&#125;</span>"</span> <span class="variable">$&#123;api_url_or_ip:8080&#125;</span>/apis/extensions/v1beta1/namespaces/<span class="variable">$&#123;namespace_name&#125;</span>/deployments</span><br></pre></td></tr></table></figure></p><h3 id="deployment命名不可重复"><a href="#deployment命名不可重复" class="headerlink" title="deployment命名不可重复"></a>deployment命名不可重复</h3><p>由于deployment的name、label不可以重复，这里可以使用jmeter设置变量，并将变量赋值到将要发送的json文件内，点击<a href="https://github.com/Conan-D/jubernetes-test/blob/master/deployment.json" target="_blank" rel="noopener">deployment.json</a>即可查看deployment的json文件。</p><h2 id="横向伸缩能力测试"><a href="#横向伸缩能力测试" class="headerlink" title="横向伸缩能力测试"></a>横向伸缩能力测试</h2><p>k8s的横向伸缩能力主要体现在两个层面：node扩展和Pod扩展，但是node的扩展同时需要IaaS的能力支持，我们这里仅仅考虑Pod的横向扩缩容。k8s可以开启<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noopener">Horizontal Pod Autoscaler</a>功能，对接了metrics指标后，可以实现根据指标策略来自动扩缩应用副本数（Pod数）。因此，性能测试需要关注的指标有：Pod在扩缩容过程中所需的启停时间；扩缩过程中服务是否会出现中断，也即服务的错误率；以及服务的TPS变化；同时对集群资源的使用率进行监控。</p><ul><li>场景一：对deployment进行扩容操作</li><li>场景二：对deployment进行缩容操作</li><li>测试策略：部署单个应用至k8s集群，关联的service端口暴露方式为NortPort，使用Jmeter对该服务进行多线程持续访问；修改deployment的replica参数，使用<code>kubectl apply -f ${deployment.yaml}</code>更新应用，观察Jmeter的TPS、Error指标数据，以及集群资源监控数据。</li></ul><blockquote><p>关于scale out/in，k8s把Pod当做”cattle”而不是”pet”去管理，这里的测试并没有使用HPA，所以手动扩缩容实际上使用的是Rolling Update，Rolling Update思路也即关闭正在运行的Pod再创建新的Pod。所以，缩容过程中可能会出现部分服务暂时中断的现象，jmeter会出现Error，如果将Pod的”优雅停”时间（默认30s）设置长一点应该能够减少Error出现的几率。</p></blockquote><ul><li>涉及工具：<code>Jmeter</code> <code>Prometheus</code> <code>Grafana</code></li></ul><h2 id="集群高可用测试"><a href="#集群高可用测试" class="headerlink" title="集群高可用测试"></a>集群高可用测试</h2><p>k8s集群高可用其实就是集群各组件的高可用，测试关注点则是集群部分组件甚至节点关闭（如master或node宕机），集群是否还能正常工作，以及业务应用对外提供服务的性能是否还能保持稳定。</p><ul><li>场景一：正在对外提供服务的业务集群突然出现部分机器断网、宕机，或者kubelet等组件停止运行</li><li>测试策略：使用systemctl命令启停相关组件，模拟组件的工作中断；使用docker stop命名停止以静态Pod运行的服务组件，模拟组件的工作终止；使用ifconfig命令启停节点的网卡，模拟网络的中断；直接关闭机器模拟集群节点的突然宕机；同时观察集群应用服务及其管理是否能正常工作，业务运行相关指标是否下降。</li><li>涉及工具：<code>systemd</code> <code>ifconfig</code> <code>docker</code> <code>vcenter</code> <code>Jmeter</code></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>优秀的架构一定是可扩展的，尤其是大规模集群管理这样的底层系统，k8s的扩展能力太强以至于它更像是IaaS和PaaS之间的中间层。以Kubernetes为核心的PaaS平台已在国内外众多企业内实施落地，由于kubernetes的插件化设计，各企业在落地过程中需要解决的网络方案、存储方案、负载均衡方案、监控体系、日志体系等各不相同，从而在性能测试方法上也不尽相同，本文主要介绍了部分性能测试可能需要关注的地方以及相关工具，不够全面系统，内容仅供参考。</p><h2 id="Acknowledgment"><a href="#Acknowledgment" class="headerlink" title="Acknowledgment"></a>Acknowledgment</h2><p>灵雀云的小伙伴们给予了文档参考和技术支持，在此致谢。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560" target="_blank" rel="noopener">Benchmark results of Kubernetes network plugins (CNI) over 10Gbit/s network</a></li><li><a href="https://www.nginx.com/resources/library/container-networking-docker-kubernetes/" target="_blank" rel="noopener">Container Networking: From Docker to Kubernetes</a></li><li><a href="https://elastisys.com/2018/01/25/setting-highly-available-kubernetes-clusters/" target="_blank" rel="noopener">On setting up highly available Kubernetes clusters</a></li><li><a href="https://iperf.fr/iperf-doc.php#3doc" target="_blank" rel="noopener">iperf3 doc</a></li><li><a href="https://linux.die.net/man/1/qperf" target="_blank" rel="noopener">qperf doc</a></li><li><a href="https://kubernetes.io/blog/2015/09/kubernetes-performance-measurements-and/" target="_blank" rel="noopener">Kubernetes Performance Measurements and Roadmap</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文主要介绍kubernetes（以下简称k8s）在性能测试中的主要关注指标以及涉及的辅助测试工具。由于各企业在私有云建设过程中使用的技术标准不尽相同，文中尽可能介绍可能涉及的通用性测试项，由于作者水平有限，以下内容仅供参考，欢迎讨论以及指正。&lt;br&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/categories/kubernetes/"/>
    
      <category term="软件测试" scheme="https://kiddie92.github.io/categories/kubernetes/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="性能测试" scheme="https://kiddie92.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 下基于kubernetes安装部署kubeflow</title>
    <link href="https://kiddie92.github.io/2019/01/05/CentOS-%E4%B8%8B%E5%9F%BA%E4%BA%8Ekubernetes%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2kubeflow/"/>
    <id>https://kiddie92.github.io/2019/01/05/CentOS-下基于kubernetes安装部署kubeflow/</id>
    <published>2019-01-05T05:45:00.000Z</published>
    <updated>2019-03-02T15:48:05.610Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>小目标：基于前期搭建的<a href="https://kiddie92.github.io/2018/12/26/CentOS%E4%B8%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Kubernetes%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/">kubernetes集群</a>，部署kubeflow，由于涉及到google的docker镜像，只好设置国外代理了<br><a id="more"></a> </p><h3 id="下载安装包："><a href="#下载安装包：" class="headerlink" title="下载安装包："></a>下载安装包：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/ksonnet/ksonnet/releases/download/v0.13.1/ks_0.13.1_linux_amd64.tar.gz</span><br><span class="line">wget https://github.com/kubeflow/kubeflow/archive/v0.4.0-rc.3.tar.gz  <span class="comment">#2019.1.4 最新版本v0.4.0-rc.3</span></span><br></pre></td></tr></table></figure></blockquote><p>将下载好的安装包解压并归档</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -vxf ks_0.13.1_linux_amd64.tar.gz</span><br><span class="line">tar -vxf v0.4.0-rc.3.tar.gz</span><br><span class="line">mkdir kubeflow-ks</span><br><span class="line">cp -r kubeflow-0.4.0-rc.3 kubeflow-ks</span><br><span class="line">cp -r ks_0.13.1_linux_amd64 kubeflow-ks</span><br></pre></td></tr></table></figure><h3 id="安装ksonnet"><a href="#安装ksonnet" class="headerlink" title="安装ksonnet"></a>安装ksonnet</h3><p>ks是一个可执行文件，直接拷贝到系统可执行目录下就OK了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> kubeflow-ks/ks_0.13.1_linux_amd64</span><br><span class="line">cp ks /usr/bin</span><br></pre></td></tr></table></figure><h3 id="安装部署kubeflow"><a href="#安装部署kubeflow" class="headerlink" title="安装部署kubeflow"></a>安装部署kubeflow</h3><p>首先定义一些临时的环境变量，安装的时候会方便很多，因为安装脚本也是需要用到这些变量的</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBEFLOW_SRC=/your/path/to/kubeflow-0.4.0-rc.3</span><br><span class="line"><span class="built_in">export</span> KFAPP=kubeflowconfig  <span class="comment">#随意命名</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>注意</strong>：KFAPP必须是将要存放配置文件的<strong>目录名称</strong>，不可以是目录的路径，否则会报以下错误：<code>&lt;name&gt; should be the name for the deployment; not a path</code></p></blockquote><p>安装部署只需要三个命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$&#123;KUBEFLOW_SRC&#125;</span>/scripts/kfctl.sh init <span class="variable">$&#123;KFAPP&#125;</span> --platform none  <span class="comment"># none 也可以是minikube等</span></span><br><span class="line"><span class="variable">$&#123;KUBEFLOW_SRC&#125;</span>/scripts/kfctl.sh generate k8s</span><br><span class="line"><span class="variable">$&#123;KUBEFLOW_SRC&#125;</span>/scripts/kfctl.sh apply k8s</span><br></pre></td></tr></table></figure></p><p>查看是否运行好了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kubeflow  <span class="comment">#理论上gcr.io的镜像pull不下来</span></span><br><span class="line"><span class="comment"># 查看ImagePullBackOff等问题</span></span><br><span class="line">kubectl describe pod scheduledworkflow -n kubeflow </span><br><span class="line"><span class="comment">#提示: Failed to pull image "gcr.io/ml-pipeline/scheduledworkflow:0.1.6"</span></span><br></pre></td></tr></table></figure></p><p>所以这里需要代理了.. 设置国外代理的方法比较多，我这里使用的是VPS的方式。</p><h3 id="想要删除-or-重新部署？"><a href="#想要删除-or-重新部署？" class="headerlink" title="想要删除 or 重新部署？"></a>想要删除 or 重新部署？</h3><p>直接删除kubeflow这个namespace和之前放置配置文件的文件夹就OK了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete ns kubeflow</span><br><span class="line">kubectl delete crd tfjobs.kubeflow.org  <span class="comment"># crd 不删除也行</span></span><br><span class="line">rm -rf <span class="variable">$&#123;KFAPP&#125;</span></span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://www.kubeflow.org/docs/started/getting-started/#kubeflow-quick-start" target="_blank" rel="noopener">官方文档</a></li><li><a href="https://www.katacoda.com/kubeflow/scenarios/deploying-kubeflow-with-ksonnet" target="_blank" rel="noopener">katacoda</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;小目标：基于前期搭建的&lt;a href=&quot;https://kiddie92.github.io/2018/12/26/CentOS%E4%B8%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Kubernetes%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/&quot;&gt;kubernetes集群&lt;/a&gt;，部署kubeflow，由于涉及到google的docker镜像，只好设置国外代理了&lt;br&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/categories/kubernetes/"/>
    
      <category term="kubeflow" scheme="https://kiddie92.github.io/categories/kubernetes/kubeflow/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="kubeflow" scheme="https://kiddie92.github.io/tags/kubeflow/"/>
    
      <category term="分布式机器学习" scheme="https://kiddie92.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>微观经济学--比较优势</title>
    <link href="https://kiddie92.github.io/2019/01/03/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E6%AF%94%E8%BE%83%E4%BC%98%E5%8A%BF/"/>
    <id>https://kiddie92.github.io/2019/01/03/微观经济学-比较优势/</id>
    <published>2019-01-03T15:05:59.000Z</published>
    <updated>2019-03-03T09:13:31.512Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>曼昆 《经济学原理》微观经济学分册学习<br>小目标：说清楚绝对优势和比较优势，以及其与中美贸易战之间的关系<br><a id="more"></a> </p><h3 id="一、绝对优势"><a href="#一、绝对优势" class="headerlink" title="一、绝对优势"></a>一、绝对优势</h3><p>假设，Frank和Lee都会两个技能“摊煎饼”，“做馒头”，显然，不同的人擅长做的事情也不一样，我们用“效率”来衡量这两个人分别做两件事情的擅长程度。但是，影响”效率”的因素太多了，比如：原材料的节约程度，产品最终的受欢迎程度….，为了简化衡量标准，我们假设他们做出的“煎饼”和“馒头”所付出的成本仅仅在制作时间上有差异。如果以单位时间作为单位成本的话，我们假设Frank一个小时平均可以摊6个煎饼<strong>或者</strong>做10个馒头，Lee一个小时平均可以做4个煎饼<strong>或者</strong>15个馒头，按照单位成本来计算（min/个）整理成下表则为：</p></blockquote><div class="table-container"><table><thead><tr><th>生产成本（min/个）</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>煎饼</td><td>10</td><td>15</td></tr><tr><td>馒头</td><td>6</td><td>4</td></tr></tbody></table></div><p>显然，成本越小，表明其优势越大，比如Frank摊煎饼的成本就比Lee小，而Lee做馒头的成本就比Frank小，这个优势在经济学里面就叫做<strong>绝对优势</strong>，比如，我们可以说，Frank在摊煎饼这项工作上具有<strong>绝对优势</strong>。</p><blockquote><p>那就有人想说，干脆让Frank只做煎饼，Lee只做馒头好了，这样的话生产出来的煎饼和馒头的总和在单位时间内就会比他们分别生产煎饼和馒头要多。</p></blockquote><p>可是，要达成这个目的还需要一个协议，Frank和Lee可以仅生产自己有绝对优势的产品，并且可以相互交换，而相互交换的规则则是<strong>“一个煎饼可以换10/6到15/4个馒头之间”，</strong>也就是定价规则。</p><p>因为，对于Frank来说一个煎饼至少得换10/6个馒头吧，不然还不如他自己做馒头呢，而对于Lee来说，一个煎饼最多可以换15/4个馒头，不然他就亏了。所以，煎饼和馒头的兑换比率应该是<strong>ratio</strong>（ 10/6=1.67 &lt; ratio &lt; 15/4=3.75）</p><p>此外，从<strong>“机会成本（opportunity cost）”</strong>的角度阐述这个问题也是一样的：</p><blockquote><p>机会成本，生产A产品而不生产B产品，所舍弃的成本；这里Frank只生产煎饼，那么为了生产煎饼而放弃生产的馒头就是他的机会成本</p></blockquote><div class="table-container"><table><thead><tr><th>-</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>1个煎饼的机会成本</td><td>10/6个馒头</td><td>15/4个馒头</td></tr><tr><td>1个馒头的机会成本</td><td>6/10个煎饼</td><td>4/15个煎饼</td></tr></tbody></table></div><p>定价的规则就是保证在双方的<strong>机会成本之间</strong>。</p><h3 id="二、比较优势"><a href="#二、比较优势" class="headerlink" title="二、比较优势"></a>二、比较优势</h3><p><strong>专业化和贸易的好处不是基于绝对优势，而是基于比较优势。</strong>假设，Frank比较厉害，无论是摊煎饼还是做馒头都比Lee快：</p><div class="table-container"><table><thead><tr><th>生产成本（min/个）</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>煎饼</td><td>10</td><td>15</td></tr><tr><td>馒头</td><td>5</td><td>6</td></tr></tbody></table></div><p>这时双方的<strong>机会成本</strong>为：</p><div class="table-container"><table><thead><tr><th>-</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>1个煎饼的机会成本</td><td>12/6个馒头</td><td>10/4个馒头</td></tr><tr><td>1个馒头的机会成本</td><td>6/12个煎饼</td><td>4/10个煎饼</td></tr></tbody></table></div><p>显然，如果一方在生产一种产品的机会成本比较低时，那他在生产另一种产品的机会成本就会比较高，因为两种产品的机会成本互为倒数。所以，Frank和Lee之间依然可以贸易，这时Frank生产他的机会成本比较小的煎饼，Lee生产他机会成本比较小的馒头。而交易的价格，也就是兑换的比率一就是在两个机会成本之间，12/6=2 &lt; 煎饼/馒头 &lt; 10/4=2.5 个。</p><blockquote><p>简单来说就是，Frank即使两个工作都很擅长，但他肯定也还是有更擅长的工作（擅长中的擅长^_^），他只要做他最擅长的那一个就OK了；而贸易则可以使整体的生产效率提高，从而提高大家的物质生活水平。</p></blockquote><p>不过理论上，这里可以有个小问题：如果Frank和Lee的机会成本一样，那还要不要贸易啊？？？</p><h3 id="三、联想"><a href="#三、联想" class="headerlink" title="三、联想"></a>三、联想</h3><ol><li><p><strong>人类为什么需要贸易</strong><br>贸易使经济生产效率提高，物质生活水平自然也会更高。有了贸易，自然就需要保护贸易正常进行的组织（不能偷、不能抢别人的，只能换），于是政府和国家的概念和角色就出现了，<strong>注意</strong>这只是理想状态下。</p></li><li><p><strong>为什么会有中美贸易战</strong><br>美国各方面都领先于中国，拥有绝对优势，但是其在生产服装、玩具、制造组装手机等方面的机会成本比中国高，而在生产高科技产品、农业产品的机会成本比中国低，所以中国向美国出口服装、玩具等，并从美国进口高科技产品、农产品等。可是，美国发现每年的中美贸易都出现逆差（对中国来说就是顺差），也就是说每年都有大量美元流入中国（中国美元的外汇储备之前一直比较高，2007年还搞了一个”中投”专门”研究”怎么花这笔钱…），为了扭转事态，美国开始加征关税（减少美国国内对中国的进口），中国当然不愿意看到这些，虽然人民币与美元并不挂钩，但是外汇储备对于中国政府来说仍然至关重要，于是中美就发生了trade war. 事实上，贸易往来总会出现不平衡的状况，一百多年前的鸦片战争也正是由于中英贸易存在类似的问题而导致的。</p></li></ol><blockquote><p>根据中国海关总署统计，美国对中国的贸易逆差从2001年的281亿美元增长到2017年2758亿美元。中美贸易总额已经从1992年的330亿美元发展到2017年的5837亿美元。由于统计口径差距，美国商务部统计数据，对中国逆差从2001年830亿美元增长到2017年3752亿美元，贸易总额增长到2017年6360亿美元。（<em>维基百科</em>）</p></blockquote><ol><li><strong>人尽其才，才尽其用的使命</strong><br>比较优势告诉我们，每个人去做自己最擅长的事情，就会使经济蛋糕变大，这就让人联想到<strong>人尽其才，物尽其用</strong>这句古话了。但是这都是理论上的，现实的世界不存在真正的自由贸易，也不会存在<strong>人尽其才，物尽其用</strong>这种理想状态。</li></ol><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li>经济学原理 — 微观经济学分册，曼昆</li><li><a href="https://www.youtube.com/watch?v=nwLqo83iqks&amp;t=0s&amp;index=3&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw" target="_blank" rel="noopener">李永乐老师视频</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;曼昆 《经济学原理》微观经济学分册学习&lt;br&gt;小目标：说清楚绝对优势和比较优势，以及其与中美贸易战之间的关系&lt;br&gt;
    
    </summary>
    
      <category term="经济学原理" scheme="https://kiddie92.github.io/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
    
    
      <category term="金融知识" scheme="https://kiddie92.github.io/tags/%E9%87%91%E8%9E%8D%E7%9F%A5%E8%AF%86/"/>
    
      <category term="比较优势" scheme="https://kiddie92.github.io/tags/%E6%AF%94%E8%BE%83%E4%BC%98%E5%8A%BF/"/>
    
  </entry>
  
  <entry>
    <title>CentOS上安装部署Kubernetes注意事项</title>
    <link href="https://kiddie92.github.io/2018/12/26/CentOS%E4%B8%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Kubernetes%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
    <id>https://kiddie92.github.io/2018/12/26/CentOS上安装部署Kubernetes注意事项/</id>
    <published>2018-12-26T05:41:15.000Z</published>
    <updated>2019-03-02T15:48:13.496Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>小目标：不翻墙的情况下，使用kubeadm安装部署Kubernetes集群（非高可用），1个master、2个node<br><a id="more"></a></p><h3 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h3><h4 id="关于机器："><a href="#关于机器：" class="headerlink" title="关于机器："></a>关于机器：</h4><ol><li>准备的主机可以连接外网，对于私有云场景，需要做好前期准备（例如：配置yum源、镜像仓库源等）</li><li>满足安装 Docker 项目所需的要求，比如 64 位的 Linux 操作系统、3.10 及以上的内核版本；</li><li>x86 或者 ARM 架构均可；</li><li>机器之间网络互通，这是将来容器之间网络互通的前提；</li></ol></blockquote><h4 id="关于Linux操作系统："><a href="#关于Linux操作系统：" class="headerlink" title="关于Linux操作系统："></a>关于Linux操作系统：</h4><ol><li>建议开启<code>root</code>权限（我这里是已经开启了root权限，以root用户登录节点）</li><li>修改各节点的hostname：打开终端输入<code>hostnamectl set-hostname master8088</code>，这里的命名需要有一定的<a href="https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md" target="_blank" rel="noopener">规范</a><em>重启后hostname失效</em></li><li>建议：<code>systemd</code>不低于234，否则执行 df 命令的时候，<strong>据说</strong>会有一定几率卡死，使用<code>systemctl --version</code>查看版本信息</li><li>建议关闭<code>swap</code>输入<code>swapoff -a</code>：如果不满足，<strong>据说</strong>系统会有一定几率出现 io 飙升，造成 docker 卡死</li><li>关闭防火墙，终端输入<code>systemctl stop firewalld &amp;&amp; systemctl disable firewalld</code></li><li>关闭selinux:<code>vi  /etc/selinux/config</code> 设置<strong>SELINUX=disabled</strong></li><li><p>修改hosts文件，<code>vi /etc/hosts</code> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.0.1 node2   <span class="comment"># ip+hostname格式</span></span><br><span class="line">192.168.0.2 node1   <span class="comment"># ip每个节点的ip地址，可以使用ifconfig命令查看</span></span><br><span class="line">192.168.0.3 master</span><br></pre></td></tr></table></figure></li><li><p>添加相关设置<code>vim /etc/sysctl.conf</code>需要修改的内容如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">vm.max_map_count=262144</span><br></pre></td></tr></table></figure></li></ol><p>输入<code>sysctl -p</code>使设置生效</p><ol><li>设置三台机器之间可以使用<code>ssh+hostname</code>互相登录，</li></ol><blockquote><p><strong>节点之间无密码互相访问设置：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys</span><br><span class="line"><span class="comment">#将每个节点的id_rsa.pub写入每个节点的authorized_keys</span></span><br><span class="line"><span class="comment">#最后生成的authorized_keys复制到集群中的每一台计算机的.ssh目录下，覆盖掉之前的authorized_keys</span></span><br></pre></td></tr></table></figure></p></blockquote><h3 id="二、安装部署Kubernetes"><a href="#二、安装部署Kubernetes" class="headerlink" title="二、安装部署Kubernetes"></a>二、安装部署Kubernetes</h3><blockquote><p>安装之前需要配置一下<code>kubernetes</code>这个yum源，否则下面的命令可能失效</p></blockquote><ol><li>在每个节点上安装kubeadm、kubelet、kubectl，这里选择的是CentOS系统，所以使用命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure></li></ol><p><strong>安装的kubeadm、kubectl、kubelet默认都是最新的版本（1.13版本），也可以指定版本，比如目前是stable版的1.11</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看版本</span></span><br><span class="line">kubeadm version</span><br><span class="line">kubectl version</span><br><span class="line">kubelet --version</span><br><span class="line"><span class="comment"># 下载安装指定版本</span></span><br><span class="line">yum list --showduplicates | grep <span class="string">'kubeadm'</span> <span class="comment">#查看有哪些版本</span></span><br><span class="line">yum install -y kubeadm-1.10.5-0.x86_64 <span class="comment"># 安装指定版本，这里选择的是1.10.5</span></span><br></pre></td></tr></table></figure></p><ol><li>部署master节点：<br>这里需要注意的是，直接使用<code>kubeadm init</code>会发现需要的镜像获取不了，因为大陆被墙了.. 不过可以指定镜像仓库源，这里选择阿里云杭州的源（感谢^_^）：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubernetes-version=v1.13.1指定了安装1.13.1版本的kubernetes</span></span><br><span class="line"><span class="comment"># pod-network-cidr是为了后续安装calico这样的网络插件</span></span><br><span class="line">kubeadm init --kubernetes-version=v1.13.1 --pod-network-cidr=192.168.0.0/16 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>可能出现kubelet和kubeapi-server失联的情况，注意排查<br>master部署完成后，会生成一个指令：<code>kubeadm join ....</code>这个是后续加入node用的<br>kubeadm还会在部署好master后，最后提示我们第一次使用kubernetes集群需要的配置命令：<code>mkdir... sudo cp ... sudo chown...</code></p></blockquote><ol><li><p>部署node节点：参照master部署完毕生成的kubeadm join提示，在每个node上执行以下命令<br><code>kubeadm join ${master_ip}:6443 --token ${kubeadm_token} --discovery-token-ca-cert-hash ${hash_value}</code><br>使用<code>kubectl get no</code>查看node是否已经添加，并且处于Ready状态，由于网络插件还没安装，应该不会Ready</p></li><li><p>安装CNI插件calico</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml</span><br><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br></pre></td></tr></table></figure></li><li><p>删除master上的Taint标签，使之也可以被调度<br><code>kubectl taint nodes --all node-role.kubernetes.io/master-</code></p></li></ol><blockquote><p>至此，一个kubernetes集群已经可以使用了，接下来还可以部署Dashboard、CSI插件</p></blockquote><h3 id="三、问题记录"><a href="#三、问题记录" class="headerlink" title="三、问题记录"></a>三、问题记录</h3><p><strong>Q1：kubeadm一次运行没有通过，但是部分static Pod已经启动？</strong><br>打开终端输入：<code>kubeadm reset</code>，即可重置集群，修改必要的参数后，再次使用<code>kubeadm init ...</code>命令部署K8s集群。</p><p><strong>Q2： 需要事先下载好国内镜像源吗？</strong><br>不需要</p><blockquote><p>由于<code>kubeadm</code>在部署<code>K8s</code>集群时，需要从<code>k8s.gcr.io</code>上拉取镜像，但是大陆需要翻墙，所以有些博客里提出先下载好一样的镜像再修改tag以此绕开从国外拉取镜像的问题，但实际上没有必要这样做；即便如此，还是记录一下吧…</p></blockquote><p>镜像下载脚本<code>image_download.sh</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span>=registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line"></span><br><span class="line">images=(</span><br><span class="line"></span><br><span class="line">kube-apiserver:v1.13.1</span><br><span class="line"></span><br><span class="line">kube-controller-manager:v1.13.1</span><br><span class="line"></span><br><span class="line">kube-scheduler:v1.13.1</span><br><span class="line"></span><br><span class="line">kube-proxy:v1.13.1</span><br><span class="line"></span><br><span class="line">pause:3.1</span><br><span class="line"></span><br><span class="line">etcd:3.2.24</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">coredns:1.2.6</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> imageName <span class="keyword">in</span> <span class="variable">$&#123;images[@]&#125;</span> ; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$imageName</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"------------------------------------"</span></span><br><span class="line">    docker pull <span class="variable">$source</span>/<span class="variable">$imageName</span></span><br><span class="line">    docker tag <span class="variable">$source</span>/<span class="variable">$imageName</span> k8s.gcr.io/<span class="variable">$imageName</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>四、参考资料</p><ol><li><a href="https://time.geekbang.org/column/article/39724" target="_blank" rel="noopener">极客时间-张磊-深入剖析Kubernetes</a></li><li><a href="https://github.com/kubernetes/kubeadm" target="_blank" rel="noopener">kubeadm</a></li><li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">Creating a single master cluster with kubeadm</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;小目标：不翻墙的情况下，使用kubeadm安装部署Kubernetes集群（非高可用），1个master、2个node&lt;br&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/categories/kubernetes/"/>
    
      <category term="Linux软件安装" scheme="https://kiddie92.github.io/categories/kubernetes/Linux%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="kubeadm" scheme="https://kiddie92.github.io/tags/kubeadm/"/>
    
  </entry>
  
  <entry>
    <title>图片识别app从keras+flask代码到kubernetes部署</title>
    <link href="https://kiddie92.github.io/2018/12/06/%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%ABapp%E4%BB%8Ekeras-flask%E4%BB%A3%E7%A0%81%E5%88%B0kubernetes%E9%83%A8%E7%BD%B2/"/>
    <id>https://kiddie92.github.io/2018/12/06/图片识别app从keras-flask代码到kubernetes部署/</id>
    <published>2018-12-06T15:03:03.000Z</published>
    <updated>2019-03-02T15:48:55.320Z</updated>
    
    <content type="html"><![CDATA[<p>使用python flask 以及 keras建立一个简单的image recognition的工具,最后使用docker和kubernetes将应用容器化部署在PaaS平台上对外提供服务。<br><a id="more"></a> </p><h1 id="机器学习-kubernetes"><a href="#机器学习-kubernetes" class="headerlink" title="机器学习+kubernetes"></a>机器学习+kubernetes</h1><blockquote><p>使用python flask 以及 keras建立一个简单的image recognition的工具，主要参考了<a href="https://medium.com/analytics-vidhya/deploy-your-first-deep-learning-model-on-kubernetes-with-python-keras-flask-and-docker-575dc07d9e76" target="_blank" rel="noopener">这里</a><br>觉得有点意思就实现了一下，里面涉及到python编程、docker、k8s的使用，image recognition模型不涉及训练，使用的是开源模型，下次自己train个模型出来看看效果^_^。<br>代码托管在<a href="https://github.com/kiddie92/keras-app" target="_blank" rel="noopener">github</a>。</p></blockquote><h2 id="测试一下代码是否可用"><a href="#测试一下代码是否可用" class="headerlink" title="测试一下代码是否可用"></a>测试一下代码是否可用</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖模块，南七技校的pip源比较好用</span></span><br><span class="line">pip install -r requirements.txt -i https://mirrors.ustc.edu.cn/pypi/web/simple/ </span><br><span class="line"><span class="comment"># 运行代码</span></span><br><span class="line">python app.py  </span><br><span class="line"><span class="comment"># 找个图片辨认一下</span></span><br><span class="line">curl -X POST -F image=@dog.jpg <span class="string">'http://127.0.0.1:2400/predict</span></span><br></pre></td></tr></table></figure><blockquote><p>首次运行代码后，需要等待一段时间，因为要下载图片识别的模型</p></blockquote><h2 id="制作docker镜像"><a href="#制作docker镜像" class="headerlink" title="制作docker镜像"></a>制作docker镜像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker build -t keras-app:latest .</span><br></pre></td></tr></table></figure><p>出现如下提示则镜像制作成功<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Successfully built pyyaml gast absl-py termcolor MarkupSafe</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Removing intermediate container 3a21aa77c06c</span><br><span class="line">Successfully built fc03d48b4096</span><br></pre></td></tr></table></figure></p><p>查看一下镜像信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[conan@localhost deeplearning_flask]$ sudo docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">keras-app           latest              fc03d48b4096        43 minutes ago      1.7 GB</span><br></pre></td></tr></table></figure></p><blockquote><p>Size 1.7G，Dockerfile中可以修改python基础镜像为pythom3.6-slim进行瘦身.</p></blockquote><h2 id="测试docker镜像"><a href="#测试docker镜像" class="headerlink" title="测试docker镜像"></a>测试docker镜像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行</span></span><br><span class="line">sudo docker run --name image-recon -d -p 2400:2400 keras-app:latest</span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">curl -X POST -F image=@dog.jpg <span class="string">'http://127.0.0.1:2400/predict'</span></span><br><span class="line"><span class="comment"># 打包带走</span></span><br><span class="line">sudo docker save keras-app:latest &gt; keras-app.tar</span><br></pre></td></tr></table></figure><h2 id="在kubernetes上调度"><a href="#在kubernetes上调度" class="headerlink" title="在kubernetes上调度"></a>在kubernetes上调度</h2><p>使用k8s集群部署应用，推荐使用yaml文件，前置条件是把刚刚的镜像push到k8s使用的镜像仓库中<br>这里使用简单一点的deployment方式来部署<code>imagerecon_deployment_test_for_fun.yaml</code><br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">imagerecon-deployment</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">imagerecon</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">imagerecon</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">imagerecon</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">imagerecon</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">keras-app:latest</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">2400</span></span><br></pre></td></tr></table></figure></p><p>部署<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f imagerecon_deployment_test_for_fun.yaml</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get pods --show-labels</span><br></pre></td></tr></table></figure></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://medium.com/analytics-vidhya/deploy-your-first-deep-learning-model-on-kubernetes-with-python-keras-flask-and-docker-575dc07d9e76" target="_blank" rel="noopener">https://medium.com/analytics-vidhya/deploy-your-first-deep-learning-model-on-kubernetes-with-python-keras-flask-and-docker-575dc07d9e76</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用python flask 以及 keras建立一个简单的image recognition的工具,最后使用docker和kubernetes将应用容器化部署在PaaS平台上对外提供服务。&lt;br&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/categories/kubernetes/"/>
    
      <category term="Machine Learning" scheme="https://kiddie92.github.io/categories/kubernetes/Machine-Learning/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="python" scheme="https://kiddie92.github.io/tags/python/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="flask" scheme="https://kiddie92.github.io/tags/flask/"/>
    
      <category term="keras" scheme="https://kiddie92.github.io/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>囚徒困境回顾</title>
    <link href="https://kiddie92.github.io/2018/11/07/%E5%9B%9A%E5%BE%92%E5%9B%B0%E5%A2%83%E5%9B%9E%E9%A1%BE/"/>
    <id>https://kiddie92.github.io/2018/11/07/囚徒困境回顾/</id>
    <published>2018-11-07T12:45:41.000Z</published>
    <updated>2019-03-02T15:48:48.782Z</updated>
    
    <content type="html"><![CDATA[<p>甲囚犯和乙囚犯分别被审讯</p><blockquote><p>甲和乙都选择合作（拒不认罪或者不指认乙），那么他们会分别被判处3年；甲选择背叛（指认乙）而乙选择合作，则甲将会被无罪释放，而乙则被判处5年；甲和乙都选择背叛（相互指认）则各获刑1年<br><a id="more"></a><br>审讯的结果是，<br>|  甲\判刑时间\乙 |  合作   |  背叛   |<br>|      :-:      |  :-:  | :-:  |<br>|   <strong>合作</strong>        |  3, 3      | 0, 5   |<br>|   <strong>背叛</strong>        |  5, 0      | 1, 1   |</p></blockquote><p>那么针对以上的规则，甲理性思考会依据<strong>对方的选择</strong>来判断自己的处境：</p><ol><li>乙背叛：那么甲选择合作就会被判5年，选择背叛就会被判1年；</li><li>乙合作：那么甲选择合作就会被判3年，选择背叛就会被判0年；</li></ol><p>显然，无论乙怎么选，甲选择背叛都是最优解</p><p>那么就此判断在竞争中，选择背叛就一定是对自己有利的吗？不一定吧…</p><p>我们改一下游戏规则（<strong>规则二</strong>）：</p><p>审讯的结果是，<br>| 甲\判刑时间\乙    |      合作     |    背叛<br>| :—: | :—: | :—: |<br>| <strong>合作</strong> |  0，0    | 0, 10  |<br>| <strong>背叛</strong> |    10, 0    | 5, 5 |</p><p>那么甲再次理性思考同样会依据对方的选择来判断自己的处境：</p><ol><li>乙背叛：那么甲选择合作就是被判10年，选择背叛就是被判5年；</li><li>乙合作：那么甲选择合作就是被判0年，选择背叛也是被判0年；</li></ol><p>显然，无论乙怎么选，甲选择背叛还是是最优解</p><p>再次改一下规则（<strong>规则三</strong>）：</p><p>审讯的结果是，<br>|    甲\判刑时间\乙 |合作|    背叛|<br>|:-:|:-:|:-:|<br>|合作    |0，0    |0, 10|<br>|背叛    |10, 0    |15, 15|</p><p>那么甲再次理性思考还是会依据对方的选择来判断自己的处境：</p><ol><li>乙背叛：那么甲选择合作就是被判10年，选择背叛就是被判15年；</li><li>乙合作：那么甲选择合作就是被判0年，选择背叛也是被判0年；</li></ol><p>显然，无论乙怎么选，甲选择背叛就<code>不再是最优解</code>了</p><p>所以说<strong>游戏规则</strong>会改变囚徒困境的结果…？</p><h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>假设第三条规则不那么合理，那么什么样的规则才是合理的呢？<br>市场行为中有多方参与，比简单的两者博弈要复杂很多… 即使如此，囚徒困境的模型还是有一些指导意义的</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;甲囚犯和乙囚犯分别被审讯&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;甲和乙都选择合作（拒不认罪或者不指认乙），那么他们会分别被判处3年；甲选择背叛（指认乙）而乙选择合作，则甲将会被无罪释放，而乙则被判处5年；甲和乙都选择背叛（相互指认）则各获刑1年&lt;br&gt;
    
    </summary>
    
      <category term="经济学原理" scheme="https://kiddie92.github.io/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
    
    
      <category term="数学" scheme="https://kiddie92.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="囚徒困境" scheme="https://kiddie92.github.io/tags/%E5%9B%9A%E5%BE%92%E5%9B%B0%E5%A2%83/"/>
    
      <category term="金融知识" scheme="https://kiddie92.github.io/tags/%E9%87%91%E8%9E%8D%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>Django安装与使用</title>
    <link href="https://kiddie92.github.io/2018/08/30/Django%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    <id>https://kiddie92.github.io/2018/08/30/Django安装与使用/</id>
    <published>2018-08-30T08:41:02.000Z</published>
    <updated>2019-03-02T02:36:43.709Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、Django简介"><a href="#一、Django简介" class="headerlink" title="一、Django简介"></a>一、Django简介</h4><p>Django是一个开源的<strong>web开发框架</strong>，该框架使用的是python语言。其集成了所有web开发需要的组件，开发测试速度极快，所以又被称为<code>all-in-one</code>类型的web开发框架。此外，Django还有<code>Secure</code>、<code>Scalable</code>、<code>Maintainable</code>等特性。Django于2017年发布2.0版本。<br><a id="more"></a> </p><blockquote><p><a href="https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django/Introduction" target="_blank" rel="noopener">这里</a>列出了很多Django的特点/优点；<br>Django早在2003-2005年间被一个新闻网站的开发团队开发出来，于<strong>2005年7月开源</strong>，并命名为Django；可以推测出，Django在做<strong>文本型的网站开发</strong>上是有优势的，比如：博客、图书馆等。</p></blockquote><h4 id="二、Django安装"><a href="#二、Django安装" class="headerlink" title="二、Django安装"></a>二、Django安装</h4><h5 id="Step1-安装python"><a href="#Step1-安装python" class="headerlink" title="Step1.安装python"></a>Step1.安装python</h5><p>安装python会涉及版本的选择问题，这里我选择的是<strong>python3</strong>，因为<code>python2</code>和<code>python3</code>的语法略有不同，<code>python3</code>没有做向下兼容，而<strong>python2又将不再被官方更新维护了</strong>，所以对于我这种新手还是学学python3吧^_^。</p><blockquote><p>python的<a href="https://www.python.org/" target="_blank" rel="noopener">官方网站</a>提供了多种平台和版本的下载</p></blockquote><p>对于python3的安装，我选择的是<code>anaconda</code>，<a href="https://anaconda.org/" target="_blank" rel="noopener"><strong>anaconda</strong></a>是一个开源的python发行版，里面包含很多常用模块，安装这个省去了后续很多模块安装的麻烦；当然，如果想多了解<code>python</code>也可以使用python安装包进行安装。</p><p><strong>anaconda安装过程</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://repo.continuum.io/archive/Anaconda3-5.2.0-Linux-x86_64.sh    <span class="comment">#在官网下载可以下3.6的版本（2018.08.30）</span></span><br><span class="line">sh Anaconda3-5.2.0-Linux-x86_64.sh   <span class="comment">#sh可以改为bash，安装的最后会让你选择安装微软的一款IDE产品，可以选择no</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc  <span class="comment">#刷新一下环境变量</span></span><br></pre></td></tr></table></figure></p><p>输入命令测试一下，出现<code>Anaconda，Inc</code>，成功<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">zhuz@qwerty:~$ python3</span><br><span class="line">Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) </span><br><span class="line">[GCC 7.2.0] on linux</span><br><span class="line">Type <span class="string">"help"</span>, <span class="string">"copyright"</span>, <span class="string">"credits"</span> or <span class="string">"license"</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p><p>windows下安装相对简单，不再赘述。</p><blockquote><p><strong>注意</strong><br>1.<code>anaconda</code>自带了<code>Jupyter</code>和<code>Spyder</code>，前者是notebook，后者是IDE，都挺好用的；<br>2.<code>Linux</code>自带了<code>python</code>，如果自带的是<code>python2.7</code>，也可以考虑安装一个<code>python3</code>或者<code>anaconda</code>，但是需要解决一下版本管理问题；<br>3.<code>windows</code>系统下，需要在安装好<code>python</code>后添加路径至环境变量，这样就可以在命令行内使用了</p></blockquote><h5 id="Step2-安装Django模块"><a href="#Step2-安装Django模块" class="headerlink" title="Step2.安装Django模块"></a>Step2.安装Django模块</h5><ul><li>2.1.使用pip或conda安装<br>pip和conda安装方法是一样的<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install django   <span class="comment">#pip是python的安装包管理工具,类似于yum和Centos的关系</span></span><br><span class="line">conda install django <span class="comment">#conda是anaconda的安装包管理工具</span></span><br></pre></td></tr></table></figure></li></ul><p>如果使用pip3安装的时候提示pip3版本过低，需要先更新pip3的版本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --upgrade pip  <span class="comment">#注意不是pip3 install --upgrade pip3</span></span><br></pre></td></tr></table></figure></p><ul><li>2.2.使用pycharm安装<br>pycharm是一款IDE，由捷克公司JetBrains开发，也是python的主流IDE，其内置了很多功能，使用方便。打开pycharm，依次点击<code>file-&gt;settings</code>，出现如下界面，点击<code>+</code>号按钮，搜索框输入<code>django</code>，选中出现的模块包，右侧便会出现相应的模块信息，接下来点击<code>Install Package</code>即可，如下图所示:<br><img src="https://upload-images.jianshu.io/upload_images/13272578-1a3d10c7177be5fd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="Django的pycharm安装"></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/13272578-f3c76b7dc3af7666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="Django的pycharm安装2"></p><blockquote><p><strong>注意</strong><br>1.<code>windows</code>系统下，需要在安装好<strong>Django</strong>后添加环境变量<br>2.如果使用的是pycharm安装Django，则需要另外添加<code>anaconda/pkgs/django-2.0.5-py36hd476221_0/Scripts</code>到环境变量，这样比较麻烦，不如用<code>conda</code>来安装；<br>3.conda只能安装python的<strong>官方包</strong></p></blockquote><ul><li>2.3.添加环境变量<br>Linux下已经自动添加了环境变量；<strong>windows10</strong>下添加环境变量的方法<code>此电脑-&gt;右键属性-&gt;高级系统设置-&gt;高级-&gt;环境变量-&gt;用户变量中双击Path-&gt;新建</code>如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/13272578-9e81c247a5ca0902.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="添加环境变量"></li></ul><p>图中红色矩形框即为Anaconda在本机上的路径，这里需要添加上面的3个路径</p><h4 id="三、Django实践"><a href="#三、Django实践" class="headerlink" title="三、Django实践"></a>三、Django实践</h4><p>这里使用Django创建一个简单的web项目，一方面是学习一下Django的框架，另一方面测试一下Django是否可用。</p><h5 id="框架理论"><a href="#框架理论" class="headerlink" title="框架理论"></a>框架理论</h5><p>Django框架是MTV模式（<code>model</code>+<code>template</code>+<code>view</code>），和MVC的模式基本一样，可以参考<a href="http://www.ruanyifeng.com/blog/2007/11/mvc.html" target="_blank" rel="noopener">阮一峰的博客学习一下</a><br>下面直接看图：<br><img src="https://upload-images.jianshu.io/upload_images/13272578-68282a52447d46ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt="basic-django"></p><p>图中显示了<strong>HTTP Request</strong>到<strong>HTTP Response</strong>的过程，首先通过<code>URLS</code>来找到<code>View</code>的路径，而<code>View</code>是由<code>Template</code>（比如一个html模板）+<code>data</code>合并得到的，<code>data</code>是由<code>Model</code>得来（所以<code>Model</code>是用来操作数据库的）。具体说来，Django分为几大块（<strong>摘自书签1</strong>）：</p><ul><li>URLs: While it is possible to process requests from every single URL via a single function, it is much more maintainable to write a separate view function to handle each resource. A URL mapper is used to redirect HTTP requests to the appropriate view based on the request URL. The URL mapper can also match particular patterns of strings or digits that appear in an URL, and pass these to a view function as data.</li><li>View: A view is a request handler function, which receives HTTP requests and returns HTTP responses. Views access the data needed to satisfy requests via models, and delegate the formatting of the response to templates.</li><li>Models: Models are Python objects that define the structure of an application’s data, and provide mechanisms to manage (add, modify, delete) and query records in the database. </li><li>Templates: A template is a text file defining the structure or layout of a file (such as an HTML page), with placeholders used to represent actual content. A view can dynamically create an HTML page using an HTML template, populating it with data from a model. A template can be used to define the structure of any type of file; it doesn’t have to be HTML!</li></ul><h5 id="项目测试"><a href="#项目测试" class="headerlink" title="项目测试"></a>项目测试</h5><p>pycharm新建一个项目：<br>依次点击<code>file-&gt;New Project-&gt;Django-&gt;Location(命名)-&gt;Create</code>即可<br>命令行新建一个项目：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 -m django --version <span class="comment">#先看一下版本</span></span><br><span class="line">django-admin startproject mysite <span class="comment">#创建一个名为mysite的项目</span></span><br></pre></td></tr></table></figure></p><p>看一下项目的目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">zhuz@qwerty:~/Just_test$ tree mysite/</span><br><span class="line">mysite/</span><br><span class="line">├── manage.py</span><br><span class="line">└── mysite</span><br><span class="line">    ├── __init__.py</span><br><span class="line">    ├── settings.py</span><br><span class="line">    ├── urls.py</span><br><span class="line">    └── wsgi.py</span><br><span class="line"></span><br><span class="line">1 directory, 5 files</span><br><span class="line">zhuz@qwerty:~/Just_test$</span><br></pre></td></tr></table></figure></p><p>创建一个app<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 manage.py startapp catalog</span><br></pre></td></tr></table></figure></p><p>看一下app的目录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">zhuz@qwerty:~/Just_test/mysite$ tree catalog/</span><br><span class="line">catalog/</span><br><span class="line">├── admin.py</span><br><span class="line">├── apps.py</span><br><span class="line">├── __init__.py</span><br><span class="line">├── migrations</span><br><span class="line">│   └── __init__.py</span><br><span class="line">├── models.py</span><br><span class="line">├── tests.py</span><br><span class="line">└── views.py</span><br><span class="line"></span><br><span class="line">1 directory, 7 files</span><br></pre></td></tr></table></figure></p><blockquote><p><strong>项目</strong> V.S. <strong>应用</strong><br>应用（<code>app</code>）是一个专门做某件事的网络应用程序——比如博客系统，或者公共记录的数据库，或者简单的投票程序。<br>项目（<code>project</code>）则是一个网站使用的配置和应用的集合。<br>项目可以包含很多个应用；应用可以被很多个项目使用。</p></blockquote><p>在<code>/mysite/mysite/setting.py</code>文件内“注册”一下刚刚创建的app，写入app的Config路径：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INSTALLED_APPS = [</span><br><span class="line">    <span class="string">'polls.apps.PollsConfig'</span>,</span><br><span class="line">    <span class="string">'django.contrib.admin'</span>,</span><br><span class="line">    <span class="string">'django.contrib.auth'</span>,</span><br><span class="line">    <span class="string">'django.contrib.contenttypes'</span>,</span><br><span class="line">    <span class="string">'django.contrib.sessions'</span>,</span><br><span class="line">    <span class="string">'django.contrib.messages'</span>,</span><br><span class="line">    <span class="string">'catalog.apps.CatalogConfig'</span>,  <span class="comment">#CatalogConfig在catalog下的apps.py文件内，这个文件下app的名字已经写好了</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><p>看到<code>setting.py</code>中的<code>DATABASES</code>默认使用的是<code>sqlite3</code>，这里就不用改了；需要改的是时区，还是在<code>setting.py</code>文件内，找到<code>TIME_ZONE</code>修改：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TIME_ZONE = <span class="string">'Asia/Shanghai'</span></span><br></pre></td></tr></table></figure></p><p>接下来写一下URL映射，我们将<code>project</code>中的url导向<code>app</code>自己的url，打开<code>mysite/mysite/urls.py</code>写入url的相对路径：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path, include <span class="comment">#默认没有添加include</span></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">'admin/'</span>, admin.site.urls),  <span class="comment">#原本自带的信息</span></span><br><span class="line">    path(<span class="string">'catalog/'</span>, include(<span class="string">'catalog.urls'</span>)), <span class="comment">#app的相对路径</span></span><br><span class="line">    path(<span class="string">''</span>, RedirectView.as_view(url=<span class="string">'/catalog/'</span>, permanent=<span class="literal">True</span>)),</span><br><span class="line">] + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)</span><br></pre></td></tr></table></figure></p><p>这样一来，我们就需要在<code>catalog</code>这个<code>app</code>下新建一个<code>urls.py</code>文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path </span><br><span class="line"><span class="keyword">from</span> catalog <span class="keyword">import</span> views  <span class="comment">#导入的这两个包以后会用到的</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line"></span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><p>OK啦，接下来可以测试运行一下了<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 manage.py makemigrations</span><br><span class="line">python3 manage.py migrate</span><br></pre></td></tr></table></figure></p><blockquote><p><strong>migrate</strong>：<br>迁移是非常强大的功能，它能让你在开发过程中持续的改变数据库结构而不需要重新删除和创建表 - 它专注于使数据库平滑升级而不会丢失数据。</p></blockquote><p>运行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 manage.py runserver</span><br></pre></td></tr></table></figure></p><p>接下来就可以访问<code>http://127.0.0.1:8000/</code>了，注意<code>Chrome</code>浏览器使用时，需要先检查一下代理，有些同学在翻墙的时候将代理端口改了一下导致不能连接…<br><img src="https://upload-images.jianshu.io/upload_images/13272578-d498278ce76d170d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550" alt="/catalog/urls.py内啥也没写所以什么都没有"><br><img src="https://upload-images.jianshu.io/upload_images/13272578-bf08459346f94e83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550" alt="admin页面还可以看"></p><blockquote><p>生产环境下web搭建一般会需要<code>LEMP(LNMP)</code>或者<code>LAMP</code>环境，即由<code>Nginx</code>或者<code>Apache</code>作为前端提供<code>http服务</code>，<code>mysql</code>提供数据库服务；但<code>Django</code>自带了一个轻量级的<code>webserver</code>进行开发调试，如需调整为生产环境，可以调换自带的<code>webserver</code></p></blockquote><h4 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h4><ul><li>1.Django是一个python的web开发框架，因此需要先搭建好python环境；</li><li>2.可以使用Anaconda安装python环境，需要修改一下系统的环境变量；</li><li>3.windows下使用pycharm添加的Django包需要单独添加环境变量，所以不建议这样安装；</li><li>4.Django自带轻量级webserver，所以无需其他组件即可搭建web app；</li></ul><h4 id="五、书签"><a href="#五、书签" class="headerlink" title="五、书签"></a>五、书签</h4><ol><li><a href="https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django/Models" target="_blank" rel="noopener">Mozilla Django Tutorial</a></li><li><a href="https://docs.djangoproject.com/zh-hans/2.1/" target="_blank" rel="noopener">Django官方中文文档</a></li><li><a href="https://www.zhihu.com/question/35540397" target="_blank" rel="noopener">Django测试与生产环境讨论1</a></li><li><a href="http://blog.51cto.com/wangweiak47/1533445" target="_blank" rel="noopener">Django测试与生产环境讨论2</a></li><li><a href="http://www.ruanyifeng.com/blog/2007/11/mvc.html" target="_blank" rel="noopener">MVC模式</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一、Django简介&quot;&gt;&lt;a href=&quot;#一、Django简介&quot; class=&quot;headerlink&quot; title=&quot;一、Django简介&quot;&gt;&lt;/a&gt;一、Django简介&lt;/h4&gt;&lt;p&gt;Django是一个开源的&lt;strong&gt;web开发框架&lt;/strong&gt;，该框架使用的是python语言。其集成了所有web开发需要的组件，开发测试速度极快，所以又被称为&lt;code&gt;all-in-one&lt;/code&gt;类型的web开发框架。此外，Django还有&lt;code&gt;Secure&lt;/code&gt;、&lt;code&gt;Scalable&lt;/code&gt;、&lt;code&gt;Maintainable&lt;/code&gt;等特性。Django于2017年发布2.0版本。&lt;br&gt;
    
    </summary>
    
      <category term="python" scheme="https://kiddie92.github.io/categories/python/"/>
    
      <category term="Web Framework" scheme="https://kiddie92.github.io/categories/python/Web-Framework/"/>
    
    
      <category term="web 框架" scheme="https://kiddie92.github.io/tags/web-%E6%A1%86%E6%9E%B6/"/>
    
      <category term="python" scheme="https://kiddie92.github.io/tags/python/"/>
    
      <category term="Django" scheme="https://kiddie92.github.io/tags/Django/"/>
    
  </entry>
  
  <entry>
    <title>单机版SuSe搭建Confluence Wiki</title>
    <link href="https://kiddie92.github.io/2018/08/15/%E5%8D%95%E6%9C%BA%E7%89%88SuSe%E6%90%AD%E5%BB%BAConfluence-Wiki/"/>
    <id>https://kiddie92.github.io/2018/08/15/单机版SuSe搭建Confluence-Wiki/</id>
    <published>2018-08-15T04:03:48.000Z</published>
    <updated>2019-03-02T15:48:40.919Z</updated>
    
    <content type="html"><![CDATA[<p><code>单机</code> <code>SuSe</code> <code>confluence</code> <code>Wiki</code></p><p>Wiki，作为知识管理的工具，实现团队成员之间的协作和知识共享。<br><a id="more"></a><br>下面主要介绍三部分内容：</p><h4 id="一-安装过程主要参考的博客地址"><a href="#一-安装过程主要参考的博客地址" class="headerlink" title="一.安装过程主要参考的博客地址"></a>一.安装过程主要参考的博客<a href="https://segmentfault.com/a/1190000008753391#articleHeader10" target="_blank" rel="noopener">地址</a></h4><p>这篇博客每一个步骤都讲的非常清楚，按照步骤来，肯定没有问题。可能出现的问题我将写在<strong>第二部分</strong>里面。</p><h4 id="二-安装过程的注意事项"><a href="#二-安装过程的注意事项" class="headerlink" title="二.安装过程的注意事项"></a>二.安装过程的注意事项</h4><p>安装软件之前需要添加SuSe的源，尽量避免下载源码自己编译；另外，如果每次都让管理员那边挂载CD源，效率也会比较低。</p><ul><li><strong>下载配置SuSe源</strong><blockquote><p>点击<a href="https://zh.opensuse.org/%E8%BD%AF%E4%BB%B6%E6%BA%90%E9%95%9C%E5%83%8F%E7%AB%99%E7%82%B9" target="_blank" rel="noopener">这里</a>即可进入软件源镜像站点<br>选择一个镜像地址，推荐国内的USTC源：）<br>建议同时下载<code>leap</code>和<code>tumbleweed</code>镜像，每个镜像大小大概4G多一点</p></blockquote></li></ul><p>1.将下载好的iso文件上传至目标主机，低于4G的文件可以使用<code>sz</code>命令（前提是<code>lszrz</code>软件已经安装好了），超过4G的文件需要使用<code>ftp</code>进行上传，注意ftp端口的设置</p><blockquote><p>鉴于公司网络安全方面的设置，我习惯用自己的电脑连接外网，公司电脑连接内网，这样<strong>查询资料</strong>或者<strong>下载文件</strong>的同时也可以使用内网比较方便。这样就会涉及到两台电脑传输数据的问题，如果公司电脑USB有加密传输设置则建议使用网线连接进行文件传输。另外，查询资料建议使用<code>Google</code>。</p></blockquote><p>2.挂载和配置Suse源<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /mnt/localsuse01   <span class="comment">#新建一个存放文件的挂载点</span></span><br><span class="line">mount -o loop imagefilename.iso /mnt/localsuse01  <span class="comment">#挂载到刚刚建立的文件夹</span></span><br><span class="line">zypper ar file:///mnt/localsuse01 localsuse01  <span class="comment">#添加源</span></span><br><span class="line">zypper lr  <span class="comment">#查看添加的源</span></span><br></pre></td></tr></table></figure></p><p>这样的设置会导致电脑重启后需要重新手动挂载，所以可以设置成开机自动挂载。</p><ul><li><strong>mysql安装和配置</strong></li></ul><p>1.使用suse安装软件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zypper se mysql #查看源里面是否有mysql的包</span><br><span class="line">zypper install mysql #或者mariadb</span><br></pre></td></tr></table></figure></p><p>2.安装完成后，启动mysql服务<code>systemctl start mariadb</code>或者<code>systemctl start mysqld</code><br>3.登录mysql：<code>mysql -uname -p</code>先设置数据库密码<br>按照参考的博客输入内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create database confluence default character <span class="built_in">set</span> utf8;</span><br><span class="line">grant all on confluence.* to <span class="string">'confluenceuser'</span>@<span class="string">'%'</span> identified by <span class="string">'confluencepasswd'</span> with grant option;</span><br><span class="line">grant all on confluence.* to <span class="string">'confluenceuser'</span>@localhost identified by <span class="string">'confluencepasswd'</span> with grant option;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></p><p>修改<code>mysql</code>的配置文件，SuSe默认安装mysql到<code>/usr/share/mysql</code>文件夹，<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zhuz@qwerty:~$ mysql --<span class="built_in">help</span>|grep <span class="string">'my.cnf'</span><span class="comment">#查看默认配置文件的位置</span></span><br><span class="line">/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf <span class="comment">#这个是按照优先级排列的</span></span><br></pre></td></tr></table></figure></p><p>所以在<code>/etc/my.cnf</code>中添加：<code>binlog_format=mixed</code><br>4.重启mysql服务：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service mariadb stop</span><br><span class="line">service mariadb start</span><br></pre></td></tr></table></figure></p><ul><li><p><strong>关闭防火墙</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SuSEfirewall2 stop</span><br></pre></td></tr></table></figure></li><li><p><strong>配置VNC</strong></p><blockquote><p>由于后续安装步骤需要用到<code>windowX</code>图形界面服务，而我们是通过<code>CRT</code>或者<code>putty</code>远程连接登录服务器进行操作的，这里推荐使用<code>VNC viewer</code><br>在服务器电脑上安装<code>vnc</code>服务，并开启即可使用，其间可能会遇到各式各样的问题，需要自行Google一下</p></blockquote></li><li><p><strong>正式安装confluence</strong><br>这里的安装部分全程比较简单，按照前面提到的blog内容step by step即可成功，需要注意的是安装的目录可以自行选择。<br>再贴下blog地址<a href="https://segmentfault.com/a/1190000008753391#articleHeader10" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008753391#articleHeader10</a></p></li></ul><h4 id="三-运行维护"><a href="#三-运行维护" class="headerlink" title="三.运行维护"></a>三.运行维护</h4><p>1.安装后的文件位于<code>/confluence/atlassian/confluence</code>文件夹下，将该目录下的<code>bin</code>目录加入系统的环境变量<code>echo &#39;export PATH=$PATH:/confluence/atlassian/confluence/bin&#39; &gt;&gt; /etc/profile</code><br>2.由于Wiki服务没有手动加入守护进程，所以可能会由于一些原因导致其停止工作，比如电脑重启，这时需要重启Wiki服务：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start mariadb <span class="comment">#1.启动mysql</span></span><br><span class="line">SuSEfirewall2 stop <span class="comment">#2.关闭防火墙</span></span><br><span class="line">start_up.sh <span class="comment">#3.最后开启wiki</span></span><br></pre></td></tr></table></figure></p><h4 id="四-书签"><a href="#四-书签" class="headerlink" title="四.书签"></a>四.书签</h4><p>CentOS7搭建Confluence Wiki<br><a href="https://segmentfault.com/a/1190000008753391#articleHeader10" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008753391#articleHeader10</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;单机&lt;/code&gt; &lt;code&gt;SuSe&lt;/code&gt; &lt;code&gt;confluence&lt;/code&gt; &lt;code&gt;Wiki&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Wiki，作为知识管理的工具，实现团队成员之间的协作和知识共享。&lt;br&gt;
    
    </summary>
    
      <category term="Linux软件安装" scheme="https://kiddie92.github.io/categories/Linux%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="Confluence Wiki" scheme="https://kiddie92.github.io/tags/Confluence-Wiki/"/>
    
      <category term="Linux" scheme="https://kiddie92.github.io/tags/Linux/"/>
    
      <category term="Suse" scheme="https://kiddie92.github.io/tags/Suse/"/>
    
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mun*</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://kiddie92.github.io/"/>
  <updated>2019-06-15T18:30:56.152Z</updated>
  <id>https://kiddie92.github.io/</id>
  
  <author>
    <name>Mun*</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分层softmax</title>
    <link href="https://kiddie92.github.io/2019/06/15/%E5%88%86%E5%B1%82softmax/"/>
    <id>https://kiddie92.github.io/2019/06/15/分层softmax/</id>
    <published>2019-06-15T03:40:00.000Z</published>
    <updated>2019-06-15T18:30:56.152Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>入坑自然语言处理，论文<a href="https://arxiv.org/pdf/1411.2738.pdf" target="_blank" rel="noopener">word2vec Parameter Learning Explained</a>基本是必读的，这篇论文中的<strong>Hierarchical Softmax</strong>，中文叫做分层softmax/层次softmax是比较让人头大的内容，这篇博文试图阐述Hierarchical Softmax算法在word2vec中的应用。<br><a id="more"></a></p></blockquote><h2 id="Huffman-Tree"><a href="#Huffman-Tree" class="headerlink" title="Huffman Tree"></a>Huffman Tree</h2><p>中文名叫霍夫曼树/霍夫曼编码，是个二叉树（注意<strong>不是</strong>二叉搜索树），这部分内容比较简单，<a href="https://zh.wikipedia.org/wiki/%E9%9C%8D%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81" target="_blank" rel="noopener">维基百科</a>上也说的非常清楚，<strong>下面搬运一下维基百科上的例子</strong>：<br><strong>示例：</strong><br>霍夫曼树常处理符号编写工作。根据整组数据中符号出现的频率高低，决定如何给符号编码。<strong>如果符号出现的频率越高，则给符号的码越短，相反符号的号码越长</strong>。假设我们要给一个英文单字”F O R G E T”进行霍夫曼编码，而每个英文字母出现的频率分别列在Fig.1。<br><img src="./TABLE1.JPG" alt="Alt text"></p><p><strong>演算过程：</strong> </p><p>（一）进行霍夫曼编码前，我们先创建一个霍夫曼树。</p><ol><li>将每个英文字母依照出现频率由小排到大，最小在左，如Fig.1。</li><li>每个字母都代表一个终端节点（叶节点），比较F.O.R.G.E.T六个字母中每个字母的出现频率，将最小的两个字母频率相加合成一个新的节点。如Fig.2所示，发现F与O的频率最小，故相加2+3=5。</li><li>比较5.R.G.E.T，发现R与G的频率最小，故相加4+4=8。</li><li>比较5.8.E.T，发现5与E的频率最小，故相加5+5=10。</li><li>比较8.10.T，发现8与T的频率最小，故相加8+7=15。</li><li>最后剩10.15，没有可以比较的对象，相加10+15=25。</li></ol><p>最后产生的树状图就是霍夫曼树，参考Fig.2。<br><img src="./Huffman_algorithm.gif" alt="Huffman_algorithm"></p><p>（二）进行编码</p><ol><li>给霍夫曼树的所有左链接’0’与右链接’1’。</li><li>从树根至树叶依序记录所有字母的编码，如Fig.3。<br><img src="./TABLE8.JPG" alt="Alt text"></li></ol><blockquote><p>以上便是Huffman Tree的主要内容，在word2vec算法中，这个方法是用来<strong>替代softmax层</strong>来减少计算量的。至此，需要了解到的信息有以下几点：<br>1.最后树的输出FOERGT是不要特定排序的，排列成FORGET也是可以的，就是画图不是很方便；<br>2.在word2vec中，这里的字母就是单词了，如果单词出现的频率越高，则给单词的码越短（离根节点越近），相反单词的号码越长；<br>3.构建Huffman Tree的中间节点（5, 8, 10, 15, 25）的个数是<strong>字典中单词个数减1</strong></p></blockquote><h2 id="softmax-in-word2vec"><a href="#softmax-in-word2vec" class="headerlink" title="softmax in word2vec"></a>softmax in word2vec</h2><p>word2vec Parameter Learning Explained这篇论文中介绍了 Continuous Bag-of-Word Model（连续词袋模型）和skip-gram model（跳字模型），分别对应了词向量的两种训练方法：利用context预测中心词以及利用中心词去预测context。对于连续词袋模型（CBOW）来说，一般的做法（如下图所示）是先对每个单词进行one-of-N编码（one-hot encoded），作为训练网络的输入，接着构建一层hidden layer，最后构建输出层，这一层是一个softmax层，每个context单词到中心单词的事件都被认为是<strong>独立的</strong>，所以将这些事件发生的<strong>概率相乘</strong>，最后构建损失函数，即：将输出概率分布和实际选中的词概率分布进行Corss Entropy计算，接下来使用SGD对参数进行更新。这里，hidden layer的训练结果就是最终的<code>word vector</code>了。</p><blockquote><p>需要注意的是：对于任意的单词，Input layer和Hidden Layer之间的权重矩阵W是参数共享的</p></blockquote><p><img src="./CBOW.png" alt="Continuous Bag-of-Word Model"></p><p>上述方法看起来是没毛病的，问题是计算量有点大，尤其是进行反向传播更新参数的时候$t$：</p><script type="math/tex; mode=display">\frac {\partial \log P(\left. w_c,   \right |w_{o_1},w_{o_2},...,w_{o_{2m}})}{\partial v_{o_i}} =\frac {1}{2m}( \vec u_c - \sum_{j \in V}P(\left. w_j \right |w_c)\vec u_j )  \tag {1}</script><p>式（1）说明，参数更新的时候，对于每一个单词每一次迭代都<strong>至少</strong>有<script type="math/tex">O|V|</script>的计算量，如此大的计算量是由于softmax引用了词典中的所有单词。</p><p>在skip-gram模型中也是一样的：</p><script type="math/tex; mode=display">\frac {\partial \log P(\left. w_o \right |w_c)}{\partial v_c} = \vec u_o - \sum_{j \in V}P(\left. w_j \right |w_c)\vec u_j</script><blockquote><p>至此应该了解到：<br>1.浅层的网络就可以学习出来词向量；<br>2.W矩阵对于不同的单词是参数共享的，单词顺序发生变化的时候是不影响结果的；<br>3.参数更新时的计算量非常大。</p></blockquote><h2 id="Hierarchical-Softmax-in-word2vec"><a href="#Hierarchical-Softmax-in-word2vec" class="headerlink" title="Hierarchical Softmax in word2vec"></a>Hierarchical Softmax in word2vec</h2><p>为了减少计算量，作者提出了两种近似计算方法，第一种叫做<code>Negative Sampling</code>（负采样），该方法就是对词典中的特定属性的单词进行特定分布的采样，将计算的数据量降低了（详见论文）；第二种就是<code>Hierarchical Softmax</code>（分层softmax/层次softmax），该方法将<code>softmax层</code>替换成了<code>分层softmax层</code>。<br><code>分层softmax</code>的计算过程如下图所示：</p><p><img src="./hierarchical_softmax1.png" alt="hierarchical_softmax"><br>图片来自<a href="https://learning.oreilly.com/library/view/python-natural-language/9781787121423/a63263c0-bd79-4c15-88d0-8898186e03a5.xhtml" target="_blank" rel="noopener">这里</a></p><p>从图中可以看出，hidden layer到output layer的连接原本是一个简单的softmax，有<strong>V个神经元</strong>和所有的hidden layer两两连接，现在变成了一个树，有<strong>V-1个神经元</strong>和所有的hidden layer两两连接。计算概率的方法也发生了变化：</p><script type="math/tex; mode=display">P(w|w_i)=\prod_{j=1}^{L(w)-1} \sigma ([n(w,j+1) = left\_child(n(w,j)] \cdot \vec U^T_{n(w,j) } \vec V_i) \tag {2}</script><p>其中，当<script type="math/tex">n(w,j+1) = left\_child(n(w,j)</script>时，中括号内为1，否则为-1，这是用到了一个sigmoid函数的小trick：<script type="math/tex">1-\sigma (x)=\sigma(-x)</script>。所以式（2）的意思就是从根节点到目标单词，有且仅有一条路径可以到达，在这条路径上往左走的概率是<script type="math/tex">\sigma(\vec U^T_{n(w,j) } \vec V_i)</script>，往右走的概论自然就是<script type="math/tex">\sigma(-\vec U^T_{n(w,j) } \vec V_i)</script>，<a href="https://kiddie92.github.io/2019/06/09/Logistic-Regression/">逻辑回归</a>那篇也介绍过，sigmoid函数是用来做二分类的，在这里正好合适；当路径上的所有二分类的概率都连乘后，得到的就是预测单词的概率，可以证明，词典中所有单词被预测到的概率和为1。这也是这个方法被叫做分层softmax的原因了。</p><p>如此一来，计算某个单词被预测的概率就仅仅和该单词到hidden layer的神经元连接的唯一路径相关了，更新参数的时候计算量一下子降到了O(log(V))。</p><blockquote><p>仔细想一下，<code>Hierarchical Softmax</code>和<code>CNN</code>的思想其实有点类似，把原本的全连接变成了部分的特定连接。</p></blockquote><p>关于这方面的源码编写可以参考<a href="http://www.trevorsimonton.com/blog/2016/12/15/huffman-tree-in-word2vec.html" target="_blank" rel="noopener">这个美国老哥的博客</a>。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Rong, X. (2014). word2vec parameter learning explained. arXiv preprint arXiv:1411.2738.</li><li>Morin, F., &amp; Bengio, Y. (2005, January). Hierarchical probabilistic neural network language model. In Aistats (Vol. 5, pp. 246-252).</li><li><a href="https://www.youtube.com/watch?v=C4X0Cb5_FSo&amp;list=PLLbeS1kM6teJqdFzw1ICHfa4a1y0hg8Ax&amp;index=17&amp;t=0s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=C4X0Cb5_FSo&amp;list=PLLbeS1kM6teJqdFzw1ICHfa4a1y0hg8Ax&amp;index=17&amp;t=0s</a></li><li><a href="https://learning.oreilly.com/library/view/python-natural-language/9781787121423/a63263c0-bd79-4c15-88d0-8898186e03a5.xhtml" target="_blank" rel="noopener">https://learning.oreilly.com/library/view/python-natural-language/9781787121423/a63263c0-bd79-4c15-88d0-8898186e03a5.xhtml</a></li><li><a href="https://zhuanlan.zhihu.com/p/35074402" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35074402</a></li><li><a href="http://www.trevorsimonton.com/blog/2016/12/15/huffman-tree-in-word2vec.html" target="_blank" rel="noopener">http://www.trevorsimonton.com/blog/2016/12/15/huffman-tree-in-word2vec.html</a></li><li><a href="https://www.quora.com/What-is-hierarchical-softmax" target="_blank" rel="noopener">https://www.quora.com/What-is-hierarchical-softmax</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;入坑自然语言处理，论文&lt;a href=&quot;https://arxiv.org/pdf/1411.2738.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;word2vec Parameter Learning Explained&lt;/a&gt;基本是必读的，这篇论文中的&lt;strong&gt;Hierarchical Softmax&lt;/strong&gt;，中文叫做分层softmax/层次softmax是比较让人头大的内容，这篇博文试图阐述Hierarchical Softmax算法在word2vec中的应用。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="NLP" scheme="https://kiddie92.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>基于矩阵分解的推荐算法</title>
    <link href="https://kiddie92.github.io/2019/06/10/Matrix-Factorization%E7%AE%80%E4%BB%8B/"/>
    <id>https://kiddie92.github.io/2019/06/10/Matrix-Factorization简介/</id>
    <published>2019-06-10T12:59:56.000Z</published>
    <updated>2019-06-16T09:18:18.597Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Matrix Factorization算法是推荐系统（Recommendation System）的基础，本篇文章仅介绍一下基于<strong>矩阵分解</strong>的推荐系统是如何工作的以及Matrix Factorization算法，最后给出一个算法示例。内容比较浅显，深入算法原理还需要阅读更多的论文和资料。<br><a id="more"></a></p></blockquote><h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>推荐系统是信息过滤系统的子集，系统任务便是预测用户接下来<strong>更可能</strong>想要查看的内容，也就是将特定的信息过滤出来提交给用户。这类算法主要应用于商业应用，比如：歌曲推荐、视频推荐、新闻推荐等。<br>推荐系统可以由很多算法实现，而基于用户/基于商品的Collaborative filtering是比较简单直接的。</p><h3 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h3><p><em>举个线下的例子：</em><br>抛开算法，可以先思考一下，超市的售货员阿姨是怎么给你推荐商品的呢？<br>你是学生吗？买回去给谁用？需要买什么价位的？这类问题经常被问及…然后，售货员便根据<strong>用户信息</strong>来推荐你可能需要的商品了：我们这有xxx，价格xxx，好多学生都买…售货员的信息则是从大量的市场调研/工作经验中学习到的<strong>商品信息</strong>。</p><p>所以，一个推荐系统应该会同时包含<code>用户信息</code>和<code>商品信息</code>，回到线上，当很多用户在某个视频网站上观看电影后，会对电影打个分，除此之外，用户还有年龄、性别、行业、家庭关系等很多信息，这些都是<code>用户信息</code>；而视频本身也有自己的分类，比如：喜剧、动作等，此外还有票房、受众人群等信息，这些便组成了<code>商品信息</code>。</p><p>在推荐系统中，这些信息交织在一起，存放于一个大矩阵中，内容为用户对于每一个商品的评价打分，如下图所示（图片来自<a href="https://en.wikipedia.org/wiki/Collaborative_filtering" target="_blank" rel="noopener">维基百科</a>）：</p><p><img src="./300px-Collaborative_filtering.gif" alt="Collaborative_filtering"></p><p>需要注意的是，很多人是不点赞、不评论甚至对某些商品完全没有听说过，所以这个<strong>数据矩阵是一个巨大的稀疏矩阵</strong>，里面很多空白。将这些评价量化后，便得到一个<code>数据源矩阵</code>了。而<code>推荐系统</code>要做的便是从该矩阵中<strong>提取信息</strong>，为用户/新用户提供items推荐服务。</p><blockquote><p>至此，应该了解到：<br>1.推荐系统基于大量的用户数据；2.数据是一个大型的稀疏矩阵，每一行/列表示某一用户（user）对所有商品（item）的打分信息，中间有很多很多空白处待填写。</p></blockquote><h3 id="算法策略"><a href="#算法策略" class="headerlink" title="算法策略"></a>算法策略</h3><p>有了<code>数据源矩阵</code>之后，接下来要做的就是在矩阵空白的地方填写数字了，数字代表用户对某一个item的喜好程度，从而推荐用户可能打分比较高的item；如何在空白处填上合理的数字是<strong>基于矩阵分解</strong>方法的核心。下图示意了算法：$tag$</p><p><img src="./An-example-of-matrix-factorization.png" alt="基于矩阵分解算法"></p><p>图片来自<a href="https://www.researchgate.net/figure/An-example-of-matrix-factorization_fig1_314071424" target="_blank" rel="noopener">这里</a></p><p>如上图所示，将<code>数据源矩阵</code>分解成<code>用户矩阵</code><script type="math/tex">W_{u \times k}</script>和<code>商品矩阵</code><script type="math/tex">W_{k \times I}</script>，得到了用户A对每一个feature的喜好程度；又有每一个item对每一个feature的权重/偏置。那就可以重新构建一个新的没有空白的数据矩阵了，也就是将原来的空白地方进行了填充。但是这里还需要一个约束，根据<strong>用户矩阵</strong>和<strong>item矩阵</strong>计算得到的<strong>新的被填满</strong>的<code>数据矩阵</code>和原来有很多空白的<code>数据源矩阵</code>一定要基本一致（原有数据不能失真）。</p><blockquote><p>需要注意的是，feature的数量k一般是少于user和itme数量的，所以最终如果仅存储<strong>用户矩阵</strong>和<strong>item矩阵</strong>，那会比存储<strong>数据源矩阵</strong>要节省很多存储空间。</p></blockquote><h2 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h2><p>现在目标就很明确了，将大型稀疏矩阵分解成两个小矩阵，一个是user矩阵，一个是item矩阵。</p><blockquote><p>矩阵分解算法有很多，使用场景也不相同，例如：QR分解在进行迭代计算时常常被使用；SVD分解在进行矩阵降维度，数据去燥方面用的比较多</p></blockquote><h3 id="算法原理和步骤"><a href="#算法原理和步骤" class="headerlink" title="算法原理和步骤"></a>算法原理和步骤</h3><p>目标：</p><script type="math/tex; mode=display">\bf D_{U \times I} \approx User_{u \times k} \times Item_{k \times I} = \hat D_{U \times I}</script><p>理论上，应该有类似QR、SVD分解这样的方法，去直接求解上式，考虑到上式是一个大型稀疏矩阵，常见的做法是直接使用<strong>梯度下降优化算法</strong>：</p><ol><li>给定初始值：矩阵U和I，设定迭代次数和误差范围；</li><li>计算<script type="math/tex">User_{u \times k} \times Item_{k \times I} = \hat D_{U \times I}</script></li><li>计算二范数距离<script type="math/tex">|| D_{U \times I}- \hat D_{U \times I}||_2=e^2</script>，这里加上正则化项也是极好的；</li><li>计算梯度<script type="math/tex">\frac {\partial e^2}{\partial U}</script> 以及 <script type="math/tex">\frac {\partial e^2}{\partial I}</script></li><li>更新参数<script type="math/tex">U'=U+\alpha \cdot \frac {\partial e^2}{\partial U}</script>以及<script type="math/tex">I'=I+\alpha \cdot \frac {\partial e^2}{\partial I}</script></li></ol><h3 id="python示例"><a href="#python示例" class="headerlink" title="python示例"></a>python示例</h3><p>点击<a href="https://nbviewer.jupyter.org/github/albertauyeung/matrix-factorization-in-python/blob/master/mf.ipynb" target="_blank" rel="noopener">这里</a>即可查看，或者<a href="https://github.com/kiddie92/Learning_Tech/tree/master/Matrix_Factorization" target="_blank" rel="noopener">这里</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>为用户生成推荐内容；</li><li>Matrix Factorization可以节省存储空间；</li><li>最重要的是数据处理。</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Covington, P., Adams, J., &amp; Sargin, E. (2016, September). Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM conference on recommender systems (pp. 191-198). ACM.</li><li><a href="http://www.albertauyeung.com/post/python-matrix-factorization/" target="_blank" rel="noopener">http://www.albertauyeung.com/post/python-matrix-factorization/</a></li><li>Thai-Nghe, N., Nhut-Tu, M., &amp; Nguyen, H. H. (2017, April). An Approach for Multi-Relational Data Context in Recommender Systems. In Asian Conference on Intelligent Information and Database Systems (pp. 709-720). Springer, Cham.</li><li><a href="https://www.youtube.com/watch?v=ZspR5PZemcs&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw&amp;index=23&amp;t=4s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=ZspR5PZemcs&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw&amp;index=23&amp;t=4s</a></li><li><a href="https://www.youtube.com/watch?v=o8PiWO8C3zs" target="_blank" rel="noopener">https://www.youtube.com/watch?v=o8PiWO8C3zs</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Matrix Factorization算法是推荐系统（Recommendation System）的基础，本篇文章仅介绍一下基于&lt;strong&gt;矩阵分解&lt;/strong&gt;的推荐系统是如何工作的以及Matrix Factorization算法，最后给出一个算法示例。内容比较浅显，深入算法原理还需要阅读更多的论文和资料。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="推荐系统" scheme="https://kiddie92.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Logistic Regression</title>
    <link href="https://kiddie92.github.io/2019/06/09/Logistic-Regression/"/>
    <id>https://kiddie92.github.io/2019/06/09/Logistic-Regression/</id>
    <published>2019-06-09T09:14:50.000Z</published>
    <updated>2019-06-15T15:36:37.022Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>对数几率回归/逻辑回归/逻辑斯蒂回归/最大熵模型也即Logistic Regression是深度学习的基础，算法的重要性不言而喻。Logistic Regression虽然叫“Rgression”，但其实与之前介绍的<a href="https://kiddie92.github.io/2019/05/10/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89/">SVM分类（svc）方法</a>一样，同属<strong>分类算法</strong>。本篇博文对该算法的介绍流程基本参考了李宏毅老师的机器学习课程，文章后半部分主要以问答的形式给出了关于逻辑斯蒂回归的部分理解。<br><a id="more"></a></p></blockquote><h2 id="基础知识回顾"><a href="#基础知识回顾" class="headerlink" title="基础知识回顾"></a>基础知识回顾</h2><p>$  $</p><h3 id="Bernoulli-distribution"><a href="#Bernoulli-distribution" class="headerlink" title="Bernoulli distribution"></a>Bernoulli distribution</h3><p>伯努利分布/两点分布/0-1分布是一个非常简单的概率模型，事件只有两种，常见于二分类问题，其概率密度函数（PDF）如下：</p><script type="math/tex; mode=display">f_X(x)=p^x(1-p)^{1-x}=\begin{cases} p, & \text {if x=1,} \\ q, & \text{if x=0.} \end{cases}  \tag{1}</script><h3 id="sigmoid-函数及其导函数"><a href="#sigmoid-函数及其导函数" class="headerlink" title="sigmoid 函数及其导函数"></a>sigmoid 函数及其导函数</h3><p>Sigmoid 函数意思就是<strong>S型函数</strong>，因为长相就是S形的，公式如图左上角所示，下图蓝色表示sigmoid函数，绿色表示其导函数。sigmiod在学习机器学习和深度学习时会时常遇到。</p><p><img src="./sigmoid.png" width="60%" height="60%"></p><h3 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h3><p>softmax可以将一组数字转换成一组概率，并且突出较大数值的优势（使其在概率上有很大的值），如下图所示：</p><p><img src="./softmax.png" width="60%" height="60%"></p><h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><h3 id="概率模型"><a href="#概率模型" class="headerlink" title="概率模型"></a>概率模型</h3><p>对于<strong>二分类</strong>问题，假设现在有一笔training data（下表中<script type="math/tex">C_1</script>表示数据<script type="math/tex">x^i</script>属于Class 1，<script type="math/tex">C_2</script>表示数据<script type="math/tex">x^i</script>属于Class 2）：</p><div class="table-container"><table><thead><tr><th style="text-align:center">数据</th><th style="text-align:center"><script type="math/tex">x^1</script></th><th style="text-align:center"><script type="math/tex">x^2</script></th><th style="text-align:center"><script type="math/tex">x^3</script></th><th style="text-align:center">……</th><th style="text-align:center"><script type="math/tex">x^N</script></th></tr></thead><tbody><tr><td style="text-align:center">类别</td><td style="text-align:center"><script type="math/tex">C_1</script></td><td style="text-align:center"><script type="math/tex">C_1</script></td><td style="text-align:center"><script type="math/tex">C_2</script></td><td style="text-align:center">……</td><td style="text-align:center"><script type="math/tex">C_1</script></td></tr></tbody></table></div><p>现已知一个<strong>新数据</strong><script type="math/tex">x</script>，我们可以构造一个<strong>概率密度函数（PDF）</strong>来表示<script type="math/tex">x</script>属于<script type="math/tex">C_1</script>的概率<script type="math/tex">P(\left. C_1 \right |x)</script>：</p><script type="math/tex; mode=display">f_{w,b}(x) = \sigma (z) = P_{w,z}(\left. C_1 \right |x)\\ z=\sum_iw_ix_i+b \tag{2}</script><p>这里引入的<script type="math/tex">w_i, b</script>参数和sigmoid函数<script type="math/tex">\sigma(z)</script>并不是凭空捏造出来的，实际上，是可以根据<strong>生成模型</strong>推导出这个公式的，这部分的内容可以参考<a href="https://www.youtube.com/watch?v=fZAZUYEeIMg&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw&amp;index=1" target="_blank" rel="noopener">这里</a>。<br>如此一来，<strong>假设“<script type="math/tex">x_i</script>属于<script type="math/tex">C_1或C_2</script>”这件事情和“<script type="math/tex">x_j</script>属于<script type="math/tex">C_1或C_2</script>”这件事情是相互独立的</strong>，那么就可以得出，training data中的所有事件<strong>全部发生</strong>的概率为：</p><script type="math/tex; mode=display">L(w,b) = f_{w,b}(x^1) \cdot f_{w,b}(x^2) \cdot (1-f_{w,b}(x^3)) …… f_{w,b}(x^N)  \tag{3}</script><blockquote><ol><li>对于二分类问题，由于<script type="math/tex">x_3</script>属于<script type="math/tex">C_2</script>，所以<script type="math/tex">P_{w,z}(\left. C_2 \right |x^3)=1-P_{w,z}(\left. C_1 \right |x^3)</script>也即<script type="math/tex">1-f_{w,b}(x^3)</script>；</li><li>实际数据往往是离散的，这里使用概率密度函数（PDF）也许不准确。</li></ol></blockquote><h3 id="最大似然估计（Maximum-Likelihood）"><a href="#最大似然估计（Maximum-Likelihood）" class="headerlink" title="最大似然估计（Maximum Likelihood）"></a>最大似然估计（Maximum Likelihood）</h3><p>为了让PDF可以表示真实数据的distribution，也即让<script type="math/tex">f_{w,b}(x)</script>最为准确，我们希望计算得到的<script type="math/tex">L(w,b)</script>尽可能大，当然，最大值就是1了。接下来目标便是找到一组<script type="math/tex">w^*, b^*</script>使得：</p><script type="math/tex; mode=display">\underset{\vec w,b}{\operatorname{arg max}} L(w,b)  \tag{4}</script><p>为了方便（Mathmatic Convenient），将上式改写：</p><script type="math/tex; mode=display">\underset{\vec w,b}{\operatorname{arg min}} { -ln[L(w,b)] }  \tag{5}</script><p>并且引入参数<script type="math/tex">\hat y</script>（也是关于x的一个两点分布）：</p><script type="math/tex; mode=display">\hat y = \begin{cases} 1, \space \space if \space x\in C_1  \\  0, \space \space if \space x\in C_2  \end{cases}  \tag{6}</script><p>结合式(5)和式(6)，有：</p><script type="math/tex; mode=display">-\ln{f_{w,b}(x^n)}= \hat y^n \ln{f_{w,b}(x^n)} + (1-\hat y^n) \ln{(1-f_{w,b}(x^n))}  \tag{7}</script><p>代入式(5)，得</p><script type="math/tex; mode=display">-ln[L(w,b)] = - \sum_n [ \hat y^n \ln{f_{w,b}(x^n)} + (1-\hat y^n) \ln{(1-f_{w,b}(x^n)}) ]  \tag{8}</script><p>式(8)的右边便是<strong>两个二项分布的Cross Entropy</strong>，也就是logistic regression的loss function/object function接下来要做的便是对式(8)进行优化/求最小值。</p><h3 id="交叉熵（Cross-Entropy-and-KL-divergence"><a href="#交叉熵（Cross-Entropy-and-KL-divergence" class="headerlink" title="交叉熵（Cross Entropy and KL-divergence)"></a>交叉熵（Cross Entropy and KL-divergence)</h3><p><code>熵</code>：在信息论中（information theroy）离散概率分布函数的熵为</p><script type="math/tex; mode=display">H(p) = - \sum_i{p_i \log{p_i}} \tag{9}</script><p><code>KL-divergence</code>: 为了衡量两个离散分布函数的相似度，如果使用传统的二范数距离或者向量的夹角距离，显然不合适，这里定义</p><script type="math/tex; mode=display">D_{KL}(\left. p \right |q) = \sum_i{p_i \log{\frac{p_i}{q_i}}}  \tag{10}</script><p>来衡量两个离散分布函数有多接近/相似，<strong>注意</strong><script type="math/tex">D_{KL}(\left. p \right |q) \ne D_{KL}(\left. q \right |p)</script>，当<script type="math/tex">D_{KL}(\left. p \right |q) =0</script>时，<script type="math/tex">p</script>同<script type="math/tex">q</script>分布。<br><code>Cross Entropy</code>:</p><script type="math/tex; mode=display">H(p,q) = H(p)+D_{KL}(\left. p \right |q)=\sum_i{p_i \log{\frac {1}{q_i}}}= -\sum_i{p_i \log{q_i}} \tag{11}</script><p>所以对应到式(8)中，对于<script type="math/tex">\forall x^n</script>，有：</p><script type="math/tex; mode=display">p=\begin{cases}  \hat y^n,  \space \space \space \space \space \space \space for \space x \in C_1 \\  1-\hat y^n, \space  for \space x \in C_2 \end{cases}, \space \space \space  q=\begin{cases}  f_{w,b}(x^n),  \space \space \space \space \space \space \space for \space x \in C_1 \\  1-f_{w,b}(x^n), \space  for \space x \in C_2 \end{cases} \tag{12}</script><script type="math/tex; mode=display">-ln[L(w,b)] = \sum_n  H(p,q) = \sum_n  H(\hat y^n,f(x^n))  \tag{13}</script><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>有了多个Corss Entropy求和作为loss，接下来便是对目标函数/损失函数进行求解，求解目标是使该函数取<strong>最小值</strong>，这里可以使用Gradient Descent方法，牛顿迭代法或者其他启发式优化算法理论上也是可以的。</p><h3 id="从二分类到多分类"><a href="#从二分类到多分类" class="headerlink" title="从二分类到多分类"></a>从二分类到多分类</h3><p>上面的推导都是基于<code>binary classification</code>的，如果要进行<code>multiple classification</code>，就需要对上面的情况进行扩展了。这里先给出做法（how），关于<code>sigmoid</code>和<code>softmax</code>分析请<strong>继续</strong>往下看。</p><p>首先<script type="math/tex">\vec x</script>不再是只做一次“<script type="math/tex">\vec w \cdot \vec x + b</script>”变换了，而是做<script type="math/tex">n</script>次，<script type="math/tex">n</script>就是需要分类的<strong>类别数</strong>，目标的分布也不再是0-1这样，而是多维的0-1分布，比如：对于三分类问题，<script type="math/tex">x^n \in C_1</script>，则<script type="math/tex">\hat y^n=[1,0,0]</script>，而计算概率的函数也由sigmiod函数转变为softmax函数。</p><p><img src="./图1.png" alt="binary VS multiple classification"></p><h3 id="方法局限性（limitation）"><a href="#方法局限性（limitation）" class="headerlink" title="方法局限性（limitation）"></a>方法局限性（limitation）</h3><p>逻辑回归的局限性在于，分类时分割线只是<strong>线性的</strong>（直线、平面或者超平面），所以对于非线性分类问题，需要另辟蹊径。<br>到这里，有些同学可能有疑问，明明使用了sigmoid或者softmax函数处理仿射变换结果，怎么会还是线性的？？？ 首先，判断一个函数/系统是不是线性的，可以从输入和输出入手来探究，如图一所示，样本<script type="math/tex">x</script>如果增大，显然<script type="math/tex">z1, z2, z3</script>也会成比例增大，而Softmax和Sigmoid在这里的作用仅仅是将结果转换成0-1之间的数值（概率），所以它还是一个线性分类的场景。</p><h3 id="非线性可分的解法"><a href="#非线性可分的解法" class="headerlink" title="非线性可分的解法"></a>非线性可分的解法</h3><p>对于非线性分类问题，可以采用类似于SVM的kernel方法，先对样本做feature map，再进行分类，但是这个map需要依靠人类的智慧去找了，具体的例子可以查看李宏毅的机器学习课。</p><h2 id="问答-amp-理解"><a href="#问答-amp-理解" class="headerlink" title="问答&amp;理解"></a>问答&amp;理解</h2><h3 id="为什么使用Cross-Entropy计算loss？"><a href="#为什么使用Cross-Entropy计算loss？" class="headerlink" title="为什么使用Cross Entropy计算loss？"></a>为什么使用Cross Entropy计算loss？</h3><p>这里的机器学习，关键部分可以理解成<strong>学习样本数据的分布</strong>，由于本质上是使用最大似然方法，要求最终得到的概率密度函数（PDF）可以给出<strong>一个新的数据属于某一类的可能性</strong>。而对于<strong>两个分布的相似度</strong>衡量，<code>Cross Entropy</code>目前来看应该还是不二之选。</p><h3 id="用Square-Error作为Loss行不行？"><a href="#用Square-Error作为Loss行不行？" class="headerlink" title="用Square Error作为Loss行不行？"></a>用Square Error作为Loss行不行？</h3><p>可以，不过训练过程将极其痛苦，按照李宏毅老师课程中所述，使用传统的二范数距离来度量两个分布的相似度的损失函数将会<strong>非常平坦</strong>，使用梯度下降算法进行优化时，往往不太可能得出比较好的结果。而使用Cross Entropy所得到的损失函数则具有较大的梯度，搜索速度将会比使用Square Error要快很多。</p><h3 id="为什么叫Regression？"><a href="#为什么叫Regression？" class="headerlink" title="为什么叫Regression？"></a>为什么叫Regression？</h3><p>对比Linear Regression方法的计算过程，发现Logistics Regression与其一模一样，包括模型参数的更新公式，形式上都是一样的，虽然Logistics Regression是用来所分类的，还是叫逻辑回归比较”亲切”。</p><h3 id="和信息论（information-theory）的关系？"><a href="#和信息论（information-theory）的关系？" class="headerlink" title="和信息论（information theory）的关系？"></a>和信息论（information theory）的关系？</h3><p>以上的推导过程都是基于概率的方法，使用了最大似然估计，但是这也完全可以从Information Theory的角度推导出逻辑回归的损失函数，所以，信息论只是认识这个问题的另外一个角度。</p><h3 id="和Generation-Model-生成模型的关系"><a href="#和Generation-Model-生成模型的关系" class="headerlink" title="和Generation Model/生成模型的关系"></a>和Generation Model/生成模型的关系</h3><p>逻辑回归是一个判别模型（Discrimination Model），我觉得和生成模型比，它是一个不好进行数学解释的模型。实际上，从生成模型到判别模型，参数被抽样化了，底层所依赖的数学理论也同样被抽象化了，一旦模型复杂了，判别模型就基本解释不了了。<br>一般来说，生成模型会对现有数据做一些假设并对样本数据内的信息进行抽象总结，从而给出模型对样本数据的<strong>新认识</strong>（样本数据里面没有的信息），而判别模型则一般仅会对样本数据之内的信息进行挖掘。所以，对于样本数足够多的时候，使用判别模型一般会由于使用生成模型。</p><h3 id="sigmoid-V-S-softmax"><a href="#sigmoid-V-S-softmax" class="headerlink" title="sigmoid V.S. softmax"></a>sigmoid V.S. softmax</h3><p>前面已经介绍过，从二分类到多分类，计算概率的函数就会从sigmoid转换为softmax，但实际上softmax就是sigmoid的“扩展板”。如果对于二分类问题也使用softmax函数，可以推导出概率模型和sigmoid给出的一模一样。</p><h3 id="Logistic-Regression-V-S-Neural-Network"><a href="#Logistic-Regression-V-S-Neural-Network" class="headerlink" title="Logistic Regression V.S. Neural Network"></a>Logistic Regression V.S. Neural Network</h3><p>到这里，其实已经很清楚了，DNN中的每一个神经元（Neural）就是一个sigmoid形式的逻辑回归，而对于softmax形式的逻辑回归，它其实就是一个<strong>没有hidden layer</strong>的NN，一层神经网络。<br>此外，之前讨论的<strong>非线性分类问题</strong>的解法，就是对原始样本数据先做特征映射，而NN算法在softmax之前都可以看成一个比较复杂的特征映射，并且这个映射的参数是自学习的。这样，也顺便解释了NN算法好于逻辑回归，并对非线性问题有很好的解决。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>介绍了逻辑回归算法的推导过程</li><li>说明了cross entropy的适用场景</li><li>对比了sigmoid和softmax函数</li><li>问答的形式给出了一些对逻辑回归算法的理解</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.youtube.com/watch?v=hSXFuypLukA&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw&amp;index=5&amp;t=0s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=hSXFuypLukA&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw&amp;index=5&amp;t=0s</a></li><li><a href="https://www.youtube.com/watch?v=fZAZUYEeIMg&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw&amp;index=1" target="_blank" rel="noopener">https://www.youtube.com/watch?v=fZAZUYEeIMg&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw&amp;index=1</a></li><li><a href="https://tdhopper.com/blog/cross-entropy-and-kl-divergence/" target="_blank" rel="noopener">cross-entropy-and-kl-divergence</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;对数几率回归/逻辑回归/逻辑斯蒂回归/最大熵模型也即Logistic Regression是深度学习的基础，算法的重要性不言而喻。Logistic Regression虽然叫“Rgression”，但其实与之前介绍的&lt;a href=&quot;https://kiddie92.github.io/2019/05/10/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89/&quot;&gt;SVM分类（svc）方法&lt;/a&gt;一样，同属&lt;strong&gt;分类算法&lt;/strong&gt;。本篇博文对该算法的介绍流程基本参考了李宏毅老师的机器学习课程，文章后半部分主要以问答的形式给出了关于逻辑斯蒂回归的部分理解。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="逻辑回归算法" scheme="https://kiddie92.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>k8s 对外服务之ingress</title>
    <link href="https://kiddie92.github.io/2019/06/03/k8s-%E5%AF%B9%E5%A4%96%E6%9C%8D%E5%8A%A1%E4%B9%8Bingress/"/>
    <id>https://kiddie92.github.io/2019/06/03/k8s-对外服务之ingress/</id>
    <published>2019-06-03T09:46:42.000Z</published>
    <updated>2019-06-18T16:03:52.290Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首先回顾了一下负载均衡和反向代理，随后介绍ingress，这部分的内容主要参考了YouTube上印度老哥的频道：<a href="https://www.youtube.com/watch?v=VicH6KojwCI" target="_blank" rel="noopener">KodeKloud的视频</a>，直接看视频效果更佳。<br><a id="more"></a></p></blockquote><h2 id="7层负载均衡"><a href="#7层负载均衡" class="headerlink" title="7层负载均衡"></a>7层负载均衡</h2><p>负载均衡（LB）在微服务架构演进中具有非常重要的意义，可以说的内容有很多，<strong>这里仅仅讨论四层和七层负载均衡的一些要点和区别</strong>，以便于对<code>ingress</code>的理解。所谓四层和七层负载均衡是按照网络层次OSI来划分的负载均衡类型（也可以按照其他的规则来分类，比如：应用的地理结构），简单来说：<code>四层负载均衡</code>表示负载均衡器用ip+port接收请求，再直接转发到后端对应的服务上，工作在传输层( transport layer )；<code>七层负载均衡</code>表示负载均衡器根据虚拟的url或主机名来接收请求，经过处理后再转向相应的后端服务上，工作在应用层( application layer )。</p><p>下图表示了4层和7层负载均衡在建立TCP连接上的区别，从图中可以看出，四层负载均衡需要建立的TCP连接其实之有一个，它只做一次转发，client直接和server连接；而7层负载均衡则需要建立两次TCP连接，client到LB，LB根据消息中的内容( 比如URL或者cookie中的信息 )来做出负载均衡的决定，接着建立LB到server的连接。<br><img src="./layer4VSlayer7_LB.png" alt="layer4VSlayer7_LB"></p><p>7层负载均衡有什么好处呢？ </p><ul><li>因为存在解包/封包的过程，比4层LB更加CPU‑intensive，但是却极少降低性能；</li><li>可以编写更加智能的负载均衡策略，比如根据URL、cookie中的信息等，甚至对接收到的内容做一些优化和修改，比如加密、压缩；</li><li>使用buffer的方式来缓解服务器连接慢的问题，从而提高性能</li><li>具有7层负载均衡功能的设备<strong>通常</strong>也被称为反向代理服务器（reverse‑proxy server）</li></ul><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>举个例子：<br><code>正向代理</code>：在大陆使用VPS访问Google的时候，通常会使用一个本地的代理服务器，浏览器的网络包会先经过本地的代理服务器，代理服务器会通过远在异国它乡的电脑来访问Google并返回消息；这就好比去附近的咖啡店要先问一下手机咖啡店在哪里一样，手机就是一个正向代理服务器。<br><code>反向代理</code>：当访问的请求到达Google时，Google那边也设置了一个代理服务器，它通过查看请求的URL，发现是想查找视频内容，于时把消息转给了视频搜索服务器（过程是我乱说的），这就好比你去朋友家做客，开门的却是个管家，问你找谁？这时候管家就是一个反向代理了。<br>关于反向代理的好处这里就不多介绍，感兴趣可以看<a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/" target="_blank" rel="noopener">这里</a></p><blockquote><p>其他OSI层也可以做反向代理</p></blockquote><h2 id="ingress"><a href="#ingress" class="headerlink" title="ingress"></a>ingress</h2><p>k8s <strong>对外</strong>暴露服务（service）主要有两种方式：<code>NotePort</code>, <code>LoadBalance</code>， 此外<code>externalIPs</code>也可以使各类service对外提供服务，但是当集群服务很多的时候，NodePort方式最大的缺点是会占用很多集群机器的端口；LB方式最大的缺点则是每个service一个LB又有点浪费和麻烦，并且需要k8s之外的支持； 而ingress则只需要一个NodePort或者一个LB就可以满足所有<code>service</code>对外服务的需求。</p><p>实际上，<code>ingress</code>相当于一个7层的负载均衡器，是k8s对反向代理的一个抽象。大概的工作原理也确实类似于Nginx，可以理解成在 Ingress 里建立一个个映射规则 , <code>ingress Controller</code> 通过监听 <code>Ingress</code>这个api对象里的配置规则并转化成 Nginx 的配置（kubernetes声明式API和控制循环） , 然后对外部提供服务。ingress包括：<strong>ingress controller</strong>和<strong>ingress resources</strong></p><p><code>ingress controller</code>：核心是一个deployment，实现方式有很多，比如nginx, Contour, Haproxy, trafik, Istio，需要编写的yaml有：Deployment, Service, ConfigMap, ServiceAccount（Auth），其中service的类型可以是NodePort或者LoadBalancer。</p><p><code>ingress resources</code>：这个就是一个类型为<code>Ingress</code>的k8s api对象了，这部分则是面向开发人员。</p><p>假设已经有两个服务部署在了k8s集群内部：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc,deploy</span><br><span class="line">NAME             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">svc/coffee-svc   ClusterIP   &lt;none&gt;       &lt;none&gt;        80/TCP    1m</span><br><span class="line">svc/tea-svc      ClusterIP   &lt;none&gt;       &lt;none&gt;        80/TCP    1m</span><br><span class="line"></span><br><span class="line">NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deploy/coffee   2         2         2            2           1m</span><br><span class="line">deploy/tea      1         1         1            1           1m</span><br></pre></td></tr></table></figure></p><p>配置 Ingress resources，即可实现多个service对外暴露服务:<br><strong>方式一：</strong><br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cafe-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line">  <span class="comment"># 配置七层域名</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">foo.bar.com</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line">      <span class="comment"># 配置Context Path</span></span><br><span class="line"><span class="attr">      - path:</span> <span class="string">/tea</span></span><br><span class="line"><span class="attr">        backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">tea-svc</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></span><br><span class="line">      <span class="comment"># 配置Context Path</span></span><br><span class="line"><span class="attr">      - path:</span> <span class="string">/coffee</span></span><br><span class="line"><span class="attr">        backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">coffee-svc</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></p><p>接着在hosts文件中添加一条解析规则：<code>${ingress_IP} foo.bar.com</code>，这时通过<strong>在浏览器</strong>中访问：<code>foo.bar.com/coffee</code>或者<code>foo.bar.com/tea</code>即可访问对应的后端service了。</p><blockquote><p>使用curl时的操作：<code>curl -H &quot;Host: foo.bar.com&quot; http://${ingress_IP}/coffee</code></p></blockquote><p><strong>方式二：</strong><br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cafe-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line">  <span class="comment"># 配置七层域名</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">tea.foo.bar.com</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">      - backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">tea-svc</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">coffee.foo.bar.com</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span>   </span><br><span class="line"><span class="attr">      - backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">coffee-svc</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></p><p>这时在hosts文件添加两条解析规则就可以在浏览器中访问了。此外，还可以配置TLS证书实现HTTPS访问，这里不再详述。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.youtube.com/watch?v=VicH6KojwCI" target="_blank" rel="noopener">YouTube视频</a></li><li><a href="https://www.alibabacloud.com/help/zh/doc-detail/86398.htm" target="_blank" rel="noopener">阿里云</a></li><li><a href="https://www.cnblogs.com/danbing/p/7459224.html" target="_blank" rel="noopener">https://www.cnblogs.com/danbing/p/7459224.html</a></li><li><a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/" target="_blank" rel="noopener">https://www.nginx.com/resources/glossary/layer-7-load-balancing/</a></li><li><a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/" target="_blank" rel="noopener">https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/</a></li><li><a href="https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0" target="_blank" rel="noopener">https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首先回顾了一下负载均衡和反向代理，随后介绍ingress，这部分的内容主要参考了YouTube上印度老哥的频道：&lt;a href=&quot;https://www.youtube.com/watch?v=VicH6KojwCI&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;KodeKloud的视频&lt;/a&gt;，直接看视频效果更佳。&lt;br&gt;
    
    </summary>
    
      <category term="容器云kubernetes" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="ingress" scheme="https://kiddie92.github.io/tags/ingress/"/>
    
  </entry>
  
  <entry>
    <title>SVM调参之股票预测</title>
    <link href="https://kiddie92.github.io/2019/05/19/SVM%E8%B0%83%E5%8F%82%E4%B9%8B%E8%82%A1%E7%A5%A8%E9%A2%84%E6%B5%8B/"/>
    <id>https://kiddie92.github.io/2019/05/19/SVM调参之股票预测/</id>
    <published>2019-05-19T09:47:30.000Z</published>
    <updated>2019-06-15T12:56:10.520Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>上篇博客讲解了SVM的算法精髓，这篇来牛刀小试一回，主要内容包括：1) 利用SVM分类来预测上证指数的涨跌；2) 试试SVM调参。<br><a id="more"></a></p></blockquote><h2 id="预测上证指数涨跌"><a href="#预测上证指数涨跌" class="headerlink" title="预测上证指数涨跌"></a>预测上证指数涨跌</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>预测股票涨跌和预测指数涨跌的原理是一样的，都是利用“<strong>历史数据</strong>”来推测未来的走势。股票数据单纯来看也就是时间序列。这里我们利用分类方法来构建预测模型：</p><ul><li>首先，获取过去长时间内上证指数的数据</li><li>计算这些数据的一些特征（features），比如：sma、wma、mom等</li><li>利用特征数据构建训练数据（train dataset）<code>x_train</code>，保留部分数据作为测试集（test dataset）</li><li>为数据打标签<code>y_train</code>：如果交易日当天的收盘价高于上一个交易日的收盘价，则为“+”数据，标签为“+1”，否则为“-1”</li><li>利用svm对上述带有标签的数据进行分类</li><li>给定测试数据，计算其特征数据，利用分类模型对其进行分类</li><li>对比分类结果（“+1”对应“涨”，“-1”对应“跌”）和实际数据的涨跌情况，若一致则说明<strong>分类准确/预测准确</strong></li></ul><p>这里需要注意的是<code>x_train</code>和<code>y_train</code>的对应关系<strong>至少要有一个交易日的时间差</strong>，否则，模型将毫无意义。</p><h3 id="写代码"><a href="#写代码" class="headerlink" title="写代码"></a>写代码</h3><p>有了想法后，写代码就比较简单了，这里参考了<strong>优矿</strong>上一个SVM代码。代码最中主要的部分就是数据处理部分，如下所示：（点击<a href="https://github.com/kiddie92/Learning_Tech/blob/master/SVM%E8%B0%83%E5%8F%82%E4%B9%8B%E8%82%A1%E7%A5%A8%E9%A2%84%E6%B5%8B/svm_quant.py.ipynb" target="_blank" rel="noopener">源代码</a>可以查看完整的源码文件）</p><blockquote><p>Tips:<br>如果github上无法直接查看ipython notebook，可以点击<a href="https://nbviewer.jupyter.org/" target="_blank" rel="noopener">这里</a>将所要查看的文件的URL拷贝进入即可查看。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(<span class="number">2</span>,len(close_pri)):</span><br><span class="line">    <span class="comment"># 取数据[-2]表示使用的特征是由今天之前的数据计算得到的</span></span><br><span class="line">    sma_data = talib.SMA(close_pri[:index],timeperiod=<span class="number">7</span>)[<span class="number">-2</span>]</span><br><span class="line">    wma_data = talib.WMA(close_pri[:index],timeperiod=<span class="number">7</span>)[<span class="number">-2</span>]</span><br><span class="line">    mom_data = talib.MOM(close_pri[:index],timeperiod=<span class="number">7</span>)[<span class="number">-2</span>]</span><br><span class="line">    </span><br><span class="line">    features = []</span><br><span class="line">    features.append(sma_data)</span><br><span class="line">    features.append(wma_data)</span><br><span class="line">    features.append(mom_data)</span><br><span class="line">    x_train.append(features)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对今天的交易进行打标签，涨则标记1，跌则标记-1</span></span><br><span class="line">    <span class="keyword">if</span> close_pri[index<span class="number">-1</span>] &lt; close_pri[index]:</span><br><span class="line">        label = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        label = <span class="number">-1</span></span><br><span class="line">    y_train.append(label)</span><br></pre></td></tr></table></figure><h2 id="SVM调参"><a href="#SVM调参" class="headerlink" title="SVM调参"></a>SVM调参</h2><p>原本计划以此为例，测试一下不同的参数得到的分类结果，最终会对预测模型的泛化能力产生什么样的影响，这里改成参数sklearn中svm分类算法的参数简介了。</p><p>首先来看一下sklearn中对svm分类问题给出的<strong>目标函数/loss</strong></p><p><code>sklearn</code>中给出的svc公式如下，对比上篇文章的式（18），可以发现，这里的参数<strong>$C$是式（18）的倒数</strong>：</p><script type="math/tex; mode=display">\min_{w,b,\zeta} \frac{1}{2}w^Tw+C\sum_{i=1}^{n} \zeta_i \\ subject to y_i(w^T\phi(x_i)+b) \ge 1-\zeta_i, \\ \zeta_i \ge 0, i=1,...n</script><p>这里理解起来类似于反演问题的<strong>正则化方法</strong>，整个目标函数可以看作是一个<strong>罚函数/penalty function</strong>，C可以看作是<strong>惩罚因子</strong>。那么，C越大，表示要求惩罚项越小，the vise versa，这里则表示分类越准确，距离是不是最大的稍微有那么一丢丢不那么重要。可以想象如果C是正无穷，则分类准确才是最最重要的，gutter的宽度已经不重要了，这时的模型必然会过拟合。<br>这么一来，还需要分析的参数只有<strong>核函数的参数</strong>了。<br>sklearn官方的参数如下（额，这么多，，），下面挑几个重要的来看一下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,</span><br><span class="line">  decision_function_shape=<span class="string">'ovr'</span>, degree=3, gamma=<span class="string">'auto'</span>, kernel=<span class="string">'rbf'</span>,</span><br><span class="line">  max_iter=-1, probability=False, random_state=None, shrinking=True,</span><br><span class="line">  tol=0.001, verbose=False)</span><br></pre></td></tr></table></figure></p><p><code>decision_function_shape</code>：‘ovo’ OR ‘ovr’，对于多分类问题，ovo表示两两做分类，ovr表示，其中一个类和其他所有做分类<br><code>degree</code>：就是多项式核函数里面的degree了<br><code>max_iter</code>：最大迭代次数，针对SMO算法<br><code>tol</code>：迭代总会有终止条件的<br><code>gamma</code>：rbf核函数的参数，gamma越大，表示精度越高，因为高斯函数会越高瘦嘛；过拟合也就越严重了，therefore，如果高斯核都搞不定的分类，那就别用svm了吧</p><h2 id="安装ta-lib"><a href="#安装ta-lib" class="headerlink" title="安装ta-lib"></a>安装ta-lib</h2><blockquote><p>安装ta-lib时遇到一点点坑，记录一下。</p></blockquote><p>按照官方<a href="https://mrjbq7.github.io/ta-lib/install.html" target="_blank" rel="noopener">ta-lib</a>的方法先安装依赖：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz</span><br><span class="line">tar -vxf ta-lib-0.4.0-src.tar.gz</span><br><span class="line"><span class="built_in">cd</span> ta-lib/</span><br><span class="line">./configure --prefix=/usr  <span class="comment"># 此处是选取lib文件存放位置</span></span><br></pre></td></tr></table></figure></p><p>试一下：<code>ipython3</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [1]: import talib</span><br><span class="line">In [2]:</span><br></pre></td></tr></table></figure></p><p>如果导入模块报错：<code>libta_lib.so.0: cannot open shared object file: No such file or directory</code>，则考虑是<code>/usr/lib/</code>下的的库文件没有被加载到系统环境变量内，导致导入模块的时候没有找到库文件<code>libta_lib.so.0</code>，添加环境变量即可：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib'</span> &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>实现了用svm做二分类来预测上证指数</li><li>对sklearn的SVC参数做了一定的分析</li><li>ta-lib这个模块在CentOS上安装时可能出现一些问题</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.joinquant.com/view/community/detail/6170c300d0aa8eb1aa3966a3b3d78d8e" target="_blank" rel="noopener">优矿SVM教程</a></li><li><a href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html" target="_blank" rel="noopener">sklearn-SVM参数说明</a></li><li></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;上篇博客讲解了SVM的算法精髓，这篇来牛刀小试一回，主要内容包括：1) 利用SVM分类来预测上证指数的涨跌；2) 试试SVM调参。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="量化投资" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="quant" scheme="https://kiddie92.github.io/tags/quant/"/>
    
  </entry>
  
  <entry>
    <title>支持向量机（SVM）</title>
    <link href="https://kiddie92.github.io/2019/05/10/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89/"/>
    <id>https://kiddie92.github.io/2019/05/10/支持向量机（SVM）/</id>
    <published>2019-05-10T15:11:42.000Z</published>
    <updated>2019-06-15T12:58:09.558Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>4月份容器云项目投产，天天加班，人也变懒也变胖了，好在项目投产还算顺利，就不吐槽托节奏的队友了。<br>如今NN算法基本可以解决SVM能解决的所有问题，但是学习SVM还是有必要滴<br>这篇文章是SVM算法的开篇，准备先介绍原理和简单的推导，展示出SVM的核心内容及理解，下一篇再以量化交易作为实战来看一下调参的过程。<br><a id="more"></a></p></blockquote><p>开篇的公式推导是少不了的，首先需要掌握一些基本的数学知识：</p><ol><li>点到直线的距离计算；</li><li>向量A到向量B的投影长度计算；</li><li>拉格朗日对偶。</li></ol><h2 id="线性可分支持向量机"><a href="#线性可分支持向量机" class="headerlink" title="线性可分支持向量机"></a>线性可分支持向量机</h2><p>现在有两类数据（这里假设是二维数据点），分布在二维平面上，如图1所示，以符号<code>+</code>代表一类数据，<code>-</code>代表另外一类数据。我们要做的事情就是画一条线将这两类数据分开来，而画线的原则是使距离这条线（图中虚线所示）<strong>最近的任意数据点</strong>到虚线的<strong>距离最大</strong>，或者说要让图中黑色实线间的<strong>宽度最大</strong>。需要说明的是，目前这里只考虑<strong>线性可分</strong>的情况。</p><p><img src="./p2.png" width="40%" height="40%"></p><p>我们使用以下公式来判断数据点是否落在<code>+</code>分类中，该式也被称为<code>Decision Rule</code></p><script type="math/tex; mode=display">\vec{w} \cdot \vec{u} + b \ge 0,  \text {THEN +} \tag{1}</script><p>式中$\vec{w}$表示垂直于分隔线（图中虚线）的<strong>向量</strong>，<script type="math/tex">\vec{u}</script>表示任意数据点的向量表示(unknown)，<script type="math/tex">b</script>表示一个与分割线相关的变量，所以，我们只要确定了<script type="math/tex">\vec w</script>和<script type="math/tex">b</script>就可以据此确定任意一个数据点属于哪个分类了。</p><blockquote><p>这里可以回顾一下解析几何中<strong>点到直线的距离</strong>公式以及推导过程，方便理解公式。</p></blockquote><p>接下来，我们<strong>规定</strong>，<code>+</code>数据代入Decision Rule得到的值大于1，而<code>-</code>数据代入Decision Rule得到的值小于-1，这个是可以做到的并且对于之后的操作是有好处的：</p><script type="math/tex; mode=display">\begin{cases} \vec{w} \cdot \vec{x_+} + b \ge +1, & \text {+ sample} \\ \vec{w} \cdot \vec{x_-} + b \le -1, & \text{-  sample} \end{cases} \tag{2}</script><p>mathematica convenient</p><p>引入变量：</p><script type="math/tex; mode=display">\begin{cases} y_i=+1, & \text for \space x_+ \\ y_i=-1, & \text for \space x_- \end{cases} \tag{3}</script><p>这标记数据其实挺有道理的，另外，数学表达上也更为便利，</p><script type="math/tex; mode=display">\begin{cases} y_i(\vec{w} \cdot \vec{x_+} + b) \ge 1 \\ y_i(\vec{w} \cdot \vec{x_-} + b) \ge 1 \end{cases} \tag{4}</script><p>哎呀～，<code>+</code>数据和<code>-</code>数据表达式上统一了，这就是<strong>mathematica convenient</strong>了：<br>这里需要说明一下，当数据点恰好落在gutter上（图1中的实黑线）时，有：<script type="math/tex">y_i(\vec{w} \cdot \vec{x_i} + b) = 1 , \space for \space x_i \space in \space the \space gutter \tag{5}</script></p><p>下面，我们想要让两条黑色实线之间的<strong>宽度</strong>（width of street）越大越好（seperate the samples as wide as possible.）如图1所示，计算<strong>宽度</strong>：距离分割线<strong>最近</strong>的<code>+</code>点用向量<script type="math/tex">\vec x_+</script>来表示，距离分割线<strong>最近</strong>的<code>-</code>点用向量<script type="math/tex">\vec x_-</script>来表示，那么<strong>宽度</strong>的计算就可以用向量<script type="math/tex">\lbrace \vec x_+-\vec x_- \rbrace</script>在向量<script type="math/tex">\vec w</script>上的投影来表示了，注意<script type="math/tex">\vec w</script>是<strong>垂直于分割线的向量</strong>，所以：</p><script type="math/tex; mode=display">WIDTH = (\vec x_+ - \vec x_-) \cdot \frac {\vec w}{||w||}  \tag{6}</script><p>其中，由公式(5)得到<script type="math/tex">\vec x_+ \cdot \vec w = 1-b</script> 而 <script type="math/tex">- \vec x_- \cdot \vec w = b+1</script>，所以：</p><script type="math/tex; mode=display">WIDTH = \frac {2}{||w||}  \tag{7}</script><p>得到了宽度的表达式后，要做的事情就变成了使<strong>宽度最大化</strong>：</p><script type="math/tex; mode=display">max {\frac {2}{||w||}} \to min \space ||w|| \to min \space \frac{1}{2}||w||_2^2  \tag{8}</script><p>此时问题已经转化为：</p><script type="math/tex; mode=display">\begin{cases} min \space \frac{1}{2}||w||_2^2 \\ y_i(\vec{w} \cdot \vec{x_i} + b) = 1, & \text for \space for \space x_i \space in \space the \space gutter \\  y_i(\vec{w} \cdot \vec{x_i} + b) > 1, & \text for \space other \space x_i  \end{cases} \tag{9}</script><p>上述问题的优化可以使用<strong>拉格朗日乘数法</strong>，定义L:</p><script type="math/tex; mode=display">L(\vec w,\vec b,\vec \alpha)=\frac{1}{2}||w||_2^2-\sum_{i=1}^m\alpha_i [y_i(\vec{w} \cdot \vec{x_i} + b) - 1] \tag{10}</script><blockquote><p>有些材料里面还会引入<script type="math/tex">\beta</script>项，似乎看起来没有必要。此外，为啥约束条件是被减去而不是加上呢，可以思考一下</p></blockquote><p>令：</p><script type="math/tex; mode=display">\frac {\partial L}{\partial w} = \vec w - \sum_i \alpha_iy_i\vec x_i =0 \implies  \vec w = \sum_i \alpha_iy_i\vec x_i \\ \frac {\partial L}{\partial b} = -\sum_i\alpha_iy_i=0 \implies \sum_i\alpha_iy_i=0 \tag{11}</script><p>这式(11)说明两点信息：1. <script type="math/tex">\vec w</script>只和个别数据相关，因为<script type="math/tex">\alpha_i</script>可能为0；2. <script type="math/tex">\alpha_i</script>之间是有约束的，加权和为0。</p><p>将式(11)代回式(10)，得到拉格朗日对偶问题：</p><script type="math/tex; mode=display">L(\vec \alpha)=\frac{1}{2}(\sum_i \alpha_iy_i\vec x_i)(\sum_j\alpha_jy_j\vec x_j)-\sum_i \alpha_iy_i\vec x_i\cdot(\sum_i \alpha_jy_j\vec x_j)-\sum_i \alpha_iy_ib + \sum_i \alpha_i  \tag{12}</script><p>下标<script type="math/tex">i,j</script>仅仅是为了区分，式(12)化简之后得到：</p><script type="math/tex; mode=display">L(\vec \alpha)=\sum_i \alpha_i- \frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j \vec x_i \vec x_j \tag{13}</script><p>数学家告诉我们，SVM里拉格朗日对偶是满足<strong>强对偶</strong>条件的，现在的问题已经转化为求<script type="math/tex">max \space L(\vec \alpha)</script>，并且该问题的解（注意需要满足约束条件）便是<strong>原始问题</strong>的解。在SVM算法中，式(13)的解法主要为<code>SMO算法</code>，由微软研究员提出。</p><p>推导至此，我们应当了解到：</p><ol><li>所谓<code>支持向量</code>就是这些对分割线（高维空间里是个超平面）产生影响的数据向量，这些数据点其实就是位于“黑色实线”上的点，或者叫做距离分割线的<strong>最近点</strong>，其他点的<script type="math/tex">\alpha_i=0</script>，对<script type="math/tex">\vec w</script>的确定没有贡献；</li><li>强对偶下，对偶问题的解就是原始问题的解，并且对偶问题始终是一个<strong>Concave优化问题</strong>，所以SVM的解一定是全局唯一解，<strong>不会陷入局部最小值</strong>；</li><li><code>Decision Rule</code>变为：<script type="math/tex">\sum_i \alpha_iy_i\vec x_i \cdot \vec u +b \ge 0, \text {THEN +}</script></li></ol><h2 id="目标函数和Hinge-Loss"><a href="#目标函数和Hinge-Loss" class="headerlink" title="目标函数和Hinge Loss"></a>目标函数和Hinge Loss</h2><p>上一部分介绍的是<strong>线性可分</strong>的支持向量机的推导，如果按照机器学习的“套路”，很难说清楚目标函数、优化算法这类概念。实际上，既然是二分类问题，那目标函数按理说应该是<strong>分类</strong>的准确性，优化的目标便是提升准确性。所以接下来稍微重构一下刚刚的问题，并简单介绍一下<strong>线性不可分（含有噪声信号）</strong>的情况如何使用SVM来做分类。</p><p>原问题：最小距离取最大</p><script type="math/tex; mode=display">\underset{\vec w,b}{\operatorname{arg max}} { \left \lbrace \frac {1}{||w||} \underset{i}{min}[y_i \cdot (w^T \cdot \vec x_i+b)] \right \rbrace} \tag{14}</script><p>现在：分类准确是前提，定义Hinge Loss，“最小距离取最大”反而变成了一个约束项：</p><script type="math/tex; mode=display">min \space L(f)=\sum_il(f(\vec x_i),y_i)+C||w||_2^2 , C 是常系数 \\ l(f(\vec x_i),y_i)=max(0,1-y_if(\vec x_i))  \\ f(\vec x_i)=\sum_iw\vec x_i+b=\begin{bmatrix} w \\ b \\ \end{bmatrix} \cdot \begin {bmatrix} x_i \\ 1 \\ \end{bmatrix}=W^TX \tag{15}</script><p>上式中，<script type="math/tex">l</script>便是目标函数/损失函数的关键，如果分类正确l应该为0，如果分类错误<script type="math/tex">l</script>将会变得很大（如下图蓝色实线所示），优化的方向便是使式(15)取最小值。如下图所示，蓝色实线表示Hinge Loss，绿色实线是理想情况下的loss，可以看到Hinge Loss在分类错误的情况下值会变的很大，而在分类正确的情况下还有部分缓冲（横轴在0.0-1.0之间的部分），这就有个好处了—Hinge Loss允许<strong>小部分的错误/非严格分类</strong>，一些资料里将这一特征称为<strong>惩罚部分</strong>，这也使得SVM拥有了天然的<strong>抗过拟合</strong>能力。</p><p><img src="./hingeloss.png" width="50%" height="50%"></p><p>接下来引入<strong>松弛因子(slack variable)</strong>的概念来换一种表达方式:</p><script type="math/tex; mode=display">\xi_i= max(0,1-y_if(\vec x_i)) \tag{16}</script><script type="math/tex; mode=display">\begin{cases} \xi_i \ge 0 \\ \xi_i \ge 1-y_if(\vec x_i) \implies y_if(\vec x_i) \ge 1-\xi_i \end{cases} \tag{17}</script><p><strong>当要求的是<script type="math/tex">\xi_i</script>的最小值</strong>时式(16)和(17)是等价的，loss function又可以写成下式，式(17)则是约束条件：</p><script type="math/tex; mode=display">min \space L(f)=\sum_i \xi_i+C||w||_2^2 \tag{18}</script><h2 id="核函数技巧"><a href="#核函数技巧" class="headerlink" title="核函数技巧"></a>核函数技巧</h2><blockquote><p>Dr. 李宏毅说SVM其实就是<code>Hinge Loss</code>+<code>Kernel Trick</code>，我认为Kernel Trick才是使SVM真正被广泛使用的关键所在。</p></blockquote><h3 id="拉格朗日对偶和核函数技巧的关系"><a href="#拉格朗日对偶和核函数技巧的关系" class="headerlink" title="拉格朗日对偶和核函数技巧的关系"></a>拉格朗日对偶和核函数技巧的关系</h3><p>原问题转换为拉格朗日对偶问题还有一个非常强大的好处，由式(13)可知分割平面仅仅和<script type="math/tex">x_i \cdot x_j</script>相关，那么，将<script type="math/tex">x_i</script> 和 <script type="math/tex">x_j</script>做相同的feature mapping是不会影响分类结果的，于是式(13)可以写成如下形式：</p><script type="math/tex; mode=display">L(\vec \alpha)=\sum_i \alpha_i- \frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j \Phi(\vec x_i) \cdot \Phi(\vec x_j) \tag{19}</script><p>两个向量的点乘是可以在某种程度上衡量两个<strong>向量的相似度</strong>的，这里数学家告诉我们只要满足Mercer’s Theory，就可以设计出一个<strong>核函数</strong>，对于非唯一的feature mapping函数，都有下面的式子成立：</p><script type="math/tex; mode=display">K(<x_i,x_j>)=\Phi (x_i) \cdot \Phi(x_j)</script><p>也即，我们不必要知道具体的函数<script type="math/tex">\Phi(x)</script>，只要将<script type="math/tex">x_i</script>和<script type="math/tex">x_j</script>代入核函数就行了，而这样计算明显比先做mapping再做inner product要快很多（虽然结果是等价的），这便是<code>Kernel Trick</code>。这样做的好处是可以对数据点进行升维，在低维空间中不可分的数据点，在高维空间则是可分的（反正总有办法让数据可分），坏处自然就是模型容易过拟合了。</p><h3 id="各类核函数"><a href="#各类核函数" class="headerlink" title="各类核函数"></a>各类核函数</h3><p>多项式核：</p><script type="math/tex; mode=display">K(\vec x_i,\vec x_j)= (\vec x_i \cdot \vec x_j+b)^n</script><p>径向基函数核（RBF）：维度太高，容易过拟合</p><script type="math/tex; mode=display">K(\vec x_i,\vec x_j)=exp(-\frac {1}{2\sigma^2}||\vec x_i-\vec x_j||_2^2)</script><p>Sigmiod核：可以理解成只有一个Hidden Layer的NN</p><script type="math/tex; mode=display">K(\vec x_i,\vec x_j)=tanh(\vec x_i \cdot \vec x_j)</script><h2 id="SVM-与-SVR"><a href="#SVM-与-SVR" class="headerlink" title="SVM 与 SVR"></a>SVM 与 SVR</h2><p>用支持向量机来做回归问题其实也是可以的，不过并不是回归问题的主流方法。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>所谓<code>支持向量</code>就是这些对分割线（高维空间里是个超平面）产生影响的数据向量，这些数据点其实就是位于“黑色实线”上的点，或者叫做距离分割线的<strong>最近点</strong>，其他点的<script type="math/tex">\alpha_i=0</script>，对<script type="math/tex">\vec w</script>的确定没有贡献；</li><li>强对偶下，对偶问题的解就是原始问题的解，并且对偶问题始终是一个<strong>Concave优化问题</strong>，所以SVM的解一定是全局唯一解，<strong>不会陷入局部最小值</strong>；</li><li><code>Decision Rule</code>变为：<script type="math/tex">\sum_i \alpha_iy_i\vec x_i \cdot \vec u +b \ge 0, \text {THEN +}</script></li><li>超平面就是data point的线性组合；</li><li>SVM拥有了天然的去outliers抗过拟合能力；</li><li>线性不可分的问题，可以通过核函数的方法将低维问题进行升维来解决；</li><li>比较常用的核函数有多项式核函数以及高斯核函数；</li><li>SVM也可以解决回归问题，对应SVR。</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>Vapnik V., “The nature of statistical learning theory,” Springer-Verlag, New-York, 1995.</li><li>Vapnik V., “Statistical learning theory,” John Wiley, New-York, 1998.</li><li>Vapnik V., “The support vector method of function estimation,” In Nonlinear Modeling: advanced black-box techniques, Suykens</li><li><a href="https://www.youtube.com/watch?v=QSEPStBgwRQ" target="_blank" rel="noopener">https://www.youtube.com/watch?v=QSEPStBgwRQ</a></li><li><a href="https://www.youtube.com/watch?v=_PwhiWxHK8o&amp;pbjreload=10" target="_blank" rel="noopener">https://www.youtube.com/watch?v=_PwhiWxHK8o&amp;pbjreload=10</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;4月份容器云项目投产，天天加班，人也变懒也变胖了，好在项目投产还算顺利，就不吐槽托节奏的队友了。&lt;br&gt;如今NN算法基本可以解决SVM能解决的所有问题，但是学习SVM还是有必要滴&lt;br&gt;这篇文章是SVM算法的开篇，准备先介绍原理和简单的推导，展示出SVM的核心内容及理解，下一篇再以量化交易作为实战来看一下调参的过程。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes网络和CNI简介</title>
    <link href="https://kiddie92.github.io/2019/04/25/kubernetes%E7%BD%91%E7%BB%9C%E5%92%8CCNI%E7%AE%80%E4%BB%8B/"/>
    <id>https://kiddie92.github.io/2019/04/25/kubernetes网络和CNI简介/</id>
    <published>2019-04-25T12:30:50.000Z</published>
    <updated>2019-06-15T12:55:34.936Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>kubernetes提供了出色的容器编排能力，同时开放了网络、存储、运行时的接口，打造了云原生生态的同时，也顺手一统了容器云的天下。网络是云服务的基础和核心之一，就网络插件而言，市面上就有很多，kubernetes提供了CNI为所有网络插件提供接口。下面简单介绍一下kubernetes的容器网络接口。<br><a id="more"></a></p></blockquote><h2 id="Pod网络"><a href="#Pod网络" class="headerlink" title="Pod网络"></a>Pod网络</h2><p>对于任何kubernetes网络方案，都需要满足以下<strong>需求</strong>：</p><ol><li>每个Pod都拥有一个独立的IP地址，而且假定所有的pod都在一个可以直接连通的、扁平的网络空间中；</li><li>用户不需要额外考虑如何建立Pod之间的连接，也不需要考虑将容器端口映射到主机端口等问题；</li><li>网络要求：</li></ol><ul><li>所有的容器都可以在不用NAT的方式下同别的容器通讯</li><li>所有节点都可在不用NAT的方式下同所有容器通讯</li><li>容器的地址和其他宿主机和容器看到的地址是同一个地址</li></ul><h3 id="Pod网络基本原理"><a href="#Pod网络基本原理" class="headerlink" title="Pod网络基本原理"></a>Pod网络基本原理</h3><p>容器通过使用linux内核提供的Cgroups和Namespaces技术实现了相互之间的网络、存储等资源的隔离与限制。对于网络，kubernetes项目中的Pod则通过让一组用户容器和pause容器/infra容器共享一个network namespace的方式，使一个Pod内的容器都使用了一个网络栈。而一个 Network Namespace 的网络栈包括：网卡（Network Interface）、回环设备（Loopback Device）、路由表（Routing Table）和 iptables 规则。所以，不难想象，Pod的网络和一台虚拟机的网络栈配置起来实际上是类似的，比如同样需要虚拟网卡，IP、MAC地址等，并且每个Pod都有自己唯一的网络栈。当所有的Pod都有了自己的网络栈后，如果想要连接两个Pod进行通信，则类似于其他任何网络架构，需要配置交换机、路由器等，并为其规划IP，路由等信息。如果是对于物理机，我们可以使用网线、交换机、路由器这些设备进行连接，但在Pod中显然需要其他方式。</p><blockquote><p>刚开始接触容器的时候，觉得这种设计好奇怪，本来进程间通信挺容易的，如今用namespace做隔离，再想办法让隔离的进程进行网络通信…~_~!! </p></blockquote><h3 id="Pod网络类型"><a href="#Pod网络类型" class="headerlink" title="Pod网络类型"></a>Pod网络类型</h3><p>kubernetes Pod的网络方案有很多，最典型的就是Flannel的三种后端实现方式了（UDP、VxLan、host-gw），讨论这些则主要是在关注容器跨主机通信的问题。而这里主要讨论的则是Pod的内部的网卡如何创建，又如何将网络数据包在宿主机和容器之间传递。</p><p><img src="./Pc1.png" alt="容器网络类型"></p><p>图片来自<a href="https://thenewstack.io/hackers-guide-kubernetes-networking/" target="_blank" rel="noopener">这里</a></p><ol><li>虚拟网桥：创建一个虚拟网卡对（veth pair），一头在容器内，一头在宿主机的root namespace内，并且使用Linux bridge（网桥）或者OpenvSwitch（OVS）来连接两个不同namespace内的网卡对。这样一来，容器内发出的网络数据包，可以通过网桥进入宿主机网络栈，而发往容器的网络数据包也可以经过网桥进入容器。例如，docker项目中的docker0、kubernetes项目中的cni0都是网桥设备。<blockquote><p>veth pair有个很好的特性，两张虚拟网卡总是成对的出现，并且，从其中一个”网卡”发出的数据包可以直接出现在与它对应的另一张”网卡”上，有点像物理的”虫洞”嚯</p></blockquote></li><li>多路复用：如图所示，使用一个中间网络设备，暴露多个虚拟网卡接口，容器网卡都可以接入这个中间设备，并通过mac地址/IP地址来区分packet应该转发给哪一个容器设备。<blockquote><p>多路复用：物理上，一根光纤内，可以同时跑很多很多不同频率的光波，这就是多路复用的其中一种实现方式。</p></blockquote></li><li>硬件交换：还有个“比较直接”的方法就是为每个Pod分配一个虚拟网卡，这样一来，Pod与Pod之间的连接关系就会变的非常清晰，因为近乎物理机之间的通信基础。如今大多数网卡都支持SR-IOV功能，该功能将单一的物理网卡虚拟成多个VF接口，每个VF接口都有单独的虚拟PCIe通道，这些虚拟的PCIe通道共用物理网卡的PCIe通道。</li></ol><h2 id="kubernetes-CNI"><a href="#kubernetes-CNI" class="headerlink" title="kubernetes CNI"></a>kubernetes CNI</h2><h3 id="工作原理简介"><a href="#工作原理简介" class="headerlink" title="工作原理简介"></a>工作原理简介</h3><p>CNI是Container Network Interface的缩写，它是一个通用的容器网络插件的k8s<strong>网络接口</strong>，开源社区里已经有了很多实现容器网络的方案，不同的网络实现方案在k8s内都是以插件调用的形式工作，所以这里需要一个统一的标准接口。如果将k8s的Pod视为一台“虚拟机”，那么网络插件的工作就是管理这台虚拟机的网络栈，包括给这台虚拟机插入网卡、配置路由、IP等；而CNI的工作则是对接<strong>网络插件</strong>和<strong>kubelet</strong>容器运行时管理工具（对于docker容器运行时来说实际上是dockershim），主要体现在Pod的创建和删除过程：</p><ul><li>CNI加载目录<code>/etc/cni/net.d/</code>下的配置文件，比如：10-calico.conflist</li><li>Pod Create<ul><li>使用macvlan二进制文件创建网卡</li><li>调用dhcp二进制文件获取IP</li><li>将网卡放入pod network namespace</li></ul></li><li>Pod Delete<ul><li>调用dhcp二进制文件释放IP</li><li>调用macvlan二进制文件删除网卡</li><li>结束容器</li></ul></li></ul><p>CNI 配置文件，给CRI使用的，比如dockershim<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">root@master8088:~<span class="comment"># cat /etc/cni/net.d/10-calico.conflist </span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"k8s-pod-network"</span>,</span><br><span class="line">  <span class="string">"cniVersion"</span>: <span class="string">"0.3.0"</span>,</span><br><span class="line">  <span class="string">"plugins"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"calico"</span>,</span><br><span class="line">      <span class="string">"log_level"</span>: <span class="string">"info"</span>,</span><br><span class="line">      <span class="string">"datastore_type"</span>: <span class="string">"kubernetes"</span>,</span><br><span class="line">      <span class="string">"nodename"</span>: <span class="string">"master8088"</span>,</span><br><span class="line">      <span class="string">"mtu"</span>: 1500,</span><br><span class="line">      <span class="string">"ipam"</span>: &#123;</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"host-local"</span>,</span><br><span class="line">        <span class="string">"subnet"</span>: <span class="string">"usePodCidr"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"policy"</span>: &#123;</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"k8s"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"kubernetes"</span>: &#123;</span><br><span class="line">        <span class="string">"kubeconfig"</span>: <span class="string">"/etc/cni/net.d/calico-kubeconfig"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"portmap"</span>,</span><br><span class="line">      <span class="string">"snat"</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="string">"capabilities"</span>: &#123;<span class="string">"portMappings"</span>: <span class="literal">true</span>&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="可执行文件"><a href="#可执行文件" class="headerlink" title="可执行文件"></a>可执行文件</h3><p>CNI官方维护的插件包括以下几个，对于已经搭建好的k8s，cni插件可以在<code>/opt/cni/bin/</code>文件夹下查看：<br>CNI的基础可执行文件按照功能可以划分为三类：<br><strong>Main插件：创建具体网络设备</strong><br><code>bridge</code>：网桥设备，连接container和host<br><code>ipvlan</code>：为容器增加ipvlan网卡<br><code>loopback</code>：lo设备<br><code>macvlan</code>：为容器创建一个MAC地址<br><code>ptp</code>：创建一对Veth Pair<br><code>vlan</code>：分配一个vlan设备<br><code>host-device</code>：将已存在的设备移入容器内</p><p><strong>IPAM插件：负责分配IP地址</strong><br><code>dhcp</code>：容器向DHCP服务器发起请求，给Pod发放或回收IP地址<br><code>host-local</code>：使用预先配置的IP地址段来进行分配<br><code>static</code>：为容器分配一个静态IPv4/IPv6地址，主要用于debug</p><p><strong>meta插件：并非单独使用</strong><br><code>bandwidth</code>：使用Token Bucket Filter（TBF）来限流的插件<br><code>flannel</code>：flannel网络方案的CNI插件，对应于flannel配置文件<br><code>portmap</code>：通过iptables配置端口映射<br><code>sbr</code>：为网卡设置source based routing<br><code>tuning</code>：通过sysctl调整网络设备参数<br><code>firewall</code>：通过iptables给容器网络的进出流量进行一系列限制</p><blockquote><p>目前kubernetes项目中的Pod只能加载一个CNI的配置，如果需要一个POD使用多网卡多网络方案是不可以的。</p></blockquote><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验内容：go安装社区维护的CNI相关插件，在linux主机上创建一个network namespace，再利用安装的网络插件给这个linux network namespace配置好网络。<strong>实验方法教程参考的是<a href="https://github.com/containernetworking/cni/tree/master/cnitool" target="_blank" rel="noopener">这里</a></strong></p><p><strong>安装cni插件：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p go/src/github.com/containernetworking/</span><br><span class="line"><span class="built_in">cd</span> go/src/github.com/containernetworking/</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/containernetworking/plugins.git </span><br><span class="line">git <span class="built_in">clone</span> https://github.com/containernetworking/cni.git </span><br><span class="line"><span class="built_in">cd</span> plugins</span><br><span class="line">./build_linux.sh</span><br><span class="line"><span class="built_in">cd</span> ../cni/cnitool</span><br><span class="line">go build cnitool.go</span><br></pre></td></tr></table></figure></p><p><strong>linux上创建一个network namespace：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip netns add Mytest</span><br></pre></td></tr></table></figure></p><p><strong>设置网络参数：</strong><br><code>vi /etc/cni/net.d/10-myptp.conf</code><br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"cniVersion"</span>: <span class="string">"0.3.1"</span>,</span><br><span class="line">  <span class="attr">"name"</span>: <span class="string">"myptp"</span>,</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"ptp"</span>,</span><br><span class="line">  <span class="attr">"ipMasq"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"ipam"</span>: &#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"host-local"</span>,</span><br><span class="line">    <span class="attr">"subnet"</span>: <span class="string">"172.16.29.0/24"</span>,</span><br><span class="line">    <span class="attr">"routes"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"dst"</span>: <span class="string">"0.0.0.0/0"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>模拟给容器配置网络：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo CNI_PATH=../../plugins/bin ./cnitool add myptp /var/run/netns/Mytest</span><br></pre></td></tr></table></figure></p><p>返回值<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"cniVersion"</span>: <span class="string">"0.3.1"</span>,</span><br><span class="line">    <span class="attr">"interfaces"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"vethe6180c75"</span>,</span><br><span class="line">            <span class="attr">"mac"</span>: <span class="string">"ea:d0:00:22:ce:33"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"eth0"</span>,</span><br><span class="line">            <span class="attr">"mac"</span>: <span class="string">"56:20:72:2b:5a:7e"</span>,</span><br><span class="line">            <span class="attr">"sandbox"</span>: <span class="string">"/var/run/netns/Mytest"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"ips"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"version"</span>: <span class="string">"4"</span>,</span><br><span class="line">            <span class="attr">"interface"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"address"</span>: <span class="string">"172.16.29.4/24"</span>,</span><br><span class="line">            <span class="attr">"gateway"</span>: <span class="string">"172.16.29.1"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"routes"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"dst"</span>: <span class="string">"0.0.0.0/0"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"dns"</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>测试网络是否可用：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ip -n Mytest addr</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">3: eth0@if12: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default </span><br><span class="line">    link/ether 56:20:72:2b:5a:7e brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.16.29.4/24 brd 172.16.29.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::5420:72ff:fe2b:5a7e/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></p><p>进入namespace，ping一下百度的DNS<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ip netns <span class="built_in">exec</span> Mytest ping -c 2 180.76.76.76</span><br><span class="line">PING 180.76.76.76 (180.76.76.76) 56(84) bytes of data.</span><br><span class="line">64 bytes from 180.76.76.76: icmp_seq=1 ttl=49 time=27.4 ms</span><br><span class="line">64 bytes from 180.76.76.76: icmp_seq=2 ttl=49 time=26.3 ms</span><br><span class="line"></span><br><span class="line">--- 180.76.76.76 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1001ms</span><br><span class="line">rtt min/avg/max/mdev = 26.374/26.916/27.458/0.542 ms</span><br></pre></td></tr></table></figure></p><p><strong>清除：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo CNI_PATH=../../plugins/bin ./cnitool del myptp /var/run/netns/Mytest`</span><br><span class="line">sudo ip netns del Mytest</span><br></pre></td></tr></table></figure></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>容器网络实现了容器间、容器和宿主机间、容器和服务间的通信；</li><li>CNI主要提供了容器运行时和网络插件之间的协作；</li><li>CNI主要以插件调用的方式工作。</li><li>自己实现一个网络方案，除了需要实现网络本身（例如：flanneld），还需要该网络对应的CNI插件（例如：flannel）。</li></ol><p>最后多说一句，所谓的云服务其实就是基于网络的服务，好好规划网络可以充分利用数据中心的资源，只有充分利用数据中心的资源，才能称之为云计算。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/containernetworking/cni/tree/master/cnitool" target="_blank" rel="noopener">https://github.com/containernetworking/cni/tree/master/cnitool</a></li><li><a href="https://thenewstack.io/hackers-guide-kubernetes-networking/" target="_blank" rel="noopener">https://thenewstack.io/hackers-guide-kubernetes-networking/</a></li><li><a href="http://www.cnblogs.com/YaoDD/p/7419383.html" target="_blank" rel="noopener">http://www.cnblogs.com/YaoDD/p/7419383.html</a></li><li><a href="https://github.com/containernetworking/plugins" target="_blank" rel="noopener">https://github.com/containernetworking/plugins</a></li><li><a href="https://time.geekbang.org/column/article/64948" target="_blank" rel="noopener">https://time.geekbang.org/column/article/64948</a></li><li><a href="https://www.zhihu.com/question/24950671" target="_blank" rel="noopener">https://www.zhihu.com/question/24950671</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;kubernetes提供了出色的容器编排能力，同时开放了网络、存储、运行时的接口，打造了云原生生态的同时，也顺手一统了容器云的天下。网络是云服务的基础和核心之一，就网络插件而言，市面上就有很多，kubernetes提供了CNI为所有网络插件提供接口。下面简单介绍一下kubernetes的容器网络接口。&lt;br&gt;
    
    </summary>
    
      <category term="容器云kubernetes" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="k8s网络插件" scheme="https://kiddie92.github.io/tags/k8s%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>k8s关键组件及其高可用方案</title>
    <link href="https://kiddie92.github.io/2019/04/18/k8s%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E5%8F%8A%E5%85%B6%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88/"/>
    <id>https://kiddie92.github.io/2019/04/18/k8s关键组件及其高可用方案/</id>
    <published>2019-04-18T12:27:58.000Z</published>
    <updated>2019-06-15T12:55:02.788Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>如今，业务上云已经不是什么新鲜事物了，容器云也已在大大小小的公司实现落地，而kubernetes（k8s）也已登上容器编排调度的霸主地位…<br><a id="more"></a></p></blockquote><h1 id="如何搭建高可用k8s集群"><a href="#如何搭建高可用k8s集群" class="headerlink" title="如何搭建高可用k8s集群"></a>如何搭建高可用k8s集群</h1><p>如今，业务上云已经不是什么新鲜事物了，容器云也已在大大小小的公司实现落地，而kubernetes（k8s）也已登上容器编排调度的霸主地位。越来越多的企业开始部署k8s集群，无论是业务应用还是中间件服务，甚至分布式计算任务，k8s集群都能轻松驾驭，然而，企业场景下稳定并且高可用的k8s集群部署也并非毫无挑战，这篇文章就根据笔者参与的企业级容器云建设项目，分享几点高可用k8s集群搭建的经验。</p><h2 id="何谓高可用"><a href="#何谓高可用" class="headerlink" title="何谓高可用"></a>何谓高可用</h2><p>高可用对于底层的IT基础设施来说是基本要求，这意味着云基础设施三个方面的需求：</p><ul><li><strong>容错：</strong>即使出了一些错误（无论是天灾还是人祸），底层系统依旧工作</li><li><strong>服务可用：</strong>跑在云上的服务必须一直是可用的状态</li><li><strong>数据安全：</strong>云上的数据确保健全、可用</li></ul><p>那么在设计上，我们就得要求<strong>“no single point of failure”</strong>：路由、防火墙、负载均衡、反向代理以及监控系统等在网络和应用层面上必须全部是冗余设计，以此来保证最佳的可用性。 下面，浅谈一下k8s高可用集群是如何组建的。</p><h2 id="k8s关键组件及其高可用方案"><a href="#k8s关键组件及其高可用方案" class="headerlink" title="k8s关键组件及其高可用方案"></a>k8s关键组件及其高可用方案</h2><p>首先，看一下架构设计（参考资料2），图中已经将<strong>高可用k8s集群</strong>各个组件的功能以及通讯调用关系清晰的展示出来了，下面我将分别从<strong>管理平面</strong>、<strong>执行平面</strong>和<strong>数据平面</strong>三个部分来简单说明一下该高可用架构方案以及各个组件的功能。<br><img src="./k8sHA.jpg" alt="image"></p><h3 id="管理平面"><a href="#管理平面" class="headerlink" title="管理平面"></a>管理平面</h3><ol><li><p><strong>apiserver:</strong> <code>apiserver</code>是k8s集群的入口，为了使用方便，<code>kubectl</code>作为其客户端供用户使用。为了实现高可用，在3个机器上分别以静态Pod的方式部署了<code>apiserver</code>并挂载在同一个loadbalancer上，如此，其与其他组件的联系都经由这个负载均衡器来做转发（图中黑色连线），这样也保证了每一个用户命令都有且仅有一个<code>apiserver</code>来响应，并且理论上只要还有一个Pod是可用的，该组件的服务就没有问题，再加上k8s的Pod有自愈能力，<code>apiserver</code>高可用可以说是能够保证的。</p><blockquote><p>这里多说两句，k8s的API至关重要，而一些针对k8s做的二次开发其实也主要是围绕着k8s<strong>声明式API</strong>做一些CRUD，而面向API编程也是你从k8s用户向玩家进阶的必经之路。</p></blockquote></li><li><p><strong>controller managers:</strong> k8s自愈能力的关键所在，<code>controller managers</code>提供一种reconciliation的功能，简单来说就是该组件会无限循环地去通过<code>apiserver</code>来查看api资源的状态，并将其实际状态转变为api资源声明中的状态。比如，一个deployment设置了replicas为3，而由于某些原因集群中运行了5个这样的Pod时，<code>controller managers</code>就会触发工作并且调用api来删除2个Pod。同样，在k8s的master节点上，每个节点以静态Pod部署一个组件以达到高可用的目的。</p></li><li><p><strong>scheduler:</strong> 该组件负责集群内部Pod的调度，主要根据集群node资源情况来平衡每个node的任务量，此外，还支持用户对Pod调度的自定义限制规则，比如NodeSelector、affinity规则等。该组件的高可用部署方案也是在每一个master节点上部署一个静态Pod。</p></li></ol><blockquote><p>组件<code>controller managers</code>和<code>scheduler</code>的选主是通过<code>etcd</code>来实现的：当一个副本不能工作时，其余副本会更新endpoint至etcd，而etcd只会接受其中一个更新请求，从而实现leader election。至于为什么需要选主，这里就留作一道思考题好了。</p></blockquote><h3 id="执行平面"><a href="#执行平面" class="headerlink" title="执行平面"></a>执行平面</h3><p>执行平面针对的就是node/slave节点，这里实际上就没有高可用一说了，即便如此，还是简单介绍一下图中出现的几个组件吧。</p><ol><li><strong>container runtime:</strong> 每个节点都需要一个容器运行时来执行容器，比如Docker。非pod启动。</li><li><strong>kubelet:</strong> 用于执行apiserver下达的命令，也可以重启启动失败的pod。</li><li><strong>kube-proxy:</strong> 通过修改<code>iptables</code>来达到网络代理、负载均衡的效果，在k8s中以<code>Service</code>作为代表。比如在使用NodePort进行对外提供服务时，所有node/slave节点都会生成特定的<code>iptables</code>，当该服务被删除或者节点断网时，<code>iptables</code>也会被清除。</li></ol><h3 id="数据平面"><a href="#数据平面" class="headerlink" title="数据平面"></a>数据平面</h3><p><strong>etcd</strong></p><ul><li>对于高可用集群来说，集群的数据至关重要，Kubernetes将<code>etcd</code>作为数据存储中心，其存储了所有集群相关的信息，比如：pod、node、cm… 鉴于底层系统的<strong>高可靠性</strong>，数据决不能丢。</li><li>如图所示，<code>etcd</code>在每个master节点上部署了一个实例，以保证其高可用性，实践证明，etcd挂载本地ssd的方式会大幅提高<strong>超大规模</strong>（节点大于2000）集群性能（参考资料6）。</li><li><code>etcd</code>官方给的部署模式是奇数个（大于等于3）就好了，推荐部署5个节点，这就不得不提<code>etcd</code>的选主协议/逻辑/算法<strong>Raft</strong>，这里有个非常生动的<a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">动画</a>值得一看。此外，还需要注意的是所谓<strong>“脑裂”</strong>问题，这里的“脑裂”是指<code>etcd</code>集群出现两个甚至多个leader，如果你也是这样理解脑裂的，那就大可放心使用，因为<a href="https://coreos.com/etcd/docs/latest/op-guide/failures.html" target="_blank" rel="noopener">there is no “split-brain” in etcd</a>。</li><li>默认的etcd参数不太适合disk io比较低的场景，由其是在测试环境，所以可以调优一下：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ETCD_ELECTION_TIMEOUT=5000 <span class="comment">#default 1000ms</span></span><br><span class="line">ETCD_HEARTBEAT_INTERVAL=250 <span class="comment">#default 100ms</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>部署高可用k8s集群对于企业级云平台来说是一个根本性的原则；</li><li><strong>容错</strong>、<strong>服务可用</strong>和<strong>数据安全</strong>是高可用基础设施的关键；</li><li>文中简单介绍了部分k8s组件，实际上还有一些必须组件，如：网络插件、DNS插件等</li><li>对于Business来说，高可用并不仅仅是一个集群就可以做到的，更复杂的还有如<strong>多网络域部署</strong>甚至<strong>异地多数据中心部署</strong>。</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.criticalcase.com/blog/5-reasons-why-you-need-high-availability-for-your-business.html" target="_blank" rel="noopener">https://www.criticalcase.com/blog/5-reasons-why-you-need-high-availability-for-your-business.html</a></li><li><a href="https://elastisys.com/2018/01/25/setting-highly-available-kubernetes-clusters/" target="_blank" rel="noopener">https://elastisys.com/2018/01/25/setting-highly-available-kubernetes-clusters/</a></li><li><a href="https://coreos.com/etcd/docs/latest/op-guide/failures.html" target="_blank" rel="noopener">https://coreos.com/etcd/docs/latest/op-guide/failures.html</a></li><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/</a></li><li><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">http://thesecretlivesofdata.com/raft/</a></li><li><a href="https://openai.com/blog/scaling-kubernetes-to-2500-nodes/" target="_blank" rel="noopener">https://openai.com/blog/scaling-kubernetes-to-2500-nodes/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;如今，业务上云已经不是什么新鲜事物了，容器云也已在大大小小的公司实现落地，而kubernetes（k8s）也已登上容器编排调度的霸主地位…&lt;br&gt;
    
    </summary>
    
      <category term="容器云kubernetes" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="高可用" scheme="https://kiddie92.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
      <category term="云计算架构" scheme="https://kiddie92.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CNN网络参数的计算</title>
    <link href="https://kiddie92.github.io/2019/03/25/CNN%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E7%9A%84%E8%AE%A1%E7%AE%97/"/>
    <id>https://kiddie92.github.io/2019/03/25/CNN网络参数的计算/</id>
    <published>2019-03-25T14:58:59.000Z</published>
    <updated>2019-06-15T12:59:34.519Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>前几天听室友给我讲算法岗的面经，其中面试官就问了一个小问题，“给出CNN网络的参数（<strong>可学习的</strong>）个数如何计算”，今天就来计算一下好了。<br><a id="more"></a></p></blockquote><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p><strong>可学习参数</strong>顾名思义就是指CNN中需要学习/更新的变量，因为CNN的网络架构设计中会引入很多需要被学习出来的变量，比如：<code>hidden layer</code>中的神经元个数便直接和仿射变换的参数个数相关，而现在的问题是把这些<strong>可学习</strong>的变量的个数统计出来。</p><h2 id="卷积神经网络架构"><a href="#卷积神经网络架构" class="headerlink" title="卷积神经网络架构"></a>卷积神经网络架构</h2><p>卷积神经网络在计算机视觉领域有比较多的应用，下图便是一个图片识别的网络架构示例图（工业界使用的模型更复杂）。</p><p><img src="./CNN.png" alt="CNN"></p><p>上图描述了卷积神经网络在进行<strong>正向计算/正向传播</strong>时的流程/架构，如图所示，当输入一个”小轿车”的图片时，我们希望经过一个函数$f(x)$各种计算后，能够输出“CAR”这个词。那么该如何计算呢？</p><ul><li><strong>输入层</strong>（input）：<br>就是读取图片，将图片用数字化的矩阵来表示。</li><li><strong>卷积（convolution）</strong>：<br>选用卷积核（filter，可以是多个）对图片的多个通道进行卷积操作（element-wise的相乘）。卷积计算会使图片的长宽变小，但是”高度”变大（如图中的图片逐渐变”厚”），这是因为使用的卷积核（filter）较多，使得计算得到的图片通道数（channels）也会增加。<blockquote><p>卷积操作其实可以理解为简化版的”连接层”，部分神经元才可以和下一层的部分神经元进行连接。</p></blockquote></li><li><strong>激活（activation）</strong>：<br>该操作主要是对之前的卷积计算结果做非线性处理，<a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" target="_blank" rel="noopener">万能逼近原理</a>告诉我们这种线性和非线性计算的组合可以拟合所有复杂的函数。常用的非线性处理函数/激活函数有Sigmoid、Relu、Leaky ReLU、tanh等，更多内容可以参考<a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">这里</a>。</li><li><strong>池化（pooling）</strong>：<br>对非线性化后的高维矩阵进行”减采样”，同样以一定步长逐步将矩阵中的”元素块（例如：<script type="math/tex">9 \times 9</script>）”仅使用一个数来代表，比如：取”元素块”中的最大值、平均值等计算方式。<blockquote><p>降采样可以减少后续的计算量还可以一定程度防止过拟合。</p></blockquote></li><li><strong>拉平(Flatten)</strong>：<br>将高维矩阵”拉平”，转换为一维矩阵，元素依次排序。</li><li><strong>全连接（Fully Connected）</strong>:<br>设置下一层神经元的个数，并使用仿射变换<script type="math/tex">y_i = \vec W_i \cdot \vec x+b_i</script>得到下一层神经元的值，因为两层之间的神经元会全部连接起来，所及叫做全连接。</li><li><strong>输出层计算分类概率（Softmax）</strong>：<br>对最后一层的神经元进行概率输出计算，即：给出各分类标签的概率，比如这里预期”Car”的概率一定要大于其他分类标签的概率值，所以最后一层的神经元个数和分类的标签个数需要一致。下面是softmax函数的表达式：<script type="math/tex; mode=display">p(y_i|\vec x) = \frac {e^{(\vec w_i \cdot \vec x+b_i)}}{\sum_{k \in K} e^{(\vec w_k \cdot \vec x+b_k)}}</script></li><li><strong>Batch-Normalization</strong>：<br>这一层其实在每一次卷积、全连接后都可以进行计算，但是图片中没有反映处这个处理过程。感兴趣可以查看我之前的博客<a href="https://kiddie92.github.io/2019/03/06/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AHow%EF%BC%9F/">卷积神经网络之Batch Normalization（一）：How？</a></li></ul><h2 id="参数个数计算"><a href="#参数个数计算" class="headerlink" title="参数个数计算"></a>参数个数计算</h2><p>按照上面的步骤描述，可知：</p><ol><li>input层是没有引进变量的；</li><li>卷积层则引入了”卷积核/filter”，假设卷积核大小为<script type="math/tex">n \times m</script>，图片有<script type="math/tex">l</script>个通道（channels）/维度，而选用的”卷积核/filter”有<script type="math/tex">k</script>个，再加上bias，可以得到引进的参数有：<script type="math/tex">(n*m*l+1)*k</script>个；</li><li>激活、池化层仅仅对原来的矩阵做了一个变换，不会引进新的参数；</li><li>拉平操作仅仅对矩阵进行了reshape，也不会引进新的变量；</li><li>全连接层就是对前后神经元做了仿射变换<script type="math/tex">\vec w_i \cdot \vec x+b_i</script>，引进的参数有权重和偏置，假设n个神经元连接m个神经元，则引入的参数有<script type="math/tex">(n+1)*m</script>；</li><li>输出层其实和全连接层没啥区别，只是输出的神经元个数要求是分类的标签个数，所以引入的变量也是<script type="math/tex">(n+1)*m</script>，这里m是分类的标签个数；</li><li>BN层引入的参数则和输入层神经元个数相关，假设输入神经元个数为n，则该层引进的参数为<script type="math/tex">2n</script></li></ol><p>综合以上，计算一个CNN架构的所有<strong>可学习参数/变量</strong>的个数可以分解成每一个步骤的参数变化量和引入参数个数两个<strong>相关</strong>的小问题，就像这样：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  name                           size                 parameters</span></span><br><span class="line">---  --------  -------------------------    ------------------------</span><br><span class="line">  0  input                       1x28x28                           0</span><br><span class="line">  1  conv2d1   (28-(5-1))=24 -&gt; 32x24x24    (5*5*1+1)*32   =     832</span><br><span class="line">  2  maxpool1                   32x12x12                           0</span><br><span class="line">  3  conv2d2   (12-(3-1))=10 -&gt; 32x10x10    (3*3*32+1)*32  =   9<span class="string">'248</span></span><br><span class="line"><span class="string">  4  maxpool2                     32x5x5                           0</span></span><br><span class="line"><span class="string">  5  dense                           256    (32*5*5+1)*256 = 205'</span>056</span><br><span class="line">  6  output                           10    (256+1)*10     =   2<span class="string">'570</span></span><br></pre></td></tr></table></figure></p><p>最后将每一个步骤的参数相加便得到所有参数的个数。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://stackoverflow.com/questions/42786717/how-to-calculate-the-number-of-parameters-for-convolutional-neural-network" target="_blank" rel="noopener">https://stackoverflow.com/questions/42786717/how-to-calculate-the-number-of-parameters-for-convolutional-neural-network</a></li><li><a href="https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050" target="_blank" rel="noopener">https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;前几天听室友给我讲算法岗的面经，其中面试官就问了一个小问题，“给出CNN网络的参数（&lt;strong&gt;可学习的&lt;/strong&gt;）个数如何计算”，今天就来计算一下好了。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="CNN" scheme="https://kiddie92.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>优化算法--牛顿迭代法</title>
    <link href="https://kiddie92.github.io/2019/03/17/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95/"/>
    <id>https://kiddie92.github.io/2019/03/17/优化算法-牛顿迭代法/</id>
    <published>2019-03-17T14:39:22.000Z</published>
    <updated>2019-06-06T14:33:26.239Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>牛顿法给出了任意方程求根的数值解法，而最优化问题一般会转换为求函数之间在”赋范线性空间”的距离<strong>最小点</strong>，所以，利用牛顿法去求解任意目标函数的<strong>极值点</strong>是个不错的思路。<br><a id="more"></a></p></blockquote><h1 id="方程求根"><a href="#方程求根" class="headerlink" title="方程求根"></a>方程求根</h1><p>对于一元二次方程，求根其实很简单，只要套用求根公式就行了，但找到一个方程的求根公式（<strong>解析解</strong>）其实是很困难的，可以证明5次方程以上便没有解析解了，参考维基百科<a href="https://zh.wikipedia.org/wiki/%E4%BA%94%E6%AC%A1%E6%96%B9%E7%A8%8B" target="_blank" rel="noopener">五次方程</a>。其他的复杂方程如偏微分方程求解更是超级困难。好在随着计算机技术的发展，解析解变的不再那么重要（至少是在工程上），取而代之的方法便是数值解法，<strong>牛顿法</strong>便是众多数值解法中的一个。<br>数值法求解又叫做<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90" target="_blank" rel="noopener">数值分析</a>，主要利用逼近的思想来使数值解通过迭代计算不断接近解析解，而得出来得解就叫做<strong>数值解</strong>，在工程上，数值解只要是在精度要求范围内满足方程便是有用的。</p><h2 id="牛顿迭代法"><a href="#牛顿迭代法" class="headerlink" title="牛顿迭代法"></a>牛顿迭代法</h2><p><img src="./sqrt2.png" alt="Alt text"></p><p>先考虑一个小问题：求解方程<script type="math/tex">x^2-2=0</script>的根，也即求解<script type="math/tex">\sqrt 2</script>。牛顿迭代法的思想从几何的角度很好理解，如上图所示（画图的脚本在<a href="https://github.com/kiddie92/Learning_Tech/blob/master/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95/equation_sqrt2.py" target="_blank" rel="noopener">这里</a>）方程的根就是函数<script type="math/tex">y=x^2-2</script>与<script type="math/tex">x</script>轴的交点处横坐标的值。从图中<script type="math/tex">x_n</script>点出发，计算函数在<script type="math/tex">x_n</script>点处的切线，再计算切线和<script type="math/tex">x</script>轴的交点得到<script type="math/tex">x_{n+1}</script>，再计算函数在<script type="math/tex">x_{n+1}</script>点处的切线… 一直这样迭代下去，可以发现<script type="math/tex">x_{n}</script>会越来越接近方程的根。</p><p>上述思路的数学表达：<br>由<script type="math/tex">x_{n}</script>计算<script type="math/tex">y_{n}</script></p><script type="math/tex; mode=display">f(x_n)=y_n</script><p>得到切线方程：</p><script type="math/tex; mode=display">y-y_n= \left.  f(x)' \right | _{x=x_n}(x-x_n)</script><p>切线和<script type="math/tex">x</script>轴的交点，也即，当<script type="math/tex">y=0</script>时，</p><script type="math/tex; mode=display">0-y_n=\left.  f(x)' \right | _{x=x_n}(x-x_n)</script><script type="math/tex; mode=display">\frac{-y_n}{\left. f'(x) \right | _{x=x_n}} = (x-x_n)</script><p>当<script type="math/tex">\left. f'(x) \right | _{x=x_n} \neq 0</script>时，</p><script type="math/tex; mode=display">x = x_n- \frac{y_n}{\left. f'(x) \right | _{x=x_n}}</script><p>由<script type="math/tex">y_n = f(x_n)</script>，得到：</p><script type="math/tex; mode=display">x = x_n- \frac{f(x_n)}{\left. f'(x) \right | _{x=x_n}}</script><p>令<script type="math/tex">x=x_n</script>，继续迭代，则得到迭代公式：</p><script type="math/tex; mode=display">x_{n+1} = x_n- \frac{f(x_n)}{\left. f'(x) \right | _{x=x_n}}</script><p>推导过程还可以从<strong>函数泰勒展开的角度</strong>去理解，这在很多博客里有写，这里就不赘述了。</p><p>根据上面的迭代公式，可以计算方程<script type="math/tex">x^2-2=0</script>的根了：</p><ol><li>猜一个初始值，因为根大概是1点多吧，那就给个<script type="math/tex">x_0=2</script>好了；</li><li>计算<script type="math/tex">x_1</script>：<script type="math/tex; mode=display">x_{1} = x_0- \frac{f(x_0)}{\left. f'(x) \right | _{x=x_0}}= 2- \frac{f(2)}{\left. f'(x) \right | _{x=2}}=1.5</script><script type="math/tex; mode=display">x_{2} = 1.5- \frac{f(1.5)}{\left. f'(x) \right | _{x=1.5}}=1.416667</script><script type="math/tex; mode=display">x_{3} = 1.416667- \frac{f(1.416667)}{\left. f'(x) \right | _{x=1.416667}}=1.414216</script></li></ol><h2 id="算法优缺点分析"><a href="#算法优缺点分析" class="headerlink" title="算法优缺点分析"></a>算法优缺点分析</h2><p>牛顿法的优点当然就是提供了一种方程求根的数值解方法。而缺点也有几点：</p><ol><li>首先算法是要求函数处处可导的，如果对于优化问题还需要导函数连续（因为要求处处存在二阶导数），否则算法就不能计算函数的根了，比如<script type="math/tex">f(x)=x^{1/3}</script>就不能收敛，虽然函数的根为0，但是它在0处的导数是不存在的；</li><li>求出的解可能仅仅是众多解中的一个，这个比较<strong>依赖于初始值的选取</strong>，比如上面的问题，初始值为2，则收敛到了方程的正数解，要想得到负数解，则需要将初始值选在负数中，现实中的问题，很难去估计解的大小范围；</li><li>如果初始的估计值与根的距离太远收敛就会变的比较慢；</li><li>要求每次迭代是得到的切线导数不能为0，如推导过程所示；</li><li>如果方程本来就没有根，那牛顿法是不能收敛的；</li></ol><h1 id="优化问题求解"><a href="#优化问题求解" class="headerlink" title="优化问题求解"></a>优化问题求解</h1><p>优化问题从泛函的角度理解起来，就是计算函数之间的距离最小。对于距离的定义有很多，比较常用的是<strong>二范数</strong>，使<strong>二范数</strong>距离最小的求解过程就叫做最小二乘。对于<script type="math/tex">Gm=data_{predict}</script>这样的线性问题（非线程问题可以通过泰勒展开转换成线性问题），可以定义距离为<script type="math/tex">\phi (m)=||Gm-data_{observation}||_2</script>，为了求距离最小值点，需要先求极值点，问题便转换为求解<script type="math/tex">\phi '(m)=0</script>的根，这时候<strong>牛顿法</strong>便派上了用场。与之前问题不同的是，这里需要求<script type="math/tex">\phi '(m)</script>的导数，也即求解<script type="math/tex">\phi "(m)</script>，也即Hessian矩阵。假设，此处的参数<script type="math/tex">m</script>是n维向量，则Hessian矩阵为：</p><script type="math/tex; mode=display">       H = \begin{pmatrix}        \frac{\partial ^2f}{\partial m_1^2} & \frac{\partial ^2f}{\partial m_1 \partial m_2} & \cdots & \frac{\partial ^2f}{\partial m_1 \partial m_n} \\        \frac{\partial ^2f}{\partial m_2 \partial m_1} & \frac{\partial ^2f}{\partial m_2^2} & \cdots & \frac{\partial ^2f}{\partial m_2 \partial m_n} \\        \vdots & \vdots & \ddots & \vdots \\        \frac{\partial ^2f}{\partial m_n \partial m_1} & \frac{\partial ^2f}{\partial m_n \partial m_2} & \cdots & \frac{\partial ^2f}{\partial m_n^2} \\        \end{pmatrix}</script><p>所以，牛顿法求解最优化问题，需要先求目标函数的Jacobian矩阵和Hessian矩阵，计算量比较大的便是计算Hessian矩阵了，因为二阶导计算量成指数增长。</p><blockquote><p>注意，这里若二阶导数是连续的，则$H$是对称矩阵。</p></blockquote><h2 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h2><p><strong>步骤1：</strong> 给定误差阈值<script type="math/tex">0\leq\epsilon <<1</script>，初始模型<script type="math/tex">m_0</script>（也可以给定迭代次数）；<br><strong>步骤2：</strong> 计算梯度<script type="math/tex">g_k=\nabla f(m_k)</script>，若<script type="math/tex">g_k\leq \epsilon</script>，停止计算，输出<script type="math/tex">m^* \approx m_k</script>;<br><strong>步骤3：</strong> 计算Hessian矩阵<script type="math/tex">G_k=\nabla^2f(m_k)</script>，计算<script type="math/tex">d_k=\frac {g_k}{G_k}</script>;<br><strong>步骤4：</strong> 令<script type="math/tex">x_{k+1}=x_{k}-d_{k}</script>，k=k+1，转到第2步。</p><h2 id="示例-amp-代码"><a href="#示例-amp-代码" class="headerlink" title="示例&amp;代码"></a>示例&amp;代码</h2><p>例子：求极小值: <script type="math/tex">f(m_1,m_2) = -m_1^3-m_2^3+3m_1^2+2m_2^2+m_1+m_2-1</script></p><p>主要代码如下所示，完整代码请查看<a href="https://github.com/kiddie92/Learning_Tech/blob/master/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95/optimazation_3.py" target="_blank" rel="noopener">这里</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> ((k &lt; n) <span class="keyword">or</span> np.sqrt(np.power(gk[<span class="number">0</span>,<span class="number">0</span>],<span class="number">2</span>)+np.power(gk[<span class="number">1</span>,<span class="number">0</span>],<span class="number">2</span>))) &gt; e:</span><br><span class="line">    <span class="comment">#向前差分计算一阶导</span></span><br><span class="line">    gk[<span class="number">0</span>,<span class="number">0</span>] = <span class="number">1</span>/m1stp*(func(m1+m1stp,m2)-func(m1,m2))</span><br><span class="line">    gk[<span class="number">1</span>,<span class="number">0</span>] = <span class="number">1</span>/m2stp*(func(m1,m2+m2stp)-func(m1,m2))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#向前差分计算海森矩阵,注意：以函数为二阶导连续为前提</span></span><br><span class="line">    Gk[<span class="number">0</span>,<span class="number">0</span>] = <span class="number">1</span>/m1stp*(func(m1+m1stp,m2)<span class="number">-2</span>*func(m1,m2)+func(m1-m1stp,m2))</span><br><span class="line">    Gk[<span class="number">0</span>,<span class="number">1</span>] = <span class="number">1</span>/(m1stp*m2stp)*(func(m1+m1stp,m2+m2stp)-func(m1,m2+m2stp)-func(m1+m1stp,m2)+func(m1,m2))</span><br><span class="line">    Gk[<span class="number">1</span>,<span class="number">0</span>] = Gk[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    Gk[<span class="number">1</span>,<span class="number">1</span>] = <span class="number">1</span>/m2stp*(func(m1,m2+m2stp)<span class="number">-2</span>*func(m1,m2)+func(m1,m2-m2stp))</span><br><span class="line"></span><br><span class="line">    dk = Gk.I*gk</span><br><span class="line"></span><br><span class="line">    <span class="comment">#修正模型</span></span><br><span class="line">    m1 = m1-dk[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">    m2 = m2-dk[<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    k = k+<span class="number">1</span></span><br></pre></td></tr></table></figure></p><h1 id="几个改进方法"><a href="#几个改进方法" class="headerlink" title="几个改进方法"></a>几个改进方法</h1><p>优化算化考虑重点包括算法的通用性、有效性、收敛性、效率，当然，这些都包括在时间复杂度和空间复杂度中。牛顿法存在几个问题需要考虑一下：</p><ol><li>计算Hessian矩阵太耗资源和时间了；</li><li>牛顿法不稳定，只有<script type="math/tex">H</script>正定时才收敛，也即要求目标函数的 Hessian 阵 <script type="math/tex">H_{i,j}</script> 在每个迭代点 <script type="math/tex">m_i</script> 处是正定的，否则难以保证牛顿法收敛的方向，实际上，<script type="math/tex">H</script>很可能是一个病态/奇异矩阵；</li><li>初始模型<script type="math/tex">m_0</script>很重要，选的不好会迭代很多次，收敛比较慢；</li><li>初始模型的选取不在最小值附近，很容易让结果陷入局部极小值。</li></ol><p>对此，大牛们提出了一些改进的方法：</p><ol><li><p>拟牛顿法：为了避免计算Hessian矩阵，不直接计算<script type="math/tex">H</script>，而是构造一个矩阵<script type="math/tex">K</script>来近似，<script type="math/tex">K</script>需要一直<strong>正定</strong>并且<strong>更新起来比较简单</strong>，此处可以查看相关文献，不赘述了；</p></li><li><p>高斯牛顿法：将目标函数<script type="math/tex">\phi (m)=||Gm-data_{observation}||_2</script>变换为<script type="math/tex">\phi (m)=\frac {1}{2}||r(m)||_2</script>，其中<script type="math/tex">r(m)</script>表示残差（residual），则根据chain rule，可以得到：</p><script type="math/tex; mode=display">\nabla^2 \phi (m)=\nabla r(m) \nabla^T r(m)+\sum_{i=1}^nr_i(m)\nabla^2 r_{i}(m)</script><p>这里令<script type="math/tex">Q(m)=\sum_{i=1}^nr_i(m)\nabla^2 r_{i}(m)</script>，若对于将要迭代的值<script type="math/tex">m^*</script>，有<script type="math/tex">r_{i}(m^*)=0</script>则<script type="math/tex">Q(m)=0</script>；这样的话就不需要计算Hessian矩阵了。这个想法不错，当<script type="math/tex">m^*</script>和极值点/最小值的距离比较近时，简直完美；但是，当初始值距离最小值较远时，<script type="math/tex">Q(m) \approx 0</script>的思路就不行了，此时，高斯-牛顿法并不收敛。</p></li></ol><blockquote><p>所以高斯-牛顿法也是极度依赖初始模型/初值的选取的</p></blockquote><ol><li>莱文贝格－马夸特方法(Levenberg–Marquardt algorithm)：该方法结合了高斯-牛顿法和最速下降法/梯度法，因为高斯-牛顿法比较依赖初始模型/初值，梯度法可以克服这个问题；而梯度法收敛速度要低于高斯-牛顿法，所以该方法能提供数非线性最小化（局部最小）的数值解。其实做法也很简单，就是在目标函数内加了一个参数<script type="math/tex">\lambda</script>，所以该方法也叫做阻尼最小二乘法。类似的做法在Tikhonov正则化中也出现了。</li></ol><blockquote><p>所有这些方法都可能陷入局部极小值，而非找到全局极小值/最小值。要想克服这个问题，就需要启发式/非线性优化算法了。</p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.youtube.com/watch?v=_pbD-3aS304" target="_blank" rel="noopener">Calculus- where Newton’s method fail</a></li><li><a href="http://www.ltcconline.net/greenl/courses/105/applications/NEWT.HTM" target="_blank" rel="noopener">Newton’s Method</a></li><li>马昌凤, 《最优化方法及其 Matlab 程序设计》</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;牛顿法给出了任意方程求根的数值解法，而最优化问题一般会转换为求函数之间在”赋范线性空间”的距离&lt;strong&gt;最小点&lt;/strong&gt;，所以，利用牛顿法去求解任意目标函数的&lt;strong&gt;极值点&lt;/strong&gt;是个不错的思路。&lt;br&gt;
    
    </summary>
    
      <category term="算法" scheme="https://kiddie92.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="优化算法" scheme="https://kiddie92.github.io/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    
      <category term="牛顿迭代法" scheme="https://kiddie92.github.io/tags/%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>数据采集之Python爬虫实验</title>
    <link href="https://kiddie92.github.io/2019/03/11/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPython%E7%88%AC%E8%99%AB%E5%AE%9E%E9%AA%8C/"/>
    <id>https://kiddie92.github.io/2019/03/11/数据分析之Python爬虫实验/</id>
    <published>2019-03-11T14:20:32.000Z</published>
    <updated>2019-03-17T14:11:53.394Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>如果说算法是程序的灵魂，那么数据就是算法的灵魂。数据采集是数据工程的第一步，为了提高效率，目前在互联网上采集数据比较高效的方法就是爬虫了。今天就来爬一下《惊奇队长》豆瓣上的影评/review。<br><a id="more"></a></p></blockquote><h1 id="爬虫简介"><a href="#爬虫简介" class="headerlink" title="爬虫简介"></a>爬虫简介</h1><p>数据可以挖掘潜在的价值，但是在挖掘之前需要有数据，否则再牛的算法也不会work。在一些具体的问题上，比如，我们可以收集各大网站上观众对于该电影的评价来判断电影的火热程度，结合其他的数据还可以估计票房等信息；又或者根据社交网络上人们对于股票市场行情的态度以及相关新闻，通过NLP处理来预测股价。那么，首先需要解决的问题就是如何获取数据。网络爬虫就是获取数据的一个重要手段，爬虫就好像一个全自动的机器人一直在浏览网页并将重要的信息收集起来，并按照一定的规则存储在相应的数据库或者文件内。数据收集好了，算法设计人员才可以做进一步的工作。</p><blockquote><p>如果有网站数据的API接口，就不用写爬虫了；<br>爬虫获取的数据都是公开的数据，很多有价值的数据还是需要花重金购买。</p></blockquote><h1 id="开始实践"><a href="#开始实践" class="headerlink" title="开始实践"></a>开始实践</h1><p>本次内容就是编写一个最简单的爬虫，实现豆瓣上电影的影评（或者叫做review），思路就是使用<code>urllib库</code>去模拟浏览器访问相关网页，再利用<code>re库</code>和<code>正则表达式</code>提取关键信息。</p><h2 id="URL分析"><a href="#URL分析" class="headerlink" title="URL分析"></a>URL分析</h2><p>首先，看一下豆瓣影评页的<code>URL</code>是否存在<strong>规律</strong>：浏览器打开豆瓣电影，逐个点击《惊奇队长》—&gt; 惊奇队长的影评 · · · · · · ( 全部 1160 条 )，查看网址为：<code>https://movie.douban.com/subject/26213252/reviews</code>，网址中出现的数字应该是电影的编号，但是没有页码的信息，点击”后页”按钮，网址变成了<code>https://movie.douban.com/subject/26213252/reviews?start=20</code>，所以猜测<code>start=20</code>这个参数是控制页码的，多试几次，发现确实是这个规律。<br>那么，在代码中设置翻页的操作就可以通过<code>for循环</code>来写了:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urlorg = <span class="string">"https://movie.douban.com/subject/26213252/reviews?start="</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(0, 100, 20):</span><br><span class="line">    url = urlorg + str(i)  <span class="comment"># 这里的url即为下一页的url了</span></span><br></pre></td></tr></table></figure><h2 id="网页源码分析"><a href="#网页源码分析" class="headerlink" title="网页源码分析"></a>网页源码分析</h2><p>查看《惊奇队长》影评页的网页源码，发现每一个影评都对应了一个<code>id</code>，而且每个<code>id</code>都对应了一个新的<code>URL</code>，想要查看完整的影评内容需要跳转到这个新的网页上进行查看；这些新的<code>URL</code>的构造也很有<strong>规律</strong>：<code>https://movie.douban.com/review/10034121/</code>最后的数字<code>10034121</code>就是这个review的<code>id</code>。通过网页源码的搜索（如下所示），可以发现<code>data-rid=&quot;9371928&quot; title=&quot;有用&quot;&gt;</code>可以唯一对应这个<code>id</code>，我们可以据此来设置正则表达式。</p><p>html 源码：</p><figure class="highlight htmlbars"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;a href="javascript:;" class="action-btn up" data-rid="9371928" title="有用"&gt;</span><br></pre></td></tr></table></figure><p>使用python 的<code>re包</code>接收正则表达式，(.*?)表示匹配项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pat = <span class="string">'data-rid="(.*?)" title="有用"'</span>   <span class="comment">#(.*?)部分即为id</span></span><br></pre></td></tr></table></figure><p>得到了每一个review的id之后，把它存在一个list内，我们就可以构造出每一个review的URL：<code>https://movie.douban.com/review/</code>+<code>str(id)</code>，打开其中一个review继续分析（我们的目标是把影评的内容拿到）；再次查看影评的网页源码，可以发现影评的题目可以通过<code>&lt;meta name=&quot;description&quot; content=&quot;影评题目&quot; /&gt;</code>唯一确定，而影评的内容则在<code>data-original=&quot;1&quot;&gt;</code>和<code>&lt;div class=&quot;copyright&quot;&gt;</code>之间，如下所示：<br><figure class="highlight htmlbars"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;meta name="description" content="影评题目" /&gt;</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">data-original="1"&gt;</span><br><span class="line">  &lt;p&gt;内容....</span><br><span class="line">     ....内容&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">  &lt;div class="copyright"&gt;</span><br></pre></td></tr></table></figure></p><p>如此以来，我们便可以设置正则将这两个主要内容提取出来。python的<code>re包</code>接收正则表达式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pat2 = <span class="string">'&lt;meta name="description" content="(.*?)" /&gt;'</span>      <span class="comment">#影评的题目</span></span><br><span class="line">pat3 = <span class="string">'data-original="1"&gt;(.*?)&lt;div class="copyright"&gt;'</span>   <span class="comment">#影评的内容</span></span><br></pre></td></tr></table></figure><h2 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h2><p>根据上面的信息，爬虫的主要代码部分已经呼之欲出了，完整代码请点击<a href="https://github.com/kiddie92/Learning_Tech/blob/master/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPython%E7%88%AC%E8%99%AB%E5%AE%9E%E9%AA%8C/spder_douban_movie.py" target="_blank" rel="noopener">这里</a>查看，爬取之前可以做一下浏览器模拟请求，最后爬下来的影评内容存放在一个文件中，以供后续使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">urlorg = <span class="string">"https://movie.douban.com/subject/26213252/reviews?start="</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#每页显示20个评论，所以间隔20算作一页</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">100</span>, <span class="number">20</span>):   <span class="comment">#如果需要爬取所有影评可以将100设置为更大的数字</span></span><br><span class="line">    url = urlorg + str(i)  </span><br><span class="line">    every_page = ur.urlopen(url).read().decode(<span class="string">"utf-8"</span>)</span><br><span class="line">    pat = <span class="string">'data-rid="(.*?)" title="有用"'</span></span><br><span class="line">    review_id = re.compile(pat).findall(every_page)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">20</span>):</span><br><span class="line">        review_url = <span class="string">"https://movie.douban.com/review/"</span> + str(review_id[j])</span><br><span class="line">        review = ur.urlopen(review_url).read().decode(<span class="string">"utf-8"</span>)</span><br><span class="line">        pat2 = <span class="string">'&lt;meta name="description" content="(.*?)" /&gt;'</span></span><br><span class="line">        pat3 = <span class="string">'data-original="1"&gt;(.*?)&lt;div class="copyright"&gt;'</span></span><br><span class="line">        review_title = re.compile(pat2).findall(review)</span><br><span class="line">        review_content = re.compile(pat3, re.S).findall(review)</span><br><span class="line">        print(review_title)</span><br><span class="line">        print(<span class="string">"-----------------------------"</span>)</span><br><span class="line">        print(review_content)</span><br></pre></td></tr></table></figure><h1 id="高级爬虫"><a href="#高级爬虫" class="headerlink" title="高级爬虫"></a>高级爬虫</h1><p>这里所谓的高级爬虫就是网络爬虫在遇到各种各样的问题时，依旧可以正常工作。下图表示一个爬虫的工作流程，首先进行网页的源码分析，看看是否存在规律，接着编写爬虫代码，最后将爬取的数据（适合存在在数据库的数据）保存在数据库内。下面简单的分析几个问题，以下问题都是有解的。</p><p><img src="archtech.png" alt="spyder"></p><ul><li><strong>网页抓包分析</strong><br>静态网页直接查看网页源码就可以爬取内容了，而动态网页则是利用一些前端技术（比如<code>js</code>、<code>css</code>等）进行动态展示。此时需要对浏览器进行抓包分析，将真正的网址抓取出来，得到关键信息。抓包的工具有<code>Fiddler</code>等。</li><li><strong>网站数据的加密、验证码</strong><br>很多网站采取了防爬虫的措施，比如对网页源码进行加密（典型的例子：网易云音乐的评论）、访问过频繁需要填写验证码等。对于网页加密，需要仔细的对网站进行抓包分析，将加密方式破解就可以了（一般还是<code>js</code>文件在搞事情）；对于填写验证码，可以让爬虫在爬取时加一个sleep时间（或者使用图片识别技术）。</li><li><strong>异常处理</strong><br>爬虫的工作依赖网络，所以网络万一出现问题，爬虫得有相应的处理机制，例如尝试连接某个网页未果后要及时爬取下一个，而不是异常退出了；再比如爬虫异常推出重启后得在重启之前得位置接着爬取数据，而不是重头再来。</li><li><strong>多线程</strong><br>对于爬虫这种io密集型的操作，多线程确实会提高效率，但是python的<code>GIL设计</code>使其多线程其实是假的多线程，所以如果比较在乎效率，这里比较推崇的做法是go语言写的爬虫。</li><li><strong>使用框架</strong><br>使用框架的好处是可以省去很多麻烦的设置，少考虑一些简单的问题，相互传阅代码也比较通俗易懂，python中的<code>scrapy框架</code>使用的比较多。</li><li><strong>数据库表的设计</strong><br>如果数据需要存入数据库，则需要设计一下数据库、表；这样做的好处是后续的数据供大家使用非常方便快捷。</li></ul><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><ol><li>网络上有很多数据值得深入的挖掘，获取数据是数据挖掘的第一步；</li><li>爬虫可以对网络的资源进行自动化获取，爬取数据之前需要对资源的获取进行仔细分析；</li><li>高级/工业级的爬虫需要考虑更多的问题，如：对加密网页内容的破解、抓包分析、爬虫的异常处理、数据存库等。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;如果说算法是程序的灵魂，那么数据就是算法的灵魂。数据采集是数据工程的第一步，为了提高效率，目前在互联网上采集数据比较高效的方法就是爬虫了。今天就来爬一下《惊奇队长》豆瓣上的影评/review。&lt;br&gt;
    
    </summary>
    
      <category term="数据工程" scheme="https://kiddie92.github.io/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="爬虫" scheme="https://kiddie92.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="数据采集" scheme="https://kiddie92.github.io/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络之Batch-Normalization（二）：Why？</title>
    <link href="https://kiddie92.github.io/2019/03/09/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AWhy%EF%BC%9F/"/>
    <id>https://kiddie92.github.io/2019/03/09/卷积神经网络之Batch-Normalization（二）：Why？/</id>
    <published>2019-03-09T13:17:35.000Z</published>
    <updated>2019-06-15T12:57:08.185Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>上一篇主要介绍了Batch-Normalization（下面简称BN）是如何工作的，即在连接层和激活函数之间加了一个BN层，这些参数参与了整个网络的正向和反向传播。这篇博文主要介绍为什么BN算法可以work，内容主要参考了两篇论文，包括18年的一篇NIPS论文。<br><a id="more"></a></p></blockquote><h2 id="问题的提出和解决"><a href="#问题的提出和解决" class="headerlink" title="问题的提出和解决"></a>问题的提出和解决</h2><p>在引入BN之前，以前的model training有一些系统性的问题，导致很多算法收敛速度都非常慢，甚至根本就不能工作，尤其在使用sigmoid激活函数时。其中一个比较著名的问题就是每层神经元是会受到它之前所有神经元影响的，因为每一层的输出都是下一层的输入，所以一个神经元输出的数据分布发生改变一定会使其他神经元跟着改变，这样相互影响的调参很容易使调参过程乱套，这个被称作Internal Covariate shift（ICS）。此外，还有其他问题，比如仿射层的输出值太大或太小，其经过sigmoid激活函数时会落在饱和区域，反向传播会有梯度消失的问题。这里先试图说明一下ICS问题及其解决方法。</p><h3 id="Internal-Covariate-shift-ICS"><a href="#Internal-Covariate-shift-ICS" class="headerlink" title="Internal Covariate shift (ICS)"></a>Internal Covariate shift (ICS)</h3><p>关于ICS，有个形象的比喻：当你有个射击目标时，如果这个目标是静止的，它就会比较容易击中；而当这个<strong>目标是在不停的移动时</strong>，它就很难被击中。深度学习的训练过程中就类似于后者：</p><ol><li>训练数据被输入到神经网络时，一般会先被normalization一下，因为输入的数据的每个维度的<strong>量纲</strong>可能会不一样，通过normalization可以消除量纲不一致的问题；</li><li>数据经过{Wx+b}和activation后，进入hidden layer，<strong>数据集的分布</strong>（均值和标准差）就会发生变化，而且每经过一层，输出数据集的分布都会变化；</li><li>由于每一层都发现自己的input数据集的分布在不停的变化，而反向传播更新参数时，想要适应训练数据集的分布就是一件非常困难的事情。</li></ol><p><img src="ICS.png" alt="Alt text"></p><p><strong>如果上面的理解是正确的</strong>，那么训练过程收敛速度非常慢就很容易理解了，尤其是对于深度较深的网络（隐含层比较多）。</p><h3 id="ICS问题的解决"><a href="#ICS问题的解决" class="headerlink" title="ICS问题的解决"></a>ICS问题的解决</h3><p>虽然ICS的问题很棘手，但也不是无解的。</p><ul><li>其中一个比较常见的解法就是<strong>减小learning rate</strong>，因为学习率一旦降低，学习训练数据集分布的过程就能够通过<strong>持续微小的调整</strong>来慢慢接近目标；但是，这也带来了一个问题，学习率太小容易使学习/训练的速度变慢，此外，还可能使学习过程陷入局部极小值。</li><li>BN算法之所以work的比较好，最主要的原因一直被认为是其解决了ICS的问题。Batch Normalization将每一层的输出都经过了“变换”，每一层的输出数据集（batch）都会重新将数据集的分布归一化到标准的分布形态上（均值为0，标准差为1）。这样一来，“目标分布” 在每一层的传递过程中变化就不会很大了，也即<strong>目标被固定住了</strong>。</li></ul><p><img src="BN.png" alt="Alt text"></p><p>下图对比了使用BN和不使用BN时，训练收敛的变化趋势，可以看到使用BN可以在更少的训练步数内达到同等的准确率，此外使用BN还可以达到更高的准确率，也即训练收敛速度更快，效果更佳。</p><p><img src="BN.VS.NOBN.png" alt="BN.VS.Stand"></p><h2 id="BN算法的有效性分析"><a href="#BN算法的有效性分析" class="headerlink" title="BN算法的有效性分析"></a>BN算法的有效性分析</h2><p>除了ICS的问题，BN算法还一并解决了深度学习训练过程中遇到的各种小问题。下面以问答的形式，说明一下几个小问题的解决。</p><h3 id="Q1-为什么先做BN再做activation？"><a href="#Q1-为什么先做BN再做activation？" class="headerlink" title="Q1: 为什么先做BN再做activation？"></a>Q1: 为什么先做BN再做activation？</h3><p>其实仅仅考虑ICS的问题，先做activation再做BN也不是不可以；但是，先做BN还是有好处的，BN将仿射层的输出标准化后，数值基本分布在0附近，对于sigmoid激活函数来说，值大都落在<strong>非饱和区</strong>了，就不太会造成梯度消失的现象了。</p><h3 id="Q2-mini-batch的大小设置多大比较合适？"><a href="#Q2-mini-batch的大小设置多大比较合适？" class="headerlink" title="Q2: mini-batch的大小设置多大比较合适？"></a>Q2: mini-batch的大小设置多大比较合适？</h3><p>mini batch的大小稍微大一点其实会比较合理，因为算法中需要使用mini-batch内的数据去估计整个样本的<strong>均值</strong>和<strong>方差</strong>，所以大一点会比较接近总体样本的分布；但是，太大又会导致training比较慢，所以，batch的大小和算力需要去权衡一下。</p><h3 id="Q3-scale和shift参数的加入有什么作用？"><a href="#Q3-scale和shift参数的加入有什么作用？" class="headerlink" title="Q3: scale和shift参数的加入有什么作用？"></a>Q3: scale和shift参数的加入有什么作用？</h3><p>scale、shift是两个独立的参数，也即和数据是没有依赖关系的，它们完全有可能将BN的作用给抵消掉，然而这恰好也是这个方法的优势，可以根据具体情况由网络自身在训练过程中来决定需不需要BN。</p><h3 id="Q4-训练好的模型如何使用，因为已经没有batch的概念了？"><a href="#Q4-训练好的模型如何使用，因为已经没有batch的概念了？" class="headerlink" title="Q4: 训练好的模型如何使用，因为已经没有batch的概念了？"></a>Q4: 训练好的模型如何使用，因为已经没有batch的概念了？</h3><p>一种方法是真的去估计整个样本在每一层的输出值的均值和方差，这个计算量太大。另一种比较常用的方法是，对训练集数据中的每一个均值和方差都保留下来，最后做移动平均来估计总体样本的均值和方差。</p><h2 id="新的理解"><a href="#新的理解" class="headerlink" title="新的理解"></a>新的理解</h2><p>这是一篇投稿于NeurIPS 2018的会议论文（参考文献2），文章以<strong>新的观点</strong>阐述了BN算法的有效性。主要涉及了两个实验（公式太多，没有细看）：</p><h3 id="在BN层之后添加Noise"><a href="#在BN层之后添加Noise" class="headerlink" title="在BN层之后添加Noise"></a>在BN层之后添加Noise</h3><p>在BatchNorm层之后加上一个随机噪音，噪音的分布异于BatchNorm层的输出（均值非0，方差非1），并且每次传播的时候，噪音都不一样。也就是说，在BatchNorm层之后故意加了一个ICS，结果发现训练并没有因此而明显变差（如下图粉红色所示），虽然隐含层的输出分布会随着迭代次数的增加（时间的推移）而变得不太稳定。</p><p><img src="why.jpg" alt="Alt text"></p><h3 id="梯度更新前后的Loss和其梯度的变化"><a href="#梯度更新前后的Loss和其梯度的变化" class="headerlink" title="梯度更新前后的Loss和其梯度的变化"></a>梯度更新前后的Loss和其梯度的变化</h3><p>作者使用量化的方式定量的说明了BN算法并不能减少ICS。实际上，作者认为BN算法减少了Lipschitz常数（也即loss函数变得更加连续/光滑），使得梯度变得跟加”可预测”（如下图所式），才是BN算法有效性的关键。</p><blockquote><p>这里”<strong>可预测</strong>“我的理解是表示变量的变化范围比较小，更加可控。</p></blockquote><p><img src="landscapes.jpg" alt="Alt text"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>ICS问题的解决使深度神经网络的收敛速度变快，另外，此时的learning rate也可以设置大一些，则加快了学习的速率；</li><li>BN的引入极大的降低了sigmoid和tanh这样的激活函数梯度消失的风险；</li><li>使用了Batch Normalization，初始化参数对神经网络的影响减小；</li><li>BN算法降低了过拟合的风险，训练过程不需要太多的正则化，也可以不需要drop out了；</li><li>新的观点认为ICS的解决并非BN算法有效的根本原因，loss变得平滑了才是主要原因；</li><li>国外发表的论文还做了一个几分钟的小视频放在youtube上，我觉得国内也可以校仿一下。</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Ioffe, S., &amp; Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.</li><li>Santurkar, S., Tsipras, D., Ilyas, A., &amp; Madry, A. (2018). How does batch normalization help optimization?. In Advances in Neural Information Processing Systems (pp. 2488-2498).</li><li><a href="https://mc.ai/batch-normalization-speed-up-neural-network-training/" target="_blank" rel="noopener">Batch Normalization — Speed up Neural Network Training</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;上一篇主要介绍了Batch-Normalization（下面简称BN）是如何工作的，即在连接层和激活函数之间加了一个BN层，这些参数参与了整个网络的正向和反向传播。这篇博文主要介绍为什么BN算法可以work，内容主要参考了两篇论文，包括18年的一篇NIPS论文。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="CNN" scheme="https://kiddie92.github.io/tags/CNN/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络之Batch Normalization（一）：How？</title>
    <link href="https://kiddie92.github.io/2019/03/06/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AHow%EF%BC%9F/"/>
    <id>https://kiddie92.github.io/2019/03/06/卷积神经网络之Batch-Normalization（一）：How？/</id>
    <published>2019-03-06T11:51:29.000Z</published>
    <updated>2019-06-15T12:57:14.762Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍深度学习里的一个常用的trick，主要用于加速收敛算法，这篇主要介绍一下怎么做的（How），下篇再介绍Why和该算法的一些好处，本来想着根据自己的理解写一下，看了大神写的之后我就决定”抄袭了”，（大神就是大神啊…）。原文使用MXNet实现的算法（原文查看文末的<strong>原文链接</strong>），这里改成使用TensorFlow实现一下这个例子。<br><a id="more"></a></p></blockquote><h1 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h1><p>这一节我们介绍批量归一化（batch normalization）层，它能让较深的神经网络的训练变得更加容易。在“实战 Kaggle 比赛：预测房价”一节里，我们对输入数据做了标准化处理：处理后的任意一个特征在数据集中所有样本上的均值为 0、标准差为 1。标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。</p><p>通常来说，数据标准化预处理对于浅层模型就足够有效了。随着模型训练的进行，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化。但对于深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。</p><p>批量归一化的提出正是为了应对深度模型训练的挑战。在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使得整个神经网络在各层的中间输出的数值更稳定。批量归一化和下一节将要介绍的残差网络为训练和设计深度模型提供了两类重要思路。</p><h2 id="批量归一化层"><a href="#批量归一化层" class="headerlink" title="批量归一化层"></a>批量归一化层</h2><p>对全连接层和卷积层做批量归一化的方法稍有不同。下面我们将分别介绍这两种情况下的批量归一化。</p><h3 id="对全连接层做批量归一化"><a href="#对全连接层做批量归一化" class="headerlink" title="对全连接层做批量归一化"></a>对全连接层做批量归一化</h3><p>我们先考虑如何对全连接层做批量归一化。通常，我们将<strong>批量归一化层置于全连接层中的仿射变换和激活函数之间</strong>。设全连接层的输入为$\boldsymbol{u}$，权重参数和偏差参数分别为 <script type="math/tex">\boldsymbol{W}</script> 和 <script type="math/tex">\boldsymbol{b}</script>，激活函数为 <script type="math/tex">\phi</script>。设批量归一化的操作符为 <script type="math/tex">\text{BN}</script>。那么，使用批量归一化的全连接层的输出为</p><script type="math/tex; mode=display">\phi(\text{BN}(\boldsymbol{x})),</script><p>其中批量归一化输入 <script type="math/tex">\boldsymbol{x}</script> 由仿射变换</p><script type="math/tex; mode=display">\boldsymbol{x} = \boldsymbol{W\boldsymbol{u} + \boldsymbol{b}}</script><p>得到。考虑一个由 <script type="math/tex">m</script> 个样本组成的小批量，仿射变换的输出为一个新的小批量 <script type="math/tex">\mathcal{B} = \{\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)} \}</script>。它们正是批量归一化层的输入。对于小批量 <script type="math/tex">\mathcal{B}</script> 中任意样本 <script type="math/tex">\boldsymbol{x}^{(i)} \in \mathbb{R}^d, 1 \leq  i \leq m</script>，批量归一化层的输出同样是 <script type="math/tex">d</script> 维向量</p><script type="math/tex; mode=display">\boldsymbol{y}^{(i)} = \text{BN}(\boldsymbol{x}^{(i)}),</script><p>并由以下几步求得。首先，对小批量 <script type="math/tex">\mathcal{B}</script> 求均值和方差：</p><script type="math/tex; mode=display">\boldsymbol{\mu}_\mathcal{B} \leftarrow \frac{1}{m}\sum_{i = 1}^{m} \boldsymbol{x}^{(i)},</script><script type="math/tex; mode=display">\boldsymbol{\sigma}_\mathcal{B}^2 \leftarrow \frac{1}{m} \sum_{i=1}^{m}(\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B})^2,</script><p>其中的平方计算是按元素求平方。接下来，我们使用按元素开方和按元素除法对 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 标准化：</p><script type="math/tex; mode=display">\hat{\boldsymbol{x}}^{(i)} \leftarrow \frac{\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B}}{\sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}},</script><p>这里 <script type="math/tex">\epsilon > 0</script> 是一个很小的常数，保证分母大于 0。在上面标准化的基础上，<strong>批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数 <script type="math/tex">\boldsymbol{\gamma}</script> 和偏移（shift）参数 <script type="math/tex">\boldsymbol{\beta}</script></strong>。这两个参数和 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 形状相同，皆为 <script type="math/tex">d</script> 维向量。它们与 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 分别做按元素乘法（符号 <script type="math/tex">\odot</script>）和加法计算：</p><script type="math/tex; mode=display">{\boldsymbol{y}}^{(i)} \leftarrow \boldsymbol{\gamma} \odot \hat{\boldsymbol{x}}^{(i)} + \boldsymbol{\beta}.</script><p>至此，我们得到了 <script type="math/tex">\boldsymbol{x}^{(i)}</script> 的批量归一化的输出 <script type="math/tex">\boldsymbol{y}^{(i)}</script>。<br>值得注意的是，可学习的拉伸和偏移参数保留了不对 <script type="math/tex">\hat{\boldsymbol{x}}^{(i)}</script> 做批量归一化的可能：此时只需学出 <script type="math/tex">\boldsymbol{\gamma} = \sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}</script> 和 <script type="math/tex">\boldsymbol{\beta} = \boldsymbol{\mu}_\mathcal{B}</script>。我们可以对此这样理解：<strong>如果批量归一化无益，理论上学出的模型可以不使用批量归一化。</strong></p><h3 id="对卷积层做批量归一化"><a href="#对卷积层做批量归一化" class="headerlink" title="对卷积层做批量归一化"></a>对卷积层做批量归一化</h3><p>对卷积层来说，批量归一化<strong>发生在卷积计算之后、应用激活函数之前</strong>。如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数，且均为标量。设小批量中有 <script type="math/tex">m</script> 个样本。在单个通道上，假设卷积计算输出的高和宽分别为 <script type="math/tex">p</script> 和 <script type="math/tex">q</script>。我们需要对该通道中 <script type="math/tex">m \times p \times q</script> 个元素同时做批量归一化。对这些元素做标准化计算时，我们使用相同的均值和方差，即该通道中 <script type="math/tex">m \times p \times q</script> 个元素的均值和方差。</p><h3 id="测试-预测时的批量归一化"><a href="#测试-预测时的批量归一化" class="headerlink" title="测试/预测时的批量归一化"></a>测试/预测时的批量归一化</h3><p>使用批量归一化训练时，我们<strong>可以将批量大小设的大一点</strong>，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用来预测/测试时，我们希望模型对于任意输入都有确定的输出。因此，单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差。一种常用的方法是<strong>通过移动平均估算整个训练数据集的样本均值和方差</strong>，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，批量归一化层在训练模式和预测模式下的计算结果也是不一样的。</p><h1 id="tensorflow调用"><a href="#tensorflow调用" class="headerlink" title="tensorflow调用"></a>tensorflow调用</h1><p>根据上面的讲解，运算流程应该是，输入神经元（neural）的数据先做<script type="math/tex">w \cdot u+b</script>得到<script type="math/tex">x_i</script>，再按照上面的公式对一个batch内的<script type="math/tex">x_i</script>进行normalization并接着scale和shift，之后再对其进行激活得到<script type="math/tex">z_i</script>。</p><script type="math/tex; mode=display">u_{i} -仿射变换-> x_i -标准化-> \hat{x_i} -拉伸和偏移-> y_i --> activation --> z_i</script><p>下面，使用mnist手写数字识别为例，按照这个流程走一遍吧，在tensorflow中调用使用的是<code>tf.layers.batch_normalization</code>，完整代码请看<a href="https://github.com/kiddie92/Learning_Tech/tree/master/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AHow%EF%BC%9F" target="_blank" rel="noopener">这里</a>(<strong>使用jupter-notebook查看</strong>)：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">epsilon = <span class="number">0.001</span></span><br><span class="line">Wx_plus_b = tf.layers.batch_normalization(Wx_plus_b, mean, var, shift, scale, epsilon)</span><br><span class="line"><span class="comment"># similar with this two steps:</span></span><br><span class="line"><span class="comment"># Wx_plus_b = (Wx_plus_b - fc_mean) / tf.sqrt(fc_var + 0.001)</span></span><br><span class="line"><span class="comment"># Wx_plus_b = Wx_plus_b * scale + shift</span></span><br></pre></td></tr></table></figure></p><p><strong>转载自：</strong>动手学深度学习<br><strong>原文网址：</strong><a href="https://zh.gluon.ai/chapter_convolutional-neural-networks/batch-norm.html" target="_blank" rel="noopener">https://zh.gluon.ai/chapter_convolutional-neural-networks/batch-norm.html</a><br><strong>作者：</strong>阿斯顿·张、<strong>李沐</strong>、扎卡里 C. 立顿、亚历山大 J. 斯莫拉</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文主要介绍深度学习里的一个常用的trick，主要用于加速收敛算法，这篇主要介绍一下怎么做的（How），下篇再介绍Why和该算法的一些好处，本来想着根据自己的理解写一下，看了大神写的之后我就决定”抄袭了”，（大神就是大神啊…）。原文使用MXNet实现的算法（原文查看文末的&lt;strong&gt;原文链接&lt;/strong&gt;），这里改成使用TensorFlow实现一下这个例子。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="深度学习" scheme="https://kiddie92.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="CNN" scheme="https://kiddie92.github.io/tags/CNN/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="神经网络" scheme="https://kiddie92.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>go语言为网站生成二维码</title>
    <link href="https://kiddie92.github.io/2019/03/05/go%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%BD%91%E5%9D%80%E4%BA%8C%E7%BB%B4%E7%A0%81/"/>
    <id>https://kiddie92.github.io/2019/03/05/go语言生成网址二维码/</id>
    <published>2019-03-05T13:40:49.000Z</published>
    <updated>2019-03-05T16:04:31.034Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>二维码有点意思，想着把俺的博客地址用二维码展示出来，比较来看还是go语言比较强大啊…<br><a id="more"></a></p></blockquote><h1 id="搭建golang环境"><a href="#搭建golang环境" class="headerlink" title="搭建golang环境"></a>搭建golang环境</h1><h2 id="安装go"><a href="#安装go" class="headerlink" title="安装go"></a>安装go</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ubuntu</span></span><br><span class="line">sudo apt install golang-go</span><br><span class="line"><span class="comment"># CentOS</span></span><br><span class="line">sudo yum install go</span><br></pre></td></tr></table></figure><h2 id="设置GOPATH"><a href="#设置GOPATH" class="headerlink" title="设置GOPATH"></a>设置GOPATH</h2><p>将GOPATH添加至环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="built_in">export</span> GOPATH=/root/go &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="comment"># 设置当前终端生效</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc </span><br><span class="line"><span class="comment"># 查看GOPATH</span></span><br><span class="line">go env</span><br></pre></td></tr></table></figure></p><p>创建所需文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/go</span><br><span class="line">mkdir bin &amp;&amp; mkdir pkg &amp;&amp; mkdir src</span><br></pre></td></tr></table></figure><p>GOPATH的目录结构:</p><ul><li>bin 编译后生成的可执行文件</li><li>pkg 编译后生成的文件（比如：.a）</li><li>src 存放源代码（比如：.go .c .h .s等）</li></ul><h2 id="运行代码"><a href="#运行代码" class="headerlink" title="运行代码"></a>运行代码</h2><p>导入第三方包：<code>go get -u github.com/yeqown/go-qrcode</code></p><p>新建文件夹<code>makeqrcode</code>，进入该文件夹后，新建文件 <code>makeqrforwebsite.go</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">        <span class="string">"fmt"</span></span><br><span class="line">        qrcode <span class="string">"github.com/yeqown/go-qrcode"</span> <span class="comment">// 给后面的包一个简称</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">        qrc, err := qrcode.New(<span class="string">"https://kiddie92.github.io/"</span>)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span>&#123;</span><br><span class="line">                fmt.Printf(<span class="string">"could not generate QRCode: %v"</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 保存二维码</span></span><br><span class="line">        <span class="keyword">if</span> err := qrc.Save(<span class="string">"."</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">                fmt.Printf(<span class="string">"could not save image: %v"</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>直接运行：<code>go run makeqrforwebsite.go</code>，生成本博客地址对应的二维码，扫描一下试试。</p><p><img src="./kiddie92.jpeg" width="30%" height="30%"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/yeqown/go-qrcode/" target="_blank" rel="noopener">https://github.com/yeqown/go-qrcode/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;二维码有点意思，想着把俺的博客地址用二维码展示出来，比较来看还是go语言比较强大啊…&lt;br&gt;
    
    </summary>
    
      <category term="go" scheme="https://kiddie92.github.io/categories/go/"/>
    
      <category term="Just for Fun" scheme="https://kiddie92.github.io/categories/go/Just-for-Fun/"/>
    
    
      <category term="go" scheme="https://kiddie92.github.io/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>浅谈深度学习算法 -- 能不能学物理定律?</title>
    <link href="https://kiddie92.github.io/2019/03/03/%E6%B5%85%E8%B0%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E8%83%BD%E4%B8%8D%E8%83%BD%E5%AD%A6%E7%89%A9%E7%90%86%E5%AE%9A%E5%BE%8B/"/>
    <id>https://kiddie92.github.io/2019/03/03/浅谈深度学习算法-能不能学物理定律/</id>
    <published>2019-03-03T12:37:49.000Z</published>
    <updated>2019-06-15T12:58:47.232Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本篇博客以一个物理问题为出发点，试图从数学的角度来理解一下深度学习算法。主要围绕着深度学习算法（未讨论非监督学习）能否学习出物理定律这个问题进行阐述。<br><a id="more"></a></p></blockquote><h1 id="先看一个物理问题"><a href="#先看一个物理问题" class="headerlink" title="先看一个物理问题"></a>先看一个物理问题</h1><p><img src="picture1.png" alt="示意图"></p><p>如上图所示，使用一个锤子敲击地面，会给地面造成一个冲击力，冲击造成的<strong>震源</strong>可以大致表示成图中<strong>（a）</strong>所显示的信号，震源使地面开始震动形成波场，<strong>（a）</strong>信号随着地面震动而传播，位于远处的<strong>检测器</strong>（倒三角形所示）感受到检测器所在位置的地面震动，并记录下来就得到了途中<strong>（b）</strong>所示的信号。这个问题可以简单理解成声音的传播，<strong>(a)</strong>是声源，经过大地传播之后（滤波作用），使接收声波的一方接收到信号<strong>（b）</strong>。</p><p>显然，不同的地质环境，大地的”材质”也会不同，那么一定会影响到<strong>（b）</strong>信号的最终形态。这就好像，人在水里说话和在空气中说话听到的声音肯定也会不一样。那么，如何描述材料的性质和接收信号<strong>（b）</strong>的关系呢？（<em>我们把这一关系表达为以下映射，在物理中称为正演问题</em>）下面给出两种解法。<br>$公式$</p><script type="math/tex; mode=display">Model Parameterts --> Data</script><h2 id="物理方法"><a href="#物理方法" class="headerlink" title="物理方法"></a>物理方法</h2><p>物理学家根据力学定律以及材料的弹性性质、密度等参数推导出<script type="math/tex">Model</script>和<script type="math/tex">Data</script>之间有着定量的关系，可以描述成下图的物理方程，有了这个方程，我们就可以建立这两者之间的关系了。</p><p><img src="phy_law.png" alt="物理方法"></p><h2 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h2><p>如今，我们还可以使用深度学习方法建立<script type="math/tex">Model</script>和<script type="math/tex">Data</script>之间的定量关系。首先我们建立一个网络架构，比如用几个卷积层、几个全链接层等，每一个神经元还有一组参数<script type="math/tex">[W]，[b]</script>通过给定<script type="math/tex">Model</script>和<script type="math/tex">Data</script>的数据对，不断的改进神经元的参数，最终在function set里面找到一个相对令人满意的函数，其可以表示<script type="math/tex">Model</script>和<script type="math/tex">Data</script>之间的映射关系。</p><p><img src="NN.png" alt="深度学习"></p><h1 id="问题的提出和回答"><a href="#问题的提出和回答" class="headerlink" title="问题的提出和回答"></a>问题的提出和回答</h1><p>上面给出了两种方法来解这个问题，我们可以看到如果两种方法都能解这个正演问题（<strong><em>深度学习实际上是在从数据反推回模型的过程中逐步给出正演函数的</em></strong>），那么是不是深度学习学习到的模型等价于物理定律呢，换句话说深度学习可以学到物理定律？</p><p>这个问题我给它拆成两个：</p><ol><li><strong>深度学习建立<script type="math/tex">Model</script>到<script type="math/tex">Data</script>的映射这件事情能不能做？</strong><br>肯定能，因为有人已经证明了深度学习算法可以拟合任何复杂的函数，参见<a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" target="_blank" rel="noopener">Universal approximation theorem</a>。相关问题也可以看看这里<a href="https://www.zhihu.com/question/268384579" target="_blank" rel="noopener">神经网络为什么可以拟合任意函数？</a>。也就是说，<script type="math/tex">Model</script>到<script type="math/tex">Data</script>的映射再复杂，深度学习也可以给你找个函数来逼近它。</li><li><strong>建立的映射好不好用？或者说模型的泛化能力会很强吗？</strong><br>虽说神经网络有万能逼近的性质，但是逼近的好不好就另说了，因为毕竟没有拿所有的数据集去训练，而一个物理问题的数据集几乎可以说是无限大的。那有没有可能深度学习学习出来的模型恰好和物理定律一致呢？那就得把深度学习模型当作一个函数来研究了，看看它是不是化简完恰好就是物理方程，不过，几万甚至上亿个参数的函数，研究起来应该很头疼吧，一般人肯定会疯掉的，所以说这个问题还是交给科学家去解决吧。<blockquote><p>这里和胡师兄讨论的时候，发现我们的理解基本一致（难道是因为大家都学地球物理的吗…）</p></blockquote></li></ol><p>其实，一个非线性的物理问题也可以线性化，比如使用泰勒展开就可以做到；从另外一个角度去理解就是<script type="math/tex">G(m)=d</script>转化成<script type="math/tex">Gm=d</script>的问题。但是，由于数据有限，这里的<script type="math/tex">G</script>存在<script type="math/tex">0</script>空间，所以会有<script type="math/tex">G_0m=0</script>，也就是说有限的数据集几乎是不可能约束<script type="math/tex">G</script>的。</p><h1 id="其他策略"><a href="#其他策略" class="headerlink" title="其他策略"></a>其他策略</h1><p>为了让深度学习学到的模型/函数/映射更加接近”理论事实”，我们可以加一些约束，比如先做特征提取、结合比较好解释的机器学习和深度学习算法来学习出一个泛化能力更强的模型/函数/映射。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>深度学习算法一般来说只能学习到数据集中已有的知识，它比较<strong>擅长于归纳，而不擅长演绎</strong>。对于<strong>非监督学习</strong>，情况可能比较复杂，暂不讨论。此外，世界是复杂的，但是伟大的理论通常在数学表达上都是简单优美的，这恐怕是<strong>现阶段</strong>人工智能所不能企及的。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本篇博客以一个物理问题为出发点，试图从数学的角度来理解一下深度学习算法。主要围绕着深度学习算法（未讨论非监督学习）能否学习出物理定律这个问题进行阐述。&lt;br&gt;
    
    </summary>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="知识理解" scheme="https://kiddie92.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%9F%A5%E8%AF%86%E7%90%86%E8%A7%A3/"/>
    
    
      <category term="算法" scheme="https://kiddie92.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="人工智能" scheme="https://kiddie92.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 特性--Graph 和 Sessions</title>
    <link href="https://kiddie92.github.io/2019/03/02/TensorFlow-%E7%89%B9%E6%80%A7-Graph-%E5%92%8C-Sessions/"/>
    <id>https://kiddie92.github.io/2019/03/02/TensorFlow-特性-Graph-和-Sessions/</id>
    <published>2019-03-02T14:14:11.000Z</published>
    <updated>2019-03-03T12:53:31.617Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>深度学习框架有很多，Google的TensorFlow市场占有率居高不下，本文的小目标是说清楚tensorflow的<strong>“图（Graph）”</strong>和<strong>“会话（Session）”</strong>机制及其优缺点，最后以一个回归问题为例实践一下。文中顺便回答一下<strong>动态图（Dynamic computation graphs）</strong>和<strong>静态图（Static computational graphs）</strong>框架的区别。<br><a id="more"></a></p></blockquote><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p><strong>深度学习</strong>是目前人工智能领域备受推崇的算法种类，其在计算机视觉（Computer vision）、自然语言处理（NLP）领域有比较广泛的应用，这里先挖个坑，<a href="https://kiddie92.github.io/2019/03/03/%E6%B5%85%E8%B0%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E8%83%BD%E4%B8%8D%E8%83%BD%E5%AD%A6%E7%89%A9%E7%90%86%E5%AE%9A%E5%BE%8B/">下一篇</a>将谈谈我对深度学习算法的理解。</p><p>目前开源市场的深度学习框架有很多，如<code>tensorflow</code>、<code>pytorch</code>、<code>mxnet</code>等，而tensorflow的市场占有率相对较高，那么为什么会有如此多的深度学习框架，tensorflow又有什么异于常人的地方呢？为了回答这个问题，本文首先尝试说明一下tensorflow的<code>Graph+Session</code>机制。</p><p>市面上的各种深度学习框架：</p><p><img src="DL-framework.png" alt="DeepLearning frameworks"></p><h2 id="计算图（Graph）"><a href="#计算图（Graph）" class="headerlink" title="计算图（Graph）"></a>计算图（Graph）</h2><p>简单来说，计算图是由tensor和opration组成的一张工程图纸。先上图（从图中来看，这是一个分类问题…），文末还附了一张PyTorch的动态图，有兴趣可以对比一下。</p><p><img src="tensors_flowing.gif" alt="Tensor and Flow"></p><h3 id="张量（Tensor）"><a href="#张量（Tensor）" class="headerlink" title="张量（Tensor）"></a>张量（Tensor）</h3><p>先把力学里面的张量忘掉，这里的张量概念包括标量、矢量和线性算子，或者简单理解成高维矩阵。输入的数据、参数大多是高维矩阵，统一被称为tensor，此外，tensor之间经过各种计算得到的结果依然是一个张量。</p><ul><li>输入<code>tf.placeholder</code></li><li>参数<code>tf.Variable</code></li><li>算子<code>tf.matmul</code>、<code>tf.sqrt()</code>等</li></ul><h3 id="算子（Operation）"><a href="#算子（Operation）" class="headerlink" title="算子（Operation）"></a>算子（Operation）</h3><p>Tensor之间的各种运算统称为operation，如加减乘除、开根号等。tensor进入operation进行各种计算，输出结果到下一个operation继续计算，像是tensor在流动，TensorFlow由此得名。</p><h2 id="会话-（Session）"><a href="#会话-（Session）" class="headerlink" title="会话 （Session）"></a>会话 （Session）</h2><p>当<code>tf.graph</code>定义好后，打开一个<code>tf.session</code>执行Graph，简单来说，会话是指机器根据工程图纸打开计算资源进行施工。Session提供了Operation执行和Tensor求值的环境，此外其还拥有物理资源（GPUs和网络连接）。当我们不再需要该session的时候，需要调用<code>sess.close()</code>关闭会话，将这些资源释放。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a default in-process session.</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a remote session.</span></span><br><span class="line"><span class="keyword">with</span> tf.Session(<span class="string">"grpc://example.org:2222"</span>):</span><br><span class="line">  <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><h2 id="数据流-（Dataflow）"><a href="#数据流-（Dataflow）" class="headerlink" title="数据流 （Dataflow）"></a>数据流 （Dataflow）</h2><p>Dataflow是一个常见的并行计算编程模型。在一个dataflow图中（如上gif图所示），节点表示计算单元，边界则表示计算单元对数据的生产和消费。dataflow模式有几个比较大的优势：</p><ul><li><strong>Parallelism</strong>：知道了各个operation之间的依赖关系，系统就可以比较好的使用并行计算了，比如：矩阵相乘可以并行计算、A算子的输入与B算子的输出没有依赖关系也可以并行计算。</li><li><strong>Distributed execution</strong>：同样利用每个operation之间的依赖关系，tensorflow好让一些计算被调度到不同机器的多个设备上（CPUs, GPUs, TPUs），tensorflow还会提供必要的机器之间的通信。</li><li><strong>Compilation</strong>：tensorflow的 XLA 编译器利用dadaflow图编译更快的机器码。</li><li><strong>Portability</strong>：datdaflow图使模型表示是语言无关的。<code>tf.saved_model</code>保存的模型可以在其他语言中使用，非常便携。</li></ul><h2 id="实践-—-回归问题"><a href="#实践-—-回归问题" class="headerlink" title="实践 — 回归问题"></a>实践 — 回归问题</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ol><li><p>构造一个函数/映射，<script type="math/tex">y_{data} = f(x_{data})</script>，其中 <script type="math/tex">x_{data}</script>是一个随机输入的<script type="math/tex">2\times100</script>矩阵，<script type="math/tex">y_{data}</script>是一个<script type="math/tex">1\times100</script>矩阵，由一个参数矩阵<script type="math/tex">W=\begin{bmatrix} 0.1 & 0.2 \end{bmatrix}</script> 和 <script type="math/tex">x_{data}</script>点乘后加上一个常数<script type="math/tex">b=0.3</script>构造出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用Numpy生成假数据(phony data),总共100个点.</span></span><br><span class="line">x_data = np.float32(np.random.rand(<span class="number">2</span>, <span class="number">100</span>))      <span class="comment"># 随机输入</span></span><br><span class="line">print(x_data)</span><br><span class="line">y_data = np.dot([<span class="number">0.100</span>, <span class="number">0.200</span>], x_data) + <span class="number">0.300</span>  <span class="comment">#输出的y为[[]]的list</span></span><br><span class="line">print(y_data)</span><br></pre></td></tr></table></figure></li><li><p>使用<script type="math/tex">x_{data}</script>和<script type="math/tex">y_{data}</script>数据来反演/学习出参数矩阵<script type="math/tex">W</script>和常量参数<script type="math/tex">b</script>，该问题等价于<strong>由100个方程求解三个参数问题</strong>，显然是一个<strong>超定问题</strong>，求解过程就是一个<strong>优化</strong>过程。</p><script type="math/tex; mode=display">\begin{pmatrix}     W_1X_{1,1} + W_2X_{2,1} +b = y_1 \\     W_1X_{1,2} + W_2X_{2,2} +b = y_2 \\      ... \\     W_1X_{1,100} + W_2X_{2,100} +b =y_{100} \\\end{pmatrix}</script></li><li><p>假设我们已经知道这个函数式了$Wx+b=y$，仅仅不知道给定的参数<script type="math/tex">W</script>和<script type="math/tex">b</script>是什么，根据函数式，可以使用初始化参数来构造<script type="math/tex">y</script>，并计算<script type="math/tex">y</script>和<script type="math/tex">y_{data}</script>之间的<em>“距离”</em>，并使用梯度下降的方式找到一个最优参数组使<strong>距离</strong>尽量减少。见代码部分10-13行。</p></li></ol><blockquote><p><strong>注意</strong>：</p><ol><li>现实世界中往往是不知道两个随机变量之间的确切关系的</li><li>这里”距离”是指向量之间的空间距离，常用的距离有欧几里得距离（2-范数）曼哈顿距离（1-范数）等。本例中使用2-范数作为距离，也即最小方差/最小二乘/Least Square方法。</li></ol></blockquote><h3 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h3><p>由于tensorflow和cuda版本（9.0.176）兼容问题，选择安装V1.12.0GPU版本，本机tensorflow环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[conan@localhost ~]$ conda list | grep tensor</span><br><span class="line">tensorboard               1.12.0                    &lt;pip&gt;</span><br><span class="line">tensorflow-gpu            1.12.0                    &lt;pip&gt;</span><br><span class="line">tensorflow-tensorboard    0.4.0                     &lt;pip&gt;</span><br></pre></td></tr></table></figure><h3 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h3><p>这里使用一个简单的平面拟合问题来实践一下，完整代码请看<strong><a href="https://github.com/kiddie92/Learning_Tech/blob/master/TensorFlow%20%E7%89%B9%E6%80%A7--Graph%20%E5%92%8C%20Sessions/Demo1_tensor.py" target="_blank" rel="noopener">这里</a></strong></p><ul><li>拟合时主要关注的参数为：<code>tf.train.GradientDescentOptimizer(0.2)</code>里的学习率（或者叫做步长）、和迭代次数<code>for step in range(0, 51):</code>，减小学习率增加迭代次数理论上会使拟合效果更好，但是会有过拟合（over fitting）的危险，并且模型的泛化能力（generalization）会比较差，控制这种风险的算法也很多，比如给目标函数加正则化（regularization）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个线性模型</span></span><br><span class="line"><span class="comment"># 实际问题中如果没有确切的物理关系,很难知道是否是线性模型, 也很难知道解在哪个范围</span></span><br><span class="line"></span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">W = tf.Variable(tf.random_uniform([<span class="number">1</span>, <span class="number">2</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">y = tf.matmul(W, x_data) + b   <span class="comment"># y is synthetic data</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面开始构建Graph</span></span><br><span class="line"><span class="comment"># 最小化方差(Least Square) 定义目标函数/损失函数/misfit function</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line"><span class="comment"># 优化器就使用最原始的梯度下降方法，参数为learning rate/步长</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>)   </span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"><span class="comment"># 启动会话</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合平面/反演参数/回归分析</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">51</span>):</span><br><span class="line">    sess.run(train)   <span class="comment"># 参数train就是前面定义的dataflow graph</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        print(step, sess.run(W), sess.run(b))</span><br><span class="line">W = sess.run(W)</span><br><span class="line">b = sess.run(b)</span><br><span class="line">sess.close()  </span><br><span class="line"><span class="comment"># 最终反演出来的方程</span></span><br><span class="line">y_pred = np.dot(W, x_data) + b</span><br><span class="line">print(<span class="string">'----------------'</span>)</span><br><span class="line">print(y_pred[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 得到最佳拟合结果 W: [[0.100 0.200]]\, b: [0.300]</span></span><br></pre></td></tr></table></figure><p>得到的y和y_data的对比：<br><img src="Comparation.jpg" alt="Comparation"></p><h1 id="静态图和动态图"><a href="#静态图和动态图" class="headerlink" title="静态图和动态图"></a>静态图和动态图</h1><p>回到最开始的问题，TensorFlow异于常人的地方：其实就是“<strong>静态图</strong>”框架。引用“hackernoon”上看到的一句话：</p><blockquote><p>TensorFlow is a <strong>“Define-and-Run”</strong> framework where one would define conditions and iterations in the graph structure whereas in comparison Chainer, DyNet, PyTorch are all <strong>“Define-by-Run”</strong> frameworks.</p></blockquote><p><strong>动态计算图框架</strong>使用起来就像做工程时一边设计一边施工，TensorFlow使用起来就没有“<strong>动态图</strong>”框架那样灵活、直接，容易调试，而这也是其入门门槛高的一个原因。但是，<strong>“静态图”</strong>的优点也是明显的—计算会更加高效，因为所有的步骤都定义好了再进行计算使计算机资源的调配更加合理、高效。所以说，“动态图”和“静态图”是优势互补的。</p><blockquote><p>TensorFlow 2.0 推出了Eager Execution，开始支持“动态图”了</p></blockquote><p><img src="dynamic_graph_pytorch.gif" alt="Dynamic Graph of PyTorch"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.tensorflow.org/guide/graphs?hl=en" target="_blank" rel="noopener">Graphs and Sessions</a></li><li><a href="https://hackernoon.com/how-is-pytorch-different-from-tensorflow-2c90f44747d6" target="_blank" rel="noopener">How is PyTorch different from Tensorflow?</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;深度学习框架有很多，Google的TensorFlow市场占有率居高不下，本文的小目标是说清楚tensorflow的&lt;strong&gt;“图（Graph）”&lt;/strong&gt;和&lt;strong&gt;“会话（Session）”&lt;/strong&gt;机制及其优缺点，最后以一个回归问题为例实践一下。文中顺便回答一下&lt;strong&gt;动态图（Dynamic computation graphs）&lt;/strong&gt;和&lt;strong&gt;静态图（Static computational graphs）&lt;/strong&gt;框架的区别。&lt;br&gt;
    
    </summary>
    
      <category term="tensorflow" scheme="https://kiddie92.github.io/categories/tensorflow/"/>
    
      <category term="机器学习" scheme="https://kiddie92.github.io/categories/tensorflow/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://kiddie92.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="tensorflow" scheme="https://kiddie92.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes 性能测试方法简介</title>
    <link href="https://kiddie92.github.io/2019/01/23/kubernetes-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E7%AE%80%E4%BB%8B/"/>
    <id>https://kiddie92.github.io/2019/01/23/kubernetes-性能测试方法简介/</id>
    <published>2019-01-23T06:41:43.000Z</published>
    <updated>2019-06-15T12:55:22.743Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍kubernetes（以下简称k8s）在性能测试中的主要关注指标以及涉及的辅助测试工具。由于各企业在私有云建设过程中使用的技术标准不尽相同，文中尽可能介绍可能涉及的通用性测试项，由于作者水平有限，以下内容仅供参考，欢迎讨论以及指正。<br><a id="more"></a> </p><h2 id="部署环境简要"><a href="#部署环境简要" class="headerlink" title="部署环境简要"></a>部署环境简要</h2><p>企业级k8s集群需要达到生产可用（GA），在部署上常采用高可用方案（HA），也即多台master节点和多台node节点的组合形式。生产上，k8s集群通常搭建在私有云或公有云IaaS之上，且需要较高的硬件资源支持。</p></blockquote><h3 id="集群资源"><a href="#集群资源" class="headerlink" title="集群资源"></a>集群资源</h3><p>从k8s集群部署需求的角度来说，集群资源应该明确给出，包括CPU、内存、系统、存储、网络以及相关的性能指标，而这些都可以由IaaS层提供，这里简单声明如下：</p><ul><li>集群存储：采用NAS作为后端持久化存储方案</li><li>集群网络：VMware提供的NSX-T容器网络方案</li><li>集群系统、CPU、内存资源列表：</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">角色</th><th style="text-align:center">角色说明</th><th style="text-align:center">节点数</th><th style="text-align:center">cpu</th><th style="text-align:center">内存</th><th style="text-align:center">系统</th><th style="text-align:center">存储大小</th></tr></thead><tbody><tr><td style="text-align:center">master</td><td style="text-align:center">k8s master节点</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">16</td><td style="text-align:center">CentOS 7.5</td><td style="text-align:center">100G</td></tr><tr><td style="text-align:center">node</td><td style="text-align:center">k8s计算节点</td><td style="text-align:center">2</td><td style="text-align:center">8</td><td style="text-align:center">16</td><td style="text-align:center">CentOS 7.5</td><td style="text-align:center">100G</td></tr></tbody></table></div><h3 id="集群部署架构"><a href="#集群部署架构" class="headerlink" title="集群部署架构"></a>集群部署架构</h3><p>企业级集群部署架构需要考虑很多因素，其中最主要的是需要有<strong>管理平面</strong>和<strong>业务平面</strong>，核心则是降低平台的使用复杂度和运维复杂度，所以部署上我们不仅仅需要有高可用的业务集群，还需要有相应的配套服务机制，其中包括监控（metrics）、日志（Logs）、网络管控、存储管控、负载均衡、私有云场景还需要提供yum源和镜像仓库服务等。</p><blockquote><p>这里，我们的监控采用单个集群使用<code>Prometheus</code>作为TSDB+<code>grafana</code>作为数据展示，而日志方面则以<code>ElasticSearch</code>集群部署的方式进行存储收集。</p></blockquote><p>业务集群的部署架构图则如下所示（图片来自<a href="https://elastisys.com/2018/01/25/setting-highly-available-kubernetes-clusters/" target="_blank" rel="noopener">这里</a>）<br><img src="k8sHA.jpg" alt="HA部署架构"></p><h2 id="容器网络测试"><a href="#容器网络测试" class="headerlink" title="容器网络测试"></a>容器网络测试</h2><h3 id="容器网络简介"><a href="#容器网络简介" class="headerlink" title="容器网络简介"></a>容器网络简介</h3><p>k8s的最小调度单位为<code>Pod</code>，而Pod“内部”的容器会通过Linux namespace机制与infra容器共享网络栈，所以<a href="https://www.nginx.com/resources/library/container-networking-docker-kubernetes/" target="_blank" rel="noopener">容器网络</a>就是指Pod之间通信的网络，kubernetes以开放插件接口的形式（Container Network Interface）让第三方插件提供Pod间网络通信的能力。</p><blockquote><p>目前主流的k8s容器网络插件有开源的Weave、Calico、Flannel-HostGW、Flannel-VxLAN、MacVLAN、IpVLAN…以及未开源的VMware NSX-T。</p></blockquote><h3 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h3><p>从容器网络性能测试的角度来说，关注点主要在于不同场景下带宽、计算资源消耗的情况。下面简单介绍一下相关的测试场景和测试策略以及涉及的测试工具：</p><blockquote><p>由于k8s网络插件在工作过程中存在Linux的<code>User Space</code>和<code>Kernel Space</code>的交互（封包解包），这是性能损耗的主要来源之一；<br>如果考虑网络安全，需要加上网络插件的限制隔离机制（Network Policies）的测试。</p></blockquote><ul><li>场景一：同主机Pod间通信</li><li>场景二：跨主机Pod间通信</li><li>场景三：集群内主机和主机间通信</li><li>场景四：Pod与宿主机间通信</li><li>场景五：Pod与非宿主机间通信</li><li>测试策略：固定网络带宽，固定网络类型，测试不同数据包大小对网络吞吐量的影响，例如可以测试获取文件传输量超过10G，系统在文件传输高峰时对局域网的<strong>带宽要求</strong>，并对比容器网络传输和非容器网络（Bare Metal）传输之间的<strong>CPU消耗</strong>以及<strong>内存消耗</strong>情况。</li><li>测试工具：<a href="https://iperf.fr/iperf-doc.php#3doc" target="_blank" rel="noopener">iperf3</a>，容器化运行在k8s集群上</li></ul><blockquote><p>相关的测试可以参考<a href="https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560" target="_blank" rel="noopener">这里</a>。</p></blockquote><h3 id="网络延迟"><a href="#网络延迟" class="headerlink" title="网络延迟"></a>网络延迟</h3><p>造成容器网络延迟的主要原因是传输延迟及处理延迟，这里的测试关注点在于不同CNI插件下，不同场景的网络延迟。</p><ul><li>场景一：通过Service的VIP或DNS进行集群内部访问</li><li>场景二：通过NodePort进行集群外部访问</li><li>场景三：通过IaaS层提供的LoadBalancer进行访问</li><li>测试策略：容器化运行<code>qperf</code>，依据场景的不同，通过设置yaml文件为qperf添加不同的Service访问方式，测试其在访问过程中的网络延迟。</li><li>涉及工具：<a href="https://linux.die.net/man/1/qperf" target="_blank" rel="noopener">qperf</a></li></ul><blockquote><p>需要注意的是：由于容器网络是基于IaaS层网络搭建，而IaaS层网络通常又是一个跨数据中心的“大二层”网络，虚拟机本身的物理位置对k8s集群来说已经是无感知的了，如此一来，容器网络的测试指标与IaaS网络其实是耦合在一起的，那么容器网络的测试实际上也是包含了IaaS层网络性能考量。</p></blockquote><h2 id="容器存储测试"><a href="#容器存储测试" class="headerlink" title="容器存储测试"></a>容器存储测试</h2><p>针对有状态应用的数据持久化以及容器日志存储需求，k8s设计了容器存储接口（CSI）并辅以PV、PVC的机制实现分布式应用的持久化存储，目前支持CSI实现容器持久化存储的方案有<a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/" target="_blank" rel="noopener">很多</a>。存储的测试主要考量的指标是容器对数据卷的读写IO，除此之外，还需要考虑容器迁移是否依然能够实现数据持久化。</p><ul><li>场景一：多容器实例跨主机部署，数据持久化</li><li>场景二：单个容器对数据卷进行读写IO</li><li>测试策略：k8s上使用deployment部署多个应用实例，每个Pod使用同一个PVC挂载同一个目录（Pod一般会分布在不同的主机上），再查看多个应用实例的数据是否同步写入同一后端存储；此外，在单容器内部使用<code>dd</code>命令在挂载目录下（本地存储或分布式存储）进行读、写以及读写测试，并使用参数<code>iflag=direct</code>，观察输出的平均读写时间。</li><li>涉及工具：<a href="https://linux.die.net/man/1/dd" target="_blank" rel="noopener">dd</a></li></ul><h2 id="k8s-并发测试"><a href="#k8s-并发测试" class="headerlink" title="k8s 并发测试"></a>k8s 并发测试</h2><p>对于使用go编写的k8s来说，并发能力理论上很强。性能测试上，可以使用多线程执行创建、删除、查询各类资源，由于k8s的最小调度单元为Pod，测试时可以仅使用创建deployment作为场景，主要的关注指标为<strong>错误率</strong>和<strong>平均响应时间</strong>以及<strong>硬件资源消耗</strong>：</p><ul><li>场景一：多线程并发创建deployment，再并发删除deployment</li><li>测试策略：使用Jmeter多线程方式发送创建不同name的deployment资源的json文件至<code>kube-apiserver</code>，删除亦如此；同时通过<code>Prometheus</code>和<code>Grafana</code>对集群的资源和相关组件的资源使用进行监控。 </li><li>涉及工具：<code>Jmeter</code> <code>curl</code> <code>Prometheus</code> <code>Grafana</code></li></ul><h3 id="kube-apiserver-api-规范"><a href="#kube-apiserver-api-规范" class="headerlink" title="kube-apiserver api 规范"></a>kube-apiserver api 规范</h3><p>使用curl测试一下kube-apiserver的api规范：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">-d @filename.json -H <span class="string">"Content-Type: application/json"</span> \</span><br><span class="line">-H <span class="string">"Authorization: Bearer <span class="variable">$&#123;token&#125;</span>"</span> <span class="variable">$&#123;api_url_or_ip:8080&#125;</span>/apis/extensions/v1beta1/namespaces/<span class="variable">$&#123;namespace_name&#125;</span>/deployments</span><br></pre></td></tr></table></figure></p><h3 id="deployment命名不可重复"><a href="#deployment命名不可重复" class="headerlink" title="deployment命名不可重复"></a>deployment命名不可重复</h3><p>由于deployment的name、label不可以重复，这里可以使用jmeter设置变量，并将变量赋值到将要发送的json文件内，点击<a href="https://github.com/Conan-D/jubernetes-test/blob/master/deployment.json" target="_blank" rel="noopener">deployment.json</a>即可查看deployment的json文件。</p><h2 id="横向伸缩能力测试"><a href="#横向伸缩能力测试" class="headerlink" title="横向伸缩能力测试"></a>横向伸缩能力测试</h2><p>k8s的横向伸缩能力主要体现在两个层面：node扩展和Pod扩展，但是node的扩展同时需要IaaS的能力支持，我们这里仅仅考虑Pod的横向扩缩容。k8s可以开启<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noopener">Horizontal Pod Autoscaler</a>功能，对接了metrics指标后，可以实现根据指标策略来自动扩缩应用副本数（Pod数）。因此，性能测试需要关注的指标有：Pod在扩缩容过程中所需的启停时间；扩缩过程中服务是否会出现中断，也即服务的错误率；以及服务的TPS变化；同时对集群资源的使用率进行监控。</p><ul><li>场景一：对deployment进行扩容操作</li><li>场景二：对deployment进行缩容操作</li><li>测试策略：部署单个应用至k8s集群，关联的service端口暴露方式为NortPort，使用Jmeter对该服务进行多线程持续访问；修改deployment的replica参数，使用<code>kubectl apply -f ${deployment.yaml}</code>更新应用，观察Jmeter的TPS、Error指标数据，以及集群资源监控数据。</li></ul><blockquote><p>关于scale out/in，k8s把Pod当做”cattle”而不是”pet”去管理，这里的测试并没有使用HPA，所以手动扩缩容实际上使用的是Rolling Update，Rolling Update思路也即关闭正在运行的Pod再创建新的Pod。所以，缩容过程中可能会出现部分服务暂时中断的现象，jmeter会出现Error，如果将Pod的”优雅停”时间（默认30s）设置长一点应该能够减少Error出现的几率。</p></blockquote><ul><li>涉及工具：<code>Jmeter</code> <code>Prometheus</code> <code>Grafana</code></li></ul><h2 id="集群高可用测试"><a href="#集群高可用测试" class="headerlink" title="集群高可用测试"></a>集群高可用测试</h2><p>k8s集群高可用其实就是集群各组件的高可用，测试关注点则是集群部分组件甚至节点关闭（如master或node宕机），集群是否还能正常工作，以及业务应用对外提供服务的性能是否还能保持稳定。</p><ul><li>场景一：正在对外提供服务的业务集群突然出现部分机器断网、宕机，或者kubelet等组件停止运行</li><li>测试策略：使用systemctl命令启停相关组件，模拟组件的工作中断；使用docker stop命名停止以静态Pod运行的服务组件，模拟组件的工作终止；使用ifconfig命令启停节点的网卡，模拟网络的中断；直接关闭机器模拟集群节点的突然宕机；同时观察集群应用服务及其管理是否能正常工作，业务运行相关指标是否下降。</li><li>涉及工具：<code>systemd</code> <code>ifconfig</code> <code>docker</code> <code>vcenter</code> <code>Jmeter</code></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>优秀的架构一定是可扩展的，尤其是大规模集群管理这样的底层系统，k8s的扩展能力太强以至于它更像是IaaS和PaaS之间的中间层。以Kubernetes为核心的PaaS平台已在国内外众多企业内实施落地，由于kubernetes的插件化设计，各企业在落地过程中需要解决的网络方案、存储方案、负载均衡方案、监控体系、日志体系等各不相同，从而在性能测试方法上也不尽相同，本文主要介绍了部分性能测试可能需要关注的地方以及相关工具，不够全面系统，内容仅供参考。</p><h2 id="Acknowledgment"><a href="#Acknowledgment" class="headerlink" title="Acknowledgment"></a>Acknowledgment</h2><p>灵雀云的小伙伴们给予了文档参考和技术支持，在此致谢。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560" target="_blank" rel="noopener">Benchmark results of Kubernetes network plugins (CNI) over 10Gbit/s network</a></li><li><a href="https://www.nginx.com/resources/library/container-networking-docker-kubernetes/" target="_blank" rel="noopener">Container Networking: From Docker to Kubernetes</a></li><li><a href="https://elastisys.com/2018/01/25/setting-highly-available-kubernetes-clusters/" target="_blank" rel="noopener">On setting up highly available Kubernetes clusters</a></li><li><a href="https://iperf.fr/iperf-doc.php#3doc" target="_blank" rel="noopener">iperf3 doc</a></li><li><a href="https://linux.die.net/man/1/qperf" target="_blank" rel="noopener">qperf doc</a></li><li><a href="https://kubernetes.io/blog/2015/09/kubernetes-performance-measurements-and/" target="_blank" rel="noopener">Kubernetes Performance Measurements and Roadmap</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文主要介绍kubernetes（以下简称k8s）在性能测试中的主要关注指标以及涉及的辅助测试工具。由于各企业在私有云建设过程中使用的技术标准不尽相同，文中尽可能介绍可能涉及的通用性测试项，由于作者水平有限，以下内容仅供参考，欢迎讨论以及指正。&lt;br&gt;
    
    </summary>
    
      <category term="容器云kubernetes" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="性能测试" scheme="https://kiddie92.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 下基于kubernetes安装部署kubeflow</title>
    <link href="https://kiddie92.github.io/2019/01/05/CentOS-%E4%B8%8B%E5%9F%BA%E4%BA%8Ekubernetes%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2kubeflow/"/>
    <id>https://kiddie92.github.io/2019/01/05/CentOS-下基于kubernetes安装部署kubeflow/</id>
    <published>2019-01-05T05:45:00.000Z</published>
    <updated>2019-06-15T13:01:10.226Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>小目标：基于前期搭建的<a href="https://kiddie92.github.io/2018/12/26/CentOS%E4%B8%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Kubernetes%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/">kubernetes集群</a>，部署kubeflow，由于涉及到google的docker镜像，只好设置国外代理了<br><a id="more"></a> </p><h3 id="下载安装包："><a href="#下载安装包：" class="headerlink" title="下载安装包："></a>下载安装包：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/ksonnet/ksonnet/releases/download/v0.13.1/ks_0.13.1_linux_amd64.tar.gz</span><br><span class="line">wget https://github.com/kubeflow/kubeflow/archive/v0.4.0-rc.3.tar.gz  <span class="comment">#2019.1.4 最新版本v0.4.0-rc.3</span></span><br></pre></td></tr></table></figure></blockquote><p>将下载好的安装包解压并归档</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -vxf ks_0.13.1_linux_amd64.tar.gz</span><br><span class="line">tar -vxf v0.4.0-rc.3.tar.gz</span><br><span class="line">mkdir kubeflow-ks</span><br><span class="line">cp -r kubeflow-0.4.0-rc.3 kubeflow-ks</span><br><span class="line">cp -r ks_0.13.1_linux_amd64 kubeflow-ks</span><br></pre></td></tr></table></figure><h3 id="安装ksonnet"><a href="#安装ksonnet" class="headerlink" title="安装ksonnet"></a>安装ksonnet</h3><p>ks是一个可执行文件，直接拷贝到系统可执行目录下就OK了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> kubeflow-ks/ks_0.13.1_linux_amd64</span><br><span class="line">cp ks /usr/bin</span><br></pre></td></tr></table></figure><h3 id="安装部署kubeflow"><a href="#安装部署kubeflow" class="headerlink" title="安装部署kubeflow"></a>安装部署kubeflow</h3><p>首先定义一些临时的环境变量，安装的时候会方便很多，因为安装脚本也是需要用到这些变量的</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBEFLOW_SRC=/your/path/to/kubeflow-0.4.0-rc.3</span><br><span class="line"><span class="built_in">export</span> KFAPP=kubeflowconfig  <span class="comment">#随意命名</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>注意</strong>：KFAPP必须是将要存放配置文件的<strong>目录名称</strong>，不可以是目录的路径，否则会报以下错误：<code>&lt;name&gt; should be the name for the deployment; not a path</code></p></blockquote><p>安装部署只需要三个命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$&#123;KUBEFLOW_SRC&#125;</span>/scripts/kfctl.sh init <span class="variable">$&#123;KFAPP&#125;</span> --platform none  <span class="comment"># none 也可以是minikube等</span></span><br><span class="line"><span class="variable">$&#123;KUBEFLOW_SRC&#125;</span>/scripts/kfctl.sh generate k8s</span><br><span class="line"><span class="variable">$&#123;KUBEFLOW_SRC&#125;</span>/scripts/kfctl.sh apply k8s</span><br></pre></td></tr></table></figure></p><p>查看是否运行好了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kubeflow  <span class="comment">#理论上gcr.io的镜像pull不下来</span></span><br><span class="line"><span class="comment"># 查看ImagePullBackOff等问题</span></span><br><span class="line">kubectl describe pod scheduledworkflow -n kubeflow </span><br><span class="line"><span class="comment">#提示: Failed to pull image "gcr.io/ml-pipeline/scheduledworkflow:0.1.6"</span></span><br></pre></td></tr></table></figure></p><p>所以这里需要代理了.. 设置国外代理的方法比较多，我这里使用的是VPS的方式。</p><h3 id="想要删除-or-重新部署？"><a href="#想要删除-or-重新部署？" class="headerlink" title="想要删除 or 重新部署？"></a>想要删除 or 重新部署？</h3><p>直接删除kubeflow这个namespace和之前放置配置文件的文件夹就OK了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete ns kubeflow</span><br><span class="line">kubectl delete crd tfjobs.kubeflow.org  <span class="comment"># crd 不删除也行</span></span><br><span class="line">rm -rf <span class="variable">$&#123;KFAPP&#125;</span></span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://www.kubeflow.org/docs/started/getting-started/#kubeflow-quick-start" target="_blank" rel="noopener">官方文档</a></li><li><a href="https://www.katacoda.com/kubeflow/scenarios/deploying-kubeflow-with-ksonnet" target="_blank" rel="noopener">katacoda</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;小目标：基于前期搭建的&lt;a href=&quot;https://kiddie92.github.io/2018/12/26/CentOS%E4%B8%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Kubernetes%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/&quot;&gt;kubernetes集群&lt;/a&gt;，部署kubeflow，由于涉及到google的docker镜像，只好设置国外代理了&lt;br&gt;
    
    </summary>
    
      <category term="容器云kubeflow" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubeflow/"/>
    
      <category term="分布式机器学习" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubeflow/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="kubeflow" scheme="https://kiddie92.github.io/tags/kubeflow/"/>
    
      <category term="分布式机器学习" scheme="https://kiddie92.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>微观经济学--比较优势</title>
    <link href="https://kiddie92.github.io/2019/01/03/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E6%AF%94%E8%BE%83%E4%BC%98%E5%8A%BF/"/>
    <id>https://kiddie92.github.io/2019/01/03/微观经济学-比较优势/</id>
    <published>2019-01-03T15:05:59.000Z</published>
    <updated>2019-03-03T09:13:31.512Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>曼昆 《经济学原理》微观经济学分册学习<br>小目标：说清楚绝对优势和比较优势，以及其与中美贸易战之间的关系<br><a id="more"></a> </p><h3 id="一、绝对优势"><a href="#一、绝对优势" class="headerlink" title="一、绝对优势"></a>一、绝对优势</h3><p>假设，Frank和Lee都会两个技能“摊煎饼”，“做馒头”，显然，不同的人擅长做的事情也不一样，我们用“效率”来衡量这两个人分别做两件事情的擅长程度。但是，影响”效率”的因素太多了，比如：原材料的节约程度，产品最终的受欢迎程度….，为了简化衡量标准，我们假设他们做出的“煎饼”和“馒头”所付出的成本仅仅在制作时间上有差异。如果以单位时间作为单位成本的话，我们假设Frank一个小时平均可以摊6个煎饼<strong>或者</strong>做10个馒头，Lee一个小时平均可以做4个煎饼<strong>或者</strong>15个馒头，按照单位成本来计算（min/个）整理成下表则为：</p></blockquote><div class="table-container"><table><thead><tr><th>生产成本（min/个）</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>煎饼</td><td>10</td><td>15</td></tr><tr><td>馒头</td><td>6</td><td>4</td></tr></tbody></table></div><p>显然，成本越小，表明其优势越大，比如Frank摊煎饼的成本就比Lee小，而Lee做馒头的成本就比Frank小，这个优势在经济学里面就叫做<strong>绝对优势</strong>，比如，我们可以说，Frank在摊煎饼这项工作上具有<strong>绝对优势</strong>。</p><blockquote><p>那就有人想说，干脆让Frank只做煎饼，Lee只做馒头好了，这样的话生产出来的煎饼和馒头的总和在单位时间内就会比他们分别生产煎饼和馒头要多。</p></blockquote><p>可是，要达成这个目的还需要一个协议，Frank和Lee可以仅生产自己有绝对优势的产品，并且可以相互交换，而相互交换的规则则是<strong>“一个煎饼可以换10/6到15/4个馒头之间”，</strong>也就是定价规则。</p><p>因为，对于Frank来说一个煎饼至少得换10/6个馒头吧，不然还不如他自己做馒头呢，而对于Lee来说，一个煎饼最多可以换15/4个馒头，不然他就亏了。所以，煎饼和馒头的兑换比率应该是<strong>ratio</strong>（ 10/6=1.67 &lt; ratio &lt; 15/4=3.75）</p><p>此外，从<strong>“机会成本（opportunity cost）”</strong>的角度阐述这个问题也是一样的：</p><blockquote><p>机会成本，生产A产品而不生产B产品，所舍弃的成本；这里Frank只生产煎饼，那么为了生产煎饼而放弃生产的馒头就是他的机会成本</p></blockquote><div class="table-container"><table><thead><tr><th>-</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>1个煎饼的机会成本</td><td>10/6个馒头</td><td>15/4个馒头</td></tr><tr><td>1个馒头的机会成本</td><td>6/10个煎饼</td><td>4/15个煎饼</td></tr></tbody></table></div><p>定价的规则就是保证在双方的<strong>机会成本之间</strong>。</p><h3 id="二、比较优势"><a href="#二、比较优势" class="headerlink" title="二、比较优势"></a>二、比较优势</h3><p><strong>专业化和贸易的好处不是基于绝对优势，而是基于比较优势。</strong>假设，Frank比较厉害，无论是摊煎饼还是做馒头都比Lee快：</p><div class="table-container"><table><thead><tr><th>生产成本（min/个）</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>煎饼</td><td>10</td><td>15</td></tr><tr><td>馒头</td><td>5</td><td>6</td></tr></tbody></table></div><p>这时双方的<strong>机会成本</strong>为：</p><div class="table-container"><table><thead><tr><th>-</th><th>Frank</th><th>Lee</th></tr></thead><tbody><tr><td>1个煎饼的机会成本</td><td>12/6个馒头</td><td>10/4个馒头</td></tr><tr><td>1个馒头的机会成本</td><td>6/12个煎饼</td><td>4/10个煎饼</td></tr></tbody></table></div><p>显然，如果一方在生产一种产品的机会成本比较低时，那他在生产另一种产品的机会成本就会比较高，因为两种产品的机会成本互为倒数。所以，Frank和Lee之间依然可以贸易，这时Frank生产他的机会成本比较小的煎饼，Lee生产他机会成本比较小的馒头。而交易的价格，也就是兑换的比率一就是在两个机会成本之间，12/6=2 &lt; 煎饼/馒头 &lt; 10/4=2.5 个。</p><blockquote><p>简单来说就是，Frank即使两个工作都很擅长，但他肯定也还是有更擅长的工作（擅长中的擅长^_^），他只要做他最擅长的那一个就OK了；而贸易则可以使整体的生产效率提高，从而提高大家的物质生活水平。</p></blockquote><p>不过理论上，这里可以有个小问题：如果Frank和Lee的机会成本一样，那还要不要贸易啊？？？</p><h3 id="三、联想"><a href="#三、联想" class="headerlink" title="三、联想"></a>三、联想</h3><ol><li><p><strong>人类为什么需要贸易</strong><br>贸易使经济生产效率提高，物质生活水平自然也会更高。有了贸易，自然就需要保护贸易正常进行的组织（不能偷、不能抢别人的，只能换），于是政府和国家的概念和角色就出现了，<strong>注意</strong>这只是理想状态下。</p></li><li><p><strong>为什么会有中美贸易战</strong><br>美国各方面都领先于中国，拥有绝对优势，但是其在生产服装、玩具、制造组装手机等方面的机会成本比中国高，而在生产高科技产品、农业产品的机会成本比中国低，所以中国向美国出口服装、玩具等，并从美国进口高科技产品、农产品等。可是，美国发现每年的中美贸易都出现逆差（对中国来说就是顺差），也就是说每年都有大量美元流入中国（中国美元的外汇储备之前一直比较高，2007年还搞了一个”中投”专门”研究”怎么花这笔钱…），为了扭转事态，美国开始加征关税（减少美国国内对中国的进口），中国当然不愿意看到这些，虽然人民币与美元并不挂钩，但是外汇储备对于中国政府来说仍然至关重要，于是中美就发生了trade war. 事实上，贸易往来总会出现不平衡的状况，一百多年前的鸦片战争也正是由于中英贸易存在类似的问题而导致的。</p></li></ol><blockquote><p>根据中国海关总署统计，美国对中国的贸易逆差从2001年的281亿美元增长到2017年2758亿美元。中美贸易总额已经从1992年的330亿美元发展到2017年的5837亿美元。由于统计口径差距，美国商务部统计数据，对中国逆差从2001年830亿美元增长到2017年3752亿美元，贸易总额增长到2017年6360亿美元。（<em>维基百科</em>）</p></blockquote><ol><li><strong>人尽其才，才尽其用的使命</strong><br>比较优势告诉我们，每个人去做自己最擅长的事情，就会使经济蛋糕变大，这就让人联想到<strong>人尽其才，物尽其用</strong>这句古话了。但是这都是理论上的，现实的世界不存在真正的自由贸易，也不会存在<strong>人尽其才，物尽其用</strong>这种理想状态。</li></ol><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li>经济学原理 — 微观经济学分册，曼昆</li><li><a href="https://www.youtube.com/watch?v=nwLqo83iqks&amp;t=0s&amp;index=3&amp;list=LLoCiddVQCg9ZvZoEa5d5wYw" target="_blank" rel="noopener">李永乐老师视频</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;曼昆 《经济学原理》微观经济学分册学习&lt;br&gt;小目标：说清楚绝对优势和比较优势，以及其与中美贸易战之间的关系&lt;br&gt;
    
    </summary>
    
      <category term="经济学原理" scheme="https://kiddie92.github.io/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
    
    
      <category term="金融知识" scheme="https://kiddie92.github.io/tags/%E9%87%91%E8%9E%8D%E7%9F%A5%E8%AF%86/"/>
    
      <category term="比较优势" scheme="https://kiddie92.github.io/tags/%E6%AF%94%E8%BE%83%E4%BC%98%E5%8A%BF/"/>
    
  </entry>
  
  <entry>
    <title>CentOS上安装部署Kubernetes注意事项</title>
    <link href="https://kiddie92.github.io/2018/12/26/CentOS%E4%B8%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Kubernetes%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
    <id>https://kiddie92.github.io/2018/12/26/CentOS上安装部署Kubernetes注意事项/</id>
    <published>2018-12-26T05:41:15.000Z</published>
    <updated>2019-06-15T12:59:45.623Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>小目标：不翻墙的情况下，使用kubeadm安装部署Kubernetes集群（非高可用），1个master、2个node<br><a id="more"></a></p><h3 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h3><h4 id="关于机器："><a href="#关于机器：" class="headerlink" title="关于机器："></a>关于机器：</h4><ol><li>准备的主机可以连接外网，对于私有云场景，需要做好前期准备（例如：配置yum源、镜像仓库源等）</li><li>满足安装 Docker 项目所需的要求，比如 64 位的 Linux 操作系统、3.10 及以上的内核版本；</li><li>x86 或者 ARM 架构均可；</li><li>机器之间网络互通，这是将来容器之间网络互通的前提；</li></ol></blockquote><h4 id="关于Linux操作系统："><a href="#关于Linux操作系统：" class="headerlink" title="关于Linux操作系统："></a>关于Linux操作系统：</h4><ol><li>建议开启<code>root</code>权限（我这里是已经开启了root权限，以root用户登录节点）</li><li>修改各节点的hostname：打开终端输入<code>hostnamectl set-hostname master8088</code>，这里的命名需要有一定的<a href="https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md" target="_blank" rel="noopener">规范</a><em>重启后hostname失效</em></li><li>建议：<code>systemd</code>不低于234，否则执行 df 命令的时候，<strong>据说</strong>会有一定几率卡死，使用<code>systemctl --version</code>查看版本信息</li><li>建议关闭<code>swap</code>输入<code>swapoff -a</code>：如果不满足，<strong>据说</strong>系统会有一定几率出现 io 飙升，造成 docker 卡死</li><li>关闭防火墙，终端输入<code>systemctl stop firewalld &amp;&amp; systemctl disable firewalld</code></li><li>关闭selinux:<code>vi  /etc/selinux/config</code> 设置<strong>SELINUX=disabled</strong></li><li><p>修改hosts文件，<code>vi /etc/hosts</code> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.0.1 node2   <span class="comment"># ip+hostname格式</span></span><br><span class="line">192.168.0.2 node1   <span class="comment"># ip每个节点的ip地址，可以使用ifconfig命令查看</span></span><br><span class="line">192.168.0.3 master</span><br></pre></td></tr></table></figure></li><li><p>添加相关设置<code>vim /etc/sysctl.conf</code>需要修改的内容如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">vm.max_map_count=262144</span><br></pre></td></tr></table></figure></li></ol><p>输入<code>sysctl -p</code>使设置生效</p><ol><li>设置三台机器之间可以使用<code>ssh+hostname</code>互相登录，</li></ol><blockquote><p><strong>节点之间无密码互相访问设置：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys</span><br><span class="line"><span class="comment">#将每个节点的id_rsa.pub写入每个节点的authorized_keys</span></span><br><span class="line"><span class="comment">#最后生成的authorized_keys复制到集群中的每一台计算机的.ssh目录下，覆盖掉之前的authorized_keys</span></span><br></pre></td></tr></table></figure></p></blockquote><h3 id="二、安装部署Kubernetes"><a href="#二、安装部署Kubernetes" class="headerlink" title="二、安装部署Kubernetes"></a>二、安装部署Kubernetes</h3><blockquote><p>安装之前需要配置一下<code>kubernetes</code>这个yum源，否则下面的命令可能失效</p></blockquote><ol><li>在每个节点上安装kubeadm、kubelet、kubectl，这里选择的是CentOS系统，所以使用命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure></li></ol><p><strong>安装的kubeadm、kubectl、kubelet默认都是最新的版本（1.13版本），也可以指定版本，比如目前是stable版的1.11</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看版本</span></span><br><span class="line">kubeadm version</span><br><span class="line">kubectl version</span><br><span class="line">kubelet --version</span><br><span class="line"><span class="comment"># 下载安装指定版本</span></span><br><span class="line">yum list --showduplicates | grep <span class="string">'kubeadm'</span> <span class="comment">#查看有哪些版本</span></span><br><span class="line">yum install -y kubeadm-1.10.5-0.x86_64 <span class="comment"># 安装指定版本，这里选择的是1.10.5</span></span><br></pre></td></tr></table></figure></p><ol><li>部署master节点：<br>这里需要注意的是，直接使用<code>kubeadm init</code>会发现需要的镜像获取不了，因为大陆被墙了.. 不过可以指定镜像仓库源，这里选择阿里云杭州的源（感谢^_^）：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubernetes-version=v1.13.1指定了安装1.13.1版本的kubernetes</span></span><br><span class="line"><span class="comment"># pod-network-cidr是为了后续安装calico这样的网络插件</span></span><br><span class="line">kubeadm init --kubernetes-version=v1.13.1 --pod-network-cidr=192.168.0.0/16 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>可能出现kubelet和kubeapi-server失联的情况，注意排查<br>master部署完成后，会生成一个指令：<code>kubeadm join ....</code>这个是后续加入node用的<br>kubeadm还会在部署好master后，最后提示我们第一次使用kubernetes集群需要的配置命令：<code>mkdir... sudo cp ... sudo chown...</code></p></blockquote><ol><li><p>部署node节点：参照master部署完毕生成的kubeadm join提示，在每个node上执行以下命令<br><code>kubeadm join ${master_ip}:6443 --token ${kubeadm_token} --discovery-token-ca-cert-hash ${hash_value}</code><br>使用<code>kubectl get no</code>查看node是否已经添加，并且处于Ready状态，由于网络插件还没安装，应该不会Ready</p></li><li><p>安装CNI插件calico</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml</span><br><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br></pre></td></tr></table></figure></li><li><p>删除master上的Taint标签，使之也可以被调度<br><code>kubectl taint nodes --all node-role.kubernetes.io/master-</code></p></li></ol><blockquote><p>至此，一个kubernetes集群已经可以使用了，接下来还可以部署Dashboard、CSI插件</p></blockquote><h3 id="三、问题记录"><a href="#三、问题记录" class="headerlink" title="三、问题记录"></a>三、问题记录</h3><p><strong>Q1：kubeadm一次运行没有通过，但是部分static Pod已经启动？</strong><br>打开终端输入：<code>kubeadm reset</code>，即可重置集群，修改必要的参数后，再次使用<code>kubeadm init ...</code>命令部署K8s集群。</p><p><strong>Q2： 需要事先下载好国内镜像源吗？</strong><br>不需要</p><blockquote><p>由于<code>kubeadm</code>在部署<code>K8s</code>集群时，需要从<code>k8s.gcr.io</code>上拉取镜像，但是大陆需要翻墙，所以有些博客里提出先下载好一样的镜像再修改tag以此绕开从国外拉取镜像的问题，但实际上没有必要这样做；即便如此，还是记录一下吧…</p></blockquote><p>镜像下载脚本<code>image_download.sh</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span>=registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line"></span><br><span class="line">images=(</span><br><span class="line"></span><br><span class="line">kube-apiserver:v1.13.1</span><br><span class="line"></span><br><span class="line">kube-controller-manager:v1.13.1</span><br><span class="line"></span><br><span class="line">kube-scheduler:v1.13.1</span><br><span class="line"></span><br><span class="line">kube-proxy:v1.13.1</span><br><span class="line"></span><br><span class="line">pause:3.1</span><br><span class="line"></span><br><span class="line">etcd:3.2.24</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">coredns:1.2.6</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> imageName <span class="keyword">in</span> <span class="variable">$&#123;images[@]&#125;</span> ; <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$imageName</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"------------------------------------"</span></span><br><span class="line">    docker pull <span class="variable">$source</span>/<span class="variable">$imageName</span></span><br><span class="line">    docker tag <span class="variable">$source</span>/<span class="variable">$imageName</span> k8s.gcr.io/<span class="variable">$imageName</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p><p>四、参考资料</p><ol><li><a href="https://time.geekbang.org/column/article/39724" target="_blank" rel="noopener">极客时间-张磊-深入剖析Kubernetes</a></li><li><a href="https://github.com/kubernetes/kubeadm" target="_blank" rel="noopener">kubeadm</a></li><li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">Creating a single master cluster with kubeadm</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;小目标：不翻墙的情况下，使用kubeadm安装部署Kubernetes集群（非高可用），1个master、2个node&lt;br&gt;
    
    </summary>
    
      <category term="容器云kubernetes" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubernetes/"/>
    
      <category term="Linux软件安装" scheme="https://kiddie92.github.io/categories/%E5%AE%B9%E5%99%A8%E4%BA%91kubernetes/Linux%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="kubernetes" scheme="https://kiddie92.github.io/tags/kubernetes/"/>
    
      <category term="kubeadm" scheme="https://kiddie92.github.io/tags/kubeadm/"/>
    
  </entry>
  
</feed>

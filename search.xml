<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[卷积神经网络之Batch Normalization（一）：How？]]></title>
    <url>%2F2019%2F03%2F06%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BBatch-Normalization%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AHow%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[本文主要介绍深度学习里的一个常用的trick，主要用于加速收敛算法，这篇主要介绍一下怎么做的（How），下篇再介绍Why和该算法的一些好处，本来想着根据自己的理解写一下，看了大神写的之后我就决定”抄袭了”，（大神就是大神啊…）。原文使用MXNet实现的算法（原文查看文末的原文链接），这里改成使用TensorFlow实现一下这个例子。 批量归一化这一节我们介绍批量归一化（batch normalization）层，它能让较深的神经网络的训练变得更加容易。在“实战 Kaggle 比赛：预测房价”一节里，我们对输入数据做了标准化处理：处理后的任意一个特征在数据集中所有样本上的均值为 0、标准差为 1。标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。 通常来说，数据标准化预处理对于浅层模型就足够有效了。随着模型训练的进行，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化。但对于深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。 批量归一化的提出正是为了应对深度模型训练的挑战。在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使得整个神经网络在各层的中间输出的数值更稳定。批量归一化和下一节将要介绍的残差网络为训练和设计深度模型提供了两类重要思路。 批量归一化层对全连接层和卷积层做批量归一化的方法稍有不同。下面我们将分别介绍这两种情况下的批量归一化。 对全连接层做批量归一化我们先考虑如何对全连接层做批量归一化。通常，我们将批量归一化层置于全连接层中的仿射变换和激活函数之间。设全连接层的输入为$\boldsymbol{u}$，权重参数和偏差参数分别为 \boldsymbol{W} 和 \boldsymbol{b}，激活函数为 \phi。设批量归一化的操作符为 \text{BN}。那么，使用批量归一化的全连接层的输出为 \phi(\text{BN}(\boldsymbol{x})),其中批量归一化输入 \boldsymbol{x} 由仿射变换 \boldsymbol{x} = \boldsymbol{W\boldsymbol{u} + \boldsymbol{b}}得到。考虑一个由 m 个样本组成的小批量，仿射变换的输出为一个新的小批量 \mathcal{B} = \{\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)} \}。它们正是批量归一化层的输入。对于小批量 \mathcal{B} 中任意样本 \boldsymbol{x}^{(i)} \in \mathbb{R}^d, 1 \leq i \leq m，批量归一化层的输出同样是 d 维向量 \boldsymbol{y}^{(i)} = \text{BN}(\boldsymbol{x}^{(i)}),并由以下几步求得。首先，对小批量 \mathcal{B} 求均值和方差： \boldsymbol{\mu}_\mathcal{B} \leftarrow \frac{1}{m}\sum_{i = 1}^{m} \boldsymbol{x}^{(i)},\boldsymbol{\sigma}_\mathcal{B}^2 \leftarrow \frac{1}{m} \sum_{i=1}^{m}(\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B})^2,其中的平方计算是按元素求平方。接下来，我们使用按元素开方和按元素除法对 \boldsymbol{x}^{(i)} 标准化： \hat{\boldsymbol{x}}^{(i)} \leftarrow \frac{\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B}}{\sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}},这里 \epsilon > 0 是一个很小的常数，保证分母大于 0。在上面标准化的基础上，批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数 \boldsymbol{\gamma} 和偏移（shift）参数 \boldsymbol{\beta}。这两个参数和 \boldsymbol{x}^{(i)} 形状相同，皆为 d 维向量。它们与 \boldsymbol{x}^{(i)} 分别做按元素乘法（符号 \odot）和加法计算： {\boldsymbol{y}}^{(i)} \leftarrow \boldsymbol{\gamma} \odot \hat{\boldsymbol{x}}^{(i)} + \boldsymbol{\beta}.至此，我们得到了 \boldsymbol{x}^{(i)} 的批量归一化的输出 \boldsymbol{y}^{(i)}。值得注意的是，可学习的拉伸和偏移参数保留了不对 \hat{\boldsymbol{x}}^{(i)} 做批量归一化的可能：此时只需学出 \boldsymbol{\gamma} = \sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon} 和 \boldsymbol{\beta} = \boldsymbol{\mu}_\mathcal{B}。我们可以对此这样理解：如果批量归一化无益，理论上学出的模型可以不使用批量归一化。 对卷积层做批量归一化对卷积层来说，批量归一化发生在卷积计算之后、应用激活函数之前。如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数，且均为标量。设小批量中有 m 个样本。在单个通道上，假设卷积计算输出的高和宽分别为 p 和 q。我们需要对该通道中 m \times p \times q 个元素同时做批量归一化。对这些元素做标准化计算时，我们使用相同的均值和方差，即该通道中 m \times p \times q 个元素的均值和方差。 测试/预测时的批量归一化使用批量归一化训练时，我们可以将批量大小设的大一点，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用来预测/测试时，我们希望模型对于任意输入都有确定的输出。因此，单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差。一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，批量归一化层在训练模式和预测模式下的计算结果也是不一样的。 tensorflow调用根据上面的讲解，运算流程应该是，输入神经元（neural）的数据先做w \cdot u+b得到x_i，再按照上面的公式对一个batch内的x_i进行normalization并接着scale和shift，之后再对其进行激活得到z_i。 u_{i} -仿射变换-> x_i -标准化-> \hat{x_i} -拉伸和偏移-> y_i --> activation --> z_i下面，使用mnist手写数字识别为例，按照这个流程走一遍吧，在tensorflow中调用使用的是tf.layers.batch_normalization，完整代码请看这里(使用jupter-notebook查看)：12345epsilon = 0.001Wx_plus_b = tf.layers.batch_normalization(Wx_plus_b, mean, var, shift, scale, epsilon)# similar with this two steps:# Wx_plus_b = (Wx_plus_b - fc_mean) / tf.sqrt(fc_var + 0.001)# Wx_plus_b = Wx_plus_b * scale + shift 转载自：动手学深度学习原文网址：https://zh.gluon.ai/chapter_convolutional-neural-networks/batch-norm.html作者：阿斯顿·张、李沐、扎卡里 C. 立顿、亚历山大 J. 斯莫拉]]></content>
      <categories>
        <category>算法，深度学习，人工智能</category>
      </categories>
      <tags>
        <tag>算法，深度学习，人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言为网站生成二维码]]></title>
    <url>%2F2019%2F03%2F05%2Fgo%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%BD%91%E5%9D%80%E4%BA%8C%E7%BB%B4%E7%A0%81%2F</url>
    <content type="text"><![CDATA[二维码有点意思，想着把俺的博客地址用二维码展示出来，比较来看还是go语言比较强大啊… 搭建golang环境安装go1234# ubuntusudo apt install golang-go# CentOSsudo yum install go 设置GOPATH将GOPATH添加至环境变量12345echo export GOPATH=/root/go &gt;&gt; ~/.bashrc# 设置当前终端生效source ~/.bashrc # 查看GOPATHgo env 创建所需文件夹 12cd /root/gomkdir bin &amp;&amp; mkdir pkg &amp;&amp; mkdir src GOPATH的目录结构: bin 编译后生成的可执行文件 pkg 编译后生成的文件（比如：.a） src 存放源代码（比如：.go .c .h .s等） 运行代码导入第三方包：go get -u github.com/yeqown/go-qrcode 新建文件夹makeqrcode，进入该文件夹后，新建文件 makeqrforwebsite.go 1234567891011121314151617package main import ( "fmt" qrcode "github.com/yeqown/go-qrcode" // 给后面的包一个简称)func main() &#123; qrc, err := qrcode.New("https://kiddie92.github.io/") if err != nil&#123; fmt.Printf("could not generate QRCode: %v", err) &#125; // 保存二维码 if err := qrc.Save("."); err != nil &#123; fmt.Printf("could not save image: %v", err) &#125;&#125; 直接运行：go run makeqrforwebsite.go，生成本博客地址对应的二维码，扫描一下试试。 Referencehttps://github.com/yeqown/go-qrcode/]]></content>
      <categories>
        <category>go</category>
        <category>Just for Fun</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈深度学习算法 -- 能不能学物理定律?]]></title>
    <url>%2F2019%2F03%2F03%2F%E6%B5%85%E8%B0%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E8%83%BD%E4%B8%8D%E8%83%BD%E5%AD%A6%E7%89%A9%E7%90%86%E5%AE%9A%E5%BE%8B%2F</url>
    <content type="text"><![CDATA[本篇博客以一个物理问题为出发点，试图从数学的角度来理解一下深度学习算法。主要围绕着深度学习算法（未讨论非监督学习）能否学习出物理定律这个问题进行阐述。 先看一个物理问题 如上图所示，使用一个锤子敲击地面，会给地面造成一个冲击力，冲击造成的震源可以大致表示成图中（a）所显示的信号，震源使地面开始震动形成波场，（a）信号随着地面震动而传播，位于远处的检测器（倒三角形所示）感受到检测器所在位置的地面震动，并记录下来就得到了途中（b）所示的信号。这个问题可以简单理解成声音的传播，(a)是声源，经过大地传播之后（滤波作用），使接收声波的一方接收到信号（b）。 显然，不同的地质环境，大地的”材质”也会不同，那么一定会影响到（b）信号的最终形态。这就好像，人在水里说话和在空气中说话听到的声音肯定也会不一样。那么，如何描述材料的性质和接收信号（b）的关系呢？（我们把这一关系表达为以下映射，在物理中称为正演问题）下面给出两种解法。$公式$ Model Parameterts --> Data物理方法物理学家根据力学定律以及材料的弹性性质、密度等参数推导出Model和Data之间有着定量的关系，可以描述成下图的物理方程，有了这个方程，我们就可以建立这两者之间的关系了。 深度学习方法如今，我们还可以使用深度学习方法建立Model和Data之间的定量关系。首先我们建立一个网络架构，比如用几个卷积层、几个全链接层等，每一个神经元还有一组参数[W]，[b]通过给定Model和Data的数据对，不断的改进神经元的参数，最终在function set里面找到一个相对令人满意的函数，其可以表示Model和Data之间的映射关系。 问题的提出和回答上面给出了两种方法来解这个问题，我们可以看到如果两种方法都能解这个正演问题（深度学习实际上是在从数据反推回模型的过程中逐步给出正演函数的），那么是不是深度学习学习到的模型等价于物理定律呢，换句话说深度学习可以学到物理定律？ 这个问题我给它拆成两个： 深度学习建立Model到Data的映射这件事情能不能做？肯定能，因为有人已经证明了深度学习算法可以拟合任何复杂的函数，参见Universal approximation theorem。相关问题也可以看看这里神经网络为什么可以拟合任意函数？。也就是说，Model到Data的映射再复杂，深度学习也可以给你找个函数来逼近它。 建立的映射好不好用？或者说模型的泛化能力会很强吗？虽说神经网络有万能逼近的性质，但是逼近的好不好就另说了，因为毕竟没有拿所有的数据集去训练，而一个物理问题的数据集几乎可以说是无限大的。那有没有可能深度学习学习出来的模型恰好和物理定律一致呢？那就得把深度学习模型当作一个函数来研究了，看看它是不是化简完恰好就是物理方程，不过，几万甚至上亿个参数的函数，研究起来应该很头疼吧，一般人肯定会疯掉的，所以说这个问题还是交给科学家去解决吧。 这里和胡师兄讨论的时候，发现我们的理解基本一致（难道是因为大家都学地球物理的吗…） 其实，一个非线性的物理问题也可以线性化，比如使用泰勒展开就可以做到；从另外一个角度去理解就是G(m)=d转化成Gm=d的问题。但是，由于数据有限，这里的G存在0空间，所以会有G_0m=0，也就是说有限的数据集几乎是不可能约束G的。 其他策略为了让深度学习学到的模型/函数/映射更加接近”理论事实”，我们可以加一些约束，比如先做特征提取、结合比较好解释的机器学习和深度学习算法来学习出一个泛化能力更强的模型/函数/映射。 小结深度学习算法一般来说只能学习到数据集中已有的知识，它比较擅长于归纳，而不擅长演绎。对于非监督学习，情况可能比较复杂，暂不讨论。此外，世界是复杂的，但是伟大的理论通常在数学表达上都是简单优美的，这恐怕是现阶段人工智能所不能企及的。]]></content>
      <categories>
        <category>算法</category>
        <category>人工智能</category>
        <category>机器学习</category>
        <category>知识理解</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>算法</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 特性--Graph 和 Sessions]]></title>
    <url>%2F2019%2F03%2F02%2FTensorFlow-%E7%89%B9%E6%80%A7-Graph-%E5%92%8C-Sessions%2F</url>
    <content type="text"><![CDATA[深度学习框架有很多，Google的TensorFlow市场占有率居高不下，本文的小目标是说清楚tensorflow的“图（Graph）”和“会话（Session）”机制及其优缺点，最后以一个回归问题为例实践一下。文中顺便回答一下动态图（Dynamic computation graphs）和静态图（Static computational graphs）框架的区别。 背景介绍深度学习是目前人工智能领域备受推崇的算法种类，其在计算机视觉（Computer vision）、自然语言处理（NLP）领域有比较广泛的应用，这里先挖个坑，下一篇将谈谈我对深度学习算法的理解。 目前开源市场的深度学习框架有很多，如tensorflow、pytorch、mxnet等，而tensorflow的市场占有率相对较高，那么为什么会有如此多的深度学习框架，tensorflow又有什么异于常人的地方呢？为了回答这个问题，本文首先尝试说明一下tensorflow的Graph+Session机制。 市面上的各种深度学习框架： 计算图（Graph）简单来说，计算图是由tensor和opration组成的一张工程图纸。先上图（从图中来看，这是一个分类问题…），文末还附了一张PyTorch的动态图，有兴趣可以对比一下。 张量（Tensor）先把力学里面的张量忘掉，这里的张量概念包括标量、矢量和线性算子，或者简单理解成高维矩阵。输入的数据、参数大多是高维矩阵，统一被称为tensor，此外，tensor之间经过各种计算得到的结果依然是一个张量。 输入tf.placeholder 参数tf.Variable 算子tf.matmul、tf.sqrt()等 算子（Operation）Tensor之间的各种运算统称为operation，如加减乘除、开根号等。tensor进入operation进行各种计算，输出结果到下一个operation继续计算，像是tensor在流动，TensorFlow由此得名。 会话 （Session）当tf.graph定义好后，打开一个tf.session执行Graph，简单来说，会话是指机器根据工程图纸打开计算资源进行施工。Session提供了Operation执行和Tensor求值的环境，此外其还拥有物理资源（GPUs和网络连接）。当我们不再需要该session的时候，需要调用sess.close()关闭会话，将这些资源释放。 1234567# Create a default in-process session.with tf.Session() as sess: # ...# Create a remote session.with tf.Session("grpc://example.org:2222"): # ... 数据流 （Dataflow）Dataflow是一个常见的并行计算编程模型。在一个dataflow图中（如上gif图所示），节点表示计算单元，边界则表示计算单元对数据的生产和消费。dataflow模式有几个比较大的优势： Parallelism：知道了各个operation之间的依赖关系，系统就可以比较好的使用并行计算了，比如：矩阵相乘可以并行计算、A算子的输入与B算子的输出没有依赖关系也可以并行计算。 Distributed execution：同样利用每个operation之间的依赖关系，tensorflow好让一些计算被调度到不同机器的多个设备上（CPUs, GPUs, TPUs），tensorflow还会提供必要的机器之间的通信。 Compilation：tensorflow的 XLA 编译器利用dadaflow图编译更快的机器码。 Portability：datdaflow图使模型表示是语言无关的。tf.saved_model保存的模型可以在其他语言中使用，非常便携。 实践 — 回归问题问题描述 构造一个函数/映射，y_{data} = f(x_{data})，其中 x_{data}是一个随机输入的2\times100矩阵，y_{data}是一个1\times100矩阵，由一个参数矩阵W=\begin{bmatrix} 0.1 & 0.2 \end{bmatrix} 和 x_{data}点乘后加上一个常数b=0.3构造出来。 12345# 使用Numpy生成假数据(phony data),总共100个点.x_data = np.float32(np.random.rand(2, 100)) # 随机输入print(x_data)y_data = np.dot([0.100, 0.200], x_data) + 0.300 #输出的y为[[]]的listprint(y_data) 使用x_{data}和y_{data}数据来反演/学习出参数矩阵W和常量参数b，该问题等价于由100个方程求解三个参数问题，显然是一个超定问题，求解过程就是一个优化过程。 \begin{pmatrix} W_1X_{1,1} + W_2X_{2,1} +b = y_1 \\ W_1X_{1,2} + W_2X_{2,2} +b = y_2 \\ ... \\ W_1X_{1,100} + W_2X_{2,100} +b =y_{100} \\ \end{pmatrix} 假设我们已经知道这个函数式了$Wx+b=y$，仅仅不知道给定的参数W和b是什么，根据函数式，可以使用初始化参数来构造y，并计算y和y_{data}之间的“距离”，并使用梯度下降的方式找到一个最优参数组使距离尽量减少。见代码部分10-13行。 注意： 现实世界中往往是不知道两个随机变量之间的确切关系的 这里”距离”是指向量之间的空间距离，常用的距离有欧几里得距离（2-范数）曼哈顿距离（1-范数）等。本例中使用2-范数作为距离，也即最小方差/最小二乘/Least Square方法。 运行环境由于tensorflow和cuda版本（9.0.176）兼容问题，选择安装V1.12.0GPU版本，本机tensorflow环境： 1234[conan@localhost ~]$ conda list | grep tensortensorboard 1.12.0 &lt;pip&gt;tensorflow-gpu 1.12.0 &lt;pip&gt;tensorflow-tensorboard 0.4.0 &lt;pip&gt; 代码部分这里使用一个简单的平面拟合问题来实践一下，完整代码请看这里 拟合时主要关注的参数为：tf.train.GradientDescentOptimizer(0.2)里的学习率（或者叫做步长）、和迭代次数for step in range(0, 51):，减小学习率增加迭代次数理论上会使拟合效果更好，但是会有过拟合（over fitting）的危险，并且模型的泛化能力（generalization）会比较差，控制这种风险的算法也很多，比如给目标函数加正则化（regularization）。 123456789101112131415161718192021222324252627282930313233# 构造一个线性模型# 实际问题中如果没有确切的物理关系,很难知道是否是线性模型, 也很难知道解在哪个范围b = tf.Variable(tf.zeros([1]))W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))y = tf.matmul(W, x_data) + b # y is synthetic data# 下面开始构建Graph# 最小化方差(Least Square) 定义目标函数/损失函数/misfit functionloss = tf.reduce_mean(tf.square(y - y_data))# 优化器就使用最原始的梯度下降方法，参数为learning rate/步长optimizer = tf.train.GradientDescentOptimizer(0.2) train = optimizer.minimize(loss)# 初始化变量init = tf.initialize_all_variables()# 启动会话sess = tf.Session()sess.run(init)# 拟合平面/反演参数/回归分析for step in range(0, 51): sess.run(train) # 参数train就是前面定义的dataflow graph if step % 10 == 0: print(step, sess.run(W), sess.run(b))W = sess.run(W)b = sess.run(b)sess.close() # 最终反演出来的方程y_pred = np.dot(W, x_data) + bprint('----------------')print(y_pred[0])# 得到最佳拟合结果 W: [[0.100 0.200]]\, b: [0.300] 得到的y和y_data的对比： 静态图和动态图回到最开始的问题，TensorFlow异于常人的地方：其实就是“静态图”框架。引用“hackernoon”上看到的一句话： TensorFlow is a “Define-and-Run” framework where one would define conditions and iterations in the graph structure whereas in comparison Chainer, DyNet, PyTorch are all “Define-by-Run” frameworks. 动态计算图框架使用起来就像做工程时一边设计一边施工，TensorFlow使用起来就没有“动态图”框架那样灵活、直接，容易调试，而这也是其入门门槛高的一个原因。但是，“静态图”的优点也是明显的—计算会更加高效，因为所有的步骤都定义好了再进行计算使计算机资源的调配更加合理、高效。所以说，“动态图”和“静态图”是优势互补的。 TensorFlow 2.0 推出了Eager Execution，开始支持“动态图”了 Reference Graphs and Sessions How is PyTorch different from Tensorflow?]]></content>
      <categories>
        <category>tensorflow</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes 性能测试方法简介]]></title>
    <url>%2F2019%2F01%2F23%2Fkubernetes-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[本文主要介绍kubernetes（以下简称k8s）在性能测试中的主要关注指标以及涉及的辅助测试工具。由于各企业在私有云建设过程中使用的技术标准不尽相同，文中尽可能介绍可能涉及的通用性测试项，由于作者水平有限，以下内容仅供参考，欢迎讨论以及指正。 部署环境简要企业级k8s集群需要达到生产可用（GA），在部署上常采用高可用方案（HA），也即多台master节点和多台node节点的组合形式。生产上，k8s集群通常搭建在私有云或公有云IaaS之上，且需要较高的硬件资源支持。 集群资源从k8s集群部署需求的角度来说，集群资源应该明确给出，包括CPU、内存、系统、存储、网络以及相关的性能指标，而这些都可以由IaaS层提供，这里简单声明如下： 集群存储：采用NAS作为后端持久化存储方案 集群网络：VMware提供的NSX-T容器网络方案 集群系统、CPU、内存资源列表： 角色 角色说明 节点数 cpu 内存 系统 存储大小 master k8s master节点 3 4 16 CentOS 7.5 100G node k8s计算节点 2 8 16 CentOS 7.5 100G 集群部署架构企业级集群部署架构需要考虑很多因素，其中最主要的是需要有管理平面和业务平面，核心则是降低平台的使用复杂度和运维复杂度，所以部署上我们不仅仅需要有高可用的业务集群，还需要有相应的配套服务机制，其中包括监控（metrics）、日志（Logs）、网络管控、存储管控、负载均衡、私有云场景还需要提供yum源和镜像仓库服务等。 这里，我们的监控采用单个集群使用Prometheus作为TSDB+grafana作为数据展示，而日志方面则以ElasticSearch集群部署的方式进行存储收集。 业务集群的部署架构图则如下所示（图片来自这里） 容器网络测试容器网络简介k8s的最小调度单位为Pod，而Pod“内部”的容器会通过Linux namespace机制与infra容器共享网络栈，所以容器网络就是指Pod之间通信的网络，kubernetes以开放插件接口的形式（Container Network Interface）让第三方插件提供Pod间网络通信的能力。 目前主流的k8s容器网络插件有开源的Weave、Calico、Flannel-HostGW、Flannel-VxLAN、MacVLAN、IpVLAN…以及未开源的VMware NSX-T。 性能测试从容器网络性能测试的角度来说，关注点主要在于不同场景下带宽、计算资源消耗的情况。下面简单介绍一下相关的测试场景和测试策略以及涉及的测试工具： 由于k8s网络插件在工作过程中存在Linux的User Space和Kernel Space的交互（封包解包），这是性能损耗的主要来源之一；如果考虑网络安全，需要加上网络插件的限制隔离机制（Network Policies）的测试。 场景一：同主机Pod间通信 场景二：跨主机Pod间通信 场景三：集群内主机和主机间通信 场景四：Pod与宿主机间通信 场景五：Pod与非宿主机间通信 测试策略：固定网络带宽，固定网络类型，测试不同数据包大小对网络吞吐量的影响，例如可以测试获取文件传输量超过10G，系统在文件传输高峰时对局域网的带宽要求，并对比容器网络传输和非容器网络（Bare Metal）传输之间的CPU消耗以及内存消耗情况。 测试工具：iperf3，容器化运行在k8s集群上 相关的测试可以参考这里。 网络延迟造成容器网络延迟的主要原因是传输延迟及处理延迟，这里的测试关注点在于不同CNI插件下，不同场景的网络延迟。 场景一：通过Service的VIP或DNS进行集群内部访问 场景二：通过NodePort进行集群外部访问 场景三：通过IaaS层提供的LoadBalancer进行访问 测试策略：容器化运行qperf，依据场景的不同，通过设置yaml文件为qperf添加不同的Service访问方式，测试其在访问过程中的网络延迟。 涉及工具：qperf 需要注意的是：由于容器网络是基于IaaS层网络搭建，而IaaS层网络通常又是一个跨数据中心的“大二层”网络，虚拟机本身的物理位置对k8s集群来说已经是无感知的了，如此一来，容器网络的测试指标与IaaS网络其实是耦合在一起的，那么容器网络的测试实际上也是包含了IaaS层网络性能考量。 容器存储测试针对有状态应用的数据持久化以及容器日志存储需求，k8s设计了容器存储接口（CSI）并辅以PV、PVC的机制实现分布式应用的持久化存储，目前支持CSI实现容器持久化存储的方案有很多。存储的测试主要考量的指标是容器对数据卷的读写IO，除此之外，还需要考虑容器迁移是否依然能够实现数据持久化。 场景一：多容器实例跨主机部署，数据持久化 场景二：单个容器对数据卷进行读写IO 测试策略：k8s上使用deployment部署多个应用实例，每个Pod使用同一个PVC挂载同一个目录（Pod一般会分布在不同的主机上），再查看多个应用实例的数据是否同步写入同一后端存储；此外，在单容器内部使用dd命令在挂载目录下（本地存储或分布式存储）进行读、写以及读写测试，并使用参数iflag=direct，观察输出的平均读写时间。 涉及工具：dd k8s 并发测试对于使用go编写的k8s来说，并发能力理论上很强。性能测试上，可以使用多线程执行创建、删除、查询各类资源，由于k8s的最小调度单元为Pod，测试时可以仅使用创建deployment作为场景，主要的关注指标为错误率和平均响应时间以及硬件资源消耗： 场景一：多线程并发创建deployment，再并发删除deployment 测试策略：使用Jmeter多线程方式发送创建不同name的deployment资源的json文件至kube-apiserver，删除亦如此；同时通过Prometheus和Grafana对集群的资源和相关组件的资源使用进行监控。 涉及工具：Jmeter curl Prometheus Grafana kube-apiserver api 规范使用curl测试一下kube-apiserver的api规范：123curl -X POST \-d @filename.json -H "Content-Type: application/json" \-H "Authorization: Bearer $&#123;token&#125;" $&#123;api_url_or_ip:8080&#125;/apis/extensions/v1beta1/namespaces/$&#123;namespace_name&#125;/deployments deployment命名不可重复由于deployment的name、label不可以重复，这里可以使用jmeter设置变量，并将变量赋值到将要发送的json文件内，点击deployment.json即可查看deployment的json文件。 横向伸缩能力测试k8s的横向伸缩能力主要体现在两个层面：node扩展和Pod扩展，但是node的扩展同时需要IaaS的能力支持，我们这里仅仅考虑Pod的横向扩缩容。k8s可以开启Horizontal Pod Autoscaler功能，对接了metrics指标后，可以实现根据指标策略来自动扩缩应用副本数（Pod数）。因此，性能测试需要关注的指标有：Pod在扩缩容过程中所需的启停时间；扩缩过程中服务是否会出现中断，也即服务的错误率；以及服务的TPS变化；同时对集群资源的使用率进行监控。 场景一：对deployment进行扩容操作 场景二：对deployment进行缩容操作 测试策略：部署单个应用至k8s集群，关联的service端口暴露方式为NortPort，使用Jmeter对该服务进行多线程持续访问；修改deployment的replica参数，使用kubectl apply -f ${deployment.yaml}更新应用，观察Jmeter的TPS、Error指标数据，以及集群资源监控数据。 关于scale out/in，k8s把Pod当做”cattle”而不是”pet”去管理，这里的测试并没有使用HPA，所以手动扩缩容实际上使用的是Rolling Update，Rolling Update思路也即关闭正在运行的Pod再创建新的Pod。所以，缩容过程中可能会出现部分服务暂时中断的现象，jmeter会出现Error，如果将Pod的”优雅停”时间（默认30s）设置长一点应该能够减少Error出现的几率。 涉及工具：Jmeter Prometheus Grafana 集群高可用测试k8s集群高可用其实就是集群各组件的高可用，测试关注点则是集群部分组件甚至节点关闭（如master或node宕机），集群是否还能正常工作，以及业务应用对外提供服务的性能是否还能保持稳定。 场景一：正在对外提供服务的业务集群突然出现部分机器断网、宕机，或者kubelet等组件停止运行 测试策略：使用systemctl命令启停相关组件，模拟组件的工作中断；使用docker stop命名停止以静态Pod运行的服务组件，模拟组件的工作终止；使用ifconfig命令启停节点的网卡，模拟网络的中断；直接关闭机器模拟集群节点的突然宕机；同时观察集群应用服务及其管理是否能正常工作，业务运行相关指标是否下降。 涉及工具：systemd ifconfig docker vcenter Jmeter 总结优秀的架构一定是可扩展的，尤其是大规模集群管理这样的底层系统，k8s的扩展能力太强以至于它更像是IaaS和PaaS之间的中间层。以Kubernetes为核心的PaaS平台已在国内外众多企业内实施落地，由于kubernetes的插件化设计，各企业在落地过程中需要解决的网络方案、存储方案、负载均衡方案、监控体系、日志体系等各不相同，从而在性能测试方法上也不尽相同，本文主要介绍了部分性能测试可能需要关注的地方以及相关工具，不够全面系统，内容仅供参考。 Acknowledgment灵雀云的小伙伴们给予了文档参考和技术支持，在此致谢。 Reference Benchmark results of Kubernetes network plugins (CNI) over 10Gbit/s network Container Networking: From Docker to Kubernetes On setting up highly available Kubernetes clusters iperf3 doc qperf doc Kubernetes Performance Measurements and Roadmap]]></content>
      <categories>
        <category>kubernetes</category>
        <category>软件测试</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>性能测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 下基于kubernetes安装部署kubeflow]]></title>
    <url>%2F2019%2F01%2F05%2FCentOS-%E4%B8%8B%E5%9F%BA%E4%BA%8Ekubernetes%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2kubeflow%2F</url>
    <content type="text"><![CDATA[小目标：基于前期搭建的kubernetes集群，部署kubeflow，由于涉及到google的docker镜像，只好设置国外代理了 下载安装包：12wget https://github.com/ksonnet/ksonnet/releases/download/v0.13.1/ks_0.13.1_linux_amd64.tar.gzwget https://github.com/kubeflow/kubeflow/archive/v0.4.0-rc.3.tar.gz #2019.1.4 最新版本v0.4.0-rc.3 将下载好的安装包解压并归档 12345tar -vxf ks_0.13.1_linux_amd64.tar.gztar -vxf v0.4.0-rc.3.tar.gzmkdir kubeflow-kscp -r kubeflow-0.4.0-rc.3 kubeflow-kscp -r ks_0.13.1_linux_amd64 kubeflow-ks 安装ksonnetks是一个可执行文件，直接拷贝到系统可执行目录下就OK了 12cd kubeflow-ks/ks_0.13.1_linux_amd64cp ks /usr/bin 安装部署kubeflow首先定义一些临时的环境变量，安装的时候会方便很多，因为安装脚本也是需要用到这些变量的 12export KUBEFLOW_SRC=/your/path/to/kubeflow-0.4.0-rc.3export KFAPP=kubeflowconfig #随意命名 注意：KFAPP必须是将要存放配置文件的目录名称，不可以是目录的路径，否则会报以下错误：&lt;name&gt; should be the name for the deployment; not a path 安装部署只需要三个命令123$&#123;KUBEFLOW_SRC&#125;/scripts/kfctl.sh init $&#123;KFAPP&#125; --platform none # none 也可以是minikube等$&#123;KUBEFLOW_SRC&#125;/scripts/kfctl.sh generate k8s$&#123;KUBEFLOW_SRC&#125;/scripts/kfctl.sh apply k8s 查看是否运行好了：1234kubectl get pod -n kubeflow #理论上gcr.io的镜像pull不下来# 查看ImagePullBackOff等问题kubectl describe pod scheduledworkflow -n kubeflow #提示: Failed to pull image "gcr.io/ml-pipeline/scheduledworkflow:0.1.6" 所以这里需要代理了.. 设置国外代理的方法比较多，我这里使用的是VPS的方式。 想要删除 or 重新部署？直接删除kubeflow这个namespace和之前放置配置文件的文件夹就OK了 123kubectl delete ns kubeflowkubectl delete crd tfjobs.kubeflow.org # crd 不删除也行rm -rf $&#123;KFAPP&#125; 参考资料 官方文档 katacoda]]></content>
      <categories>
        <category>kubernetes</category>
        <category>kubeflow</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>kubeflow</tag>
        <tag>分布式机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微观经济学--比较优势]]></title>
    <url>%2F2019%2F01%2F03%2F%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E6%AF%94%E8%BE%83%E4%BC%98%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[曼昆 《经济学原理》微观经济学分册学习小目标：说清楚绝对优势和比较优势，以及其与中美贸易战之间的关系 一、绝对优势假设，Frank和Lee都会两个技能“摊煎饼”，“做馒头”，显然，不同的人擅长做的事情也不一样，我们用“效率”来衡量这两个人分别做两件事情的擅长程度。但是，影响”效率”的因素太多了，比如：原材料的节约程度，产品最终的受欢迎程度….，为了简化衡量标准，我们假设他们做出的“煎饼”和“馒头”所付出的成本仅仅在制作时间上有差异。如果以单位时间作为单位成本的话，我们假设Frank一个小时平均可以摊6个煎饼或者做10个馒头，Lee一个小时平均可以做4个煎饼或者15个馒头，按照单位成本来计算（min/个）整理成下表则为： 生产成本（min/个） Frank Lee 煎饼 10 15 馒头 6 4 显然，成本越小，表明其优势越大，比如Frank摊煎饼的成本就比Lee小，而Lee做馒头的成本就比Frank小，这个优势在经济学里面就叫做绝对优势，比如，我们可以说，Frank在摊煎饼这项工作上具有绝对优势。 那就有人想说，干脆让Frank只做煎饼，Lee只做馒头好了，这样的话生产出来的煎饼和馒头的总和在单位时间内就会比他们分别生产煎饼和馒头要多。 可是，要达成这个目的还需要一个协议，Frank和Lee可以仅生产自己有绝对优势的产品，并且可以相互交换，而相互交换的规则则是“一个煎饼可以换10/6到15/4个馒头之间”，也就是定价规则。 因为，对于Frank来说一个煎饼至少得换10/6个馒头吧，不然还不如他自己做馒头呢，而对于Lee来说，一个煎饼最多可以换15/4个馒头，不然他就亏了。所以，煎饼和馒头的兑换比率应该是ratio（ 10/6=1.67 &lt; ratio &lt; 15/4=3.75） 此外，从“机会成本（opportunity cost）”的角度阐述这个问题也是一样的： 机会成本，生产A产品而不生产B产品，所舍弃的成本；这里Frank只生产煎饼，那么为了生产煎饼而放弃生产的馒头就是他的机会成本 - Frank Lee 1个煎饼的机会成本 10/6个馒头 15/4个馒头 1个馒头的机会成本 6/10个煎饼 4/15个煎饼 定价的规则就是保证在双方的机会成本之间。 二、比较优势专业化和贸易的好处不是基于绝对优势，而是基于比较优势。假设，Frank比较厉害，无论是摊煎饼还是做馒头都比Lee快： 生产成本（min/个） Frank Lee 煎饼 10 15 馒头 5 6 这时双方的机会成本为： - Frank Lee 1个煎饼的机会成本 12/6个馒头 10/4个馒头 1个馒头的机会成本 6/12个煎饼 4/10个煎饼 显然，如果一方在生产一种产品的机会成本比较低时，那他在生产另一种产品的机会成本就会比较高，因为两种产品的机会成本互为倒数。所以，Frank和Lee之间依然可以贸易，这时Frank生产他的机会成本比较小的煎饼，Lee生产他机会成本比较小的馒头。而交易的价格，也就是兑换的比率一就是在两个机会成本之间，12/6=2 &lt; 煎饼/馒头 &lt; 10/4=2.5 个。 简单来说就是，Frank即使两个工作都很擅长，但他肯定也还是有更擅长的工作（擅长中的擅长^_^），他只要做他最擅长的那一个就OK了；而贸易则可以使整体的生产效率提高，从而提高大家的物质生活水平。 不过理论上，这里可以有个小问题：如果Frank和Lee的机会成本一样，那还要不要贸易啊？？？ 三、联想 人类为什么需要贸易贸易使经济生产效率提高，物质生活水平自然也会更高。有了贸易，自然就需要保护贸易正常进行的组织（不能偷、不能抢别人的，只能换），于是政府和国家的概念和角色就出现了，注意这只是理想状态下。 为什么会有中美贸易战美国各方面都领先于中国，拥有绝对优势，但是其在生产服装、玩具、制造组装手机等方面的机会成本比中国高，而在生产高科技产品、农业产品的机会成本比中国低，所以中国向美国出口服装、玩具等，并从美国进口高科技产品、农产品等。可是，美国发现每年的中美贸易都出现逆差（对中国来说就是顺差），也就是说每年都有大量美元流入中国（中国美元的外汇储备之前一直比较高，2007年还搞了一个”中投”专门”研究”怎么花这笔钱…），为了扭转事态，美国开始加征关税（减少美国国内对中国的进口），中国当然不愿意看到这些，虽然人民币与美元并不挂钩，但是外汇储备对于中国政府来说仍然至关重要，于是中美就发生了trade war. 事实上，贸易往来总会出现不平衡的状况，一百多年前的鸦片战争也正是由于中英贸易存在类似的问题而导致的。 根据中国海关总署统计，美国对中国的贸易逆差从2001年的281亿美元增长到2017年2758亿美元。中美贸易总额已经从1992年的330亿美元发展到2017年的5837亿美元。由于统计口径差距，美国商务部统计数据，对中国逆差从2001年830亿美元增长到2017年3752亿美元，贸易总额增长到2017年6360亿美元。（维基百科） 人尽其才，才尽其用的使命比较优势告诉我们，每个人去做自己最擅长的事情，就会使经济蛋糕变大，这就让人联想到人尽其才，物尽其用这句古话了。但是这都是理论上的，现实的世界不存在真正的自由贸易，也不会存在人尽其才，物尽其用这种理想状态。 参考资料 经济学原理 — 微观经济学分册，曼昆 李永乐老师视频]]></content>
      <categories>
        <category>经济学原理</category>
      </categories>
      <tags>
        <tag>金融知识</tag>
        <tag>比较优势</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装部署Kubernetes注意事项]]></title>
    <url>%2F2018%2F12%2F26%2FCentOS%E4%B8%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Kubernetes%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[小目标：不翻墙的情况下，使用kubeadm安装部署Kubernetes集群（非高可用），1个master、2个node 一、准备工作关于机器： 准备的主机可以连接外网，对于私有云场景，需要做好前期准备（例如：配置yum源、镜像仓库源等） 满足安装 Docker 项目所需的要求，比如 64 位的 Linux 操作系统、3.10 及以上的内核版本； x86 或者 ARM 架构均可； 机器之间网络互通，这是将来容器之间网络互通的前提； 关于Linux操作系统： 建议开启root权限（我这里是已经开启了root权限，以root用户登录节点） 修改各节点的hostname：打开终端输入hostnamectl set-hostname master8088，这里的命名需要有一定的规范重启后hostname失效 建议：systemd不低于234，否则执行 df 命令的时候，据说会有一定几率卡死，使用systemctl --version查看版本信息 建议关闭swap输入swapoff -a：如果不满足，据说系统会有一定几率出现 io 飙升，造成 docker 卡死 关闭防火墙，终端输入systemctl stop firewalld &amp;&amp; systemctl disable firewalld 关闭selinux:vi /etc/selinux/config 设置SELINUX=disabled 修改hosts文件，vi /etc/hosts 123192.168.0.1 node2 # ip+hostname格式192.168.0.2 node1 # ip每个节点的ip地址，可以使用ifconfig命令查看192.168.0.3 master 添加相关设置vim /etc/sysctl.conf需要修改的内容如下所示： 1234net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1vm.max_map_count=262144 输入sysctl -p使设置生效 设置三台机器之间可以使用ssh+hostname互相登录， 节点之间无密码互相访问设置：1234ssh-keygencat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys#将每个节点的id_rsa.pub写入每个节点的authorized_keys#最后生成的authorized_keys复制到集群中的每一台计算机的.ssh目录下，覆盖掉之前的authorized_keys 二、安装部署Kubernetes 安装之前需要配置一下kubernetes这个yum源，否则下面的命令可能失效 在每个节点上安装kubeadm、kubelet、kubectl，这里选择的是CentOS系统，所以使用命令1yum install -y kubelet kubeadm kubectl 安装的kubeadm、kubectl、kubelet默认都是最新的版本（1.13版本），也可以指定版本，比如目前是stable版的1.111234567# 查看版本kubeadm versionkubectl versionkubelet --version# 下载安装指定版本yum list --showduplicates | grep 'kubeadm' #查看有哪些版本yum install -y kubeadm-1.10.5-0.x86_64 # 安装指定版本，这里选择的是1.10.5 部署master节点：这里需要注意的是，直接使用kubeadm init会发现需要的镜像获取不了，因为大陆被墙了.. 不过可以指定镜像仓库源，这里选择阿里云杭州的源（感谢^_^）：123# kubernetes-version=v1.13.1指定了安装1.13.1版本的kubernetes# pod-network-cidr是为了后续安装calico这样的网络插件kubeadm init --kubernetes-version=v1.13.1 --pod-network-cidr=192.168.0.0/16 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers 可能出现kubelet和kubeapi-server失联的情况，注意排查master部署完成后，会生成一个指令：kubeadm join ....这个是后续加入node用的kubeadm还会在部署好master后，最后提示我们第一次使用kubernetes集群需要的配置命令：mkdir... sudo cp ... sudo chown... 部署node节点：参照master部署完毕生成的kubeadm join提示，在每个node上执行以下命令kubeadm join ${master_ip}:6443 --token ${kubeadm_token} --discovery-token-ca-cert-hash ${hash_value}使用kubectl get no查看node是否已经添加，并且处于Ready状态，由于网络插件还没安装，应该不会Ready 安装CNI插件calico 12kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yamlkubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml 删除master上的Taint标签，使之也可以被调度kubectl taint nodes --all node-role.kubernetes.io/master- 至此，一个kubernetes集群已经可以使用了，接下来还可以部署Dashboard、CSI插件 三、问题记录Q1：kubeadm一次运行没有通过，但是部分static Pod已经启动？打开终端输入：kubeadm reset，即可重置集群，修改必要的参数后，再次使用kubeadm init ...命令部署K8s集群。 Q2： 需要事先下载好国内镜像源吗？不需要 由于kubeadm在部署K8s集群时，需要从k8s.gcr.io上拉取镜像，但是大陆需要翻墙，所以有些博客里提出先下载好一样的镜像再修改tag以此绕开从国外拉取镜像的问题，但实际上没有必要这样做；即便如此，还是记录一下吧… 镜像下载脚本image_download.sh1234567891011121314151617181920212223242526272829#! bin/bashsource=registry.cn-hangzhou.aliyuncs.com/google_containersimages=(kube-apiserver:v1.13.1kube-controller-manager:v1.13.1kube-scheduler:v1.13.1kube-proxy:v1.13.1pause:3.1etcd:3.2.24coredns:1.2.6)for imageName in $&#123;images[@]&#125; ; do echo $imageName echo "------------------------------------" docker pull $source/$imageName docker tag $source/$imageName k8s.gcr.io/$imageNamedone 四、参考资料 极客时间-张磊-深入剖析Kubernetes kubeadm Creating a single master cluster with kubeadm]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Linux软件安装</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图片识别app从keras+flask代码到kubernetes部署]]></title>
    <url>%2F2018%2F12%2F06%2F%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%ABapp%E4%BB%8Ekeras-flask%E4%BB%A3%E7%A0%81%E5%88%B0kubernetes%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[使用python flask 以及 keras建立一个简单的image recognition的工具,最后使用docker和kubernetes将应用容器化部署在PaaS平台上对外提供服务。 机器学习+kubernetes 使用python flask 以及 keras建立一个简单的image recognition的工具，主要参考了这里觉得有点意思就实现了一下，里面涉及到python编程、docker、k8s的使用，image recognition模型不涉及训练，使用的是开源模型，下次自己train个模型出来看看效果^_^。代码托管在github。 测试一下代码是否可用123456# 安装依赖模块，南七技校的pip源比较好用pip install -r requirements.txt -i https://mirrors.ustc.edu.cn/pypi/web/simple/ # 运行代码python app.py # 找个图片辨认一下curl -X POST -F image=@dog.jpg 'http://127.0.0.1:2400/predict 首次运行代码后，需要等待一段时间，因为要下载图片识别的模型 制作docker镜像1sudo docker build -t keras-app:latest . 出现如下提示则镜像制作成功12345Successfully built pyyaml gast absl-py termcolor MarkupSafe......Removing intermediate container 3a21aa77c06cSuccessfully built fc03d48b4096 查看一下镜像信息：123[conan@localhost deeplearning_flask]$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEkeras-app latest fc03d48b4096 43 minutes ago 1.7 GB Size 1.7G，Dockerfile中可以修改python基础镜像为pythom3.6-slim进行瘦身. 测试docker镜像123456# 运行sudo docker run --name image-recon -d -p 2400:2400 keras-app:latest# 测试curl -X POST -F image=@dog.jpg 'http://127.0.0.1:2400/predict'# 打包带走sudo docker save keras-app:latest &gt; keras-app.tar 在kubernetes上调度使用k8s集群部署应用，推荐使用yaml文件，前置条件是把刚刚的镜像push到k8s使用的镜像仓库中这里使用简单一点的deployment方式来部署imagerecon_deployment_test_for_fun.yaml123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: imagerecon-deployment labels: app: imagereconspec: replicas: 1 selector: matchLabels: app: imagerecon template: metadata: labels: app: imagerecon spec: containers: - name: imagerecon image: keras-app:latest ports: - containerPort: 2400 部署123kubectl create -f imagerecon_deployment_test_for_fun.yaml# 查看kubectl get pods --show-labels 参考资料https://medium.com/analytics-vidhya/deploy-your-first-deep-learning-model-on-kubernetes-with-python-keras-flask-and-docker-575dc07d9e76]]></content>
      <categories>
        <category>kubernetes</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>python</tag>
        <tag>机器学习</tag>
        <tag>flask</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[囚徒困境回顾]]></title>
    <url>%2F2018%2F11%2F07%2F%E5%9B%9A%E5%BE%92%E5%9B%B0%E5%A2%83%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[甲囚犯和乙囚犯分别被审讯 甲和乙都选择合作（拒不认罪或者不指认乙），那么他们会分别被判处3年；甲选择背叛（指认乙）而乙选择合作，则甲将会被无罪释放，而乙则被判处5年；甲和乙都选择背叛（相互指认）则各获刑1年审讯的结果是，| 甲\判刑时间\乙 | 合作 | 背叛 || :-: | :-: | :-: || 合作 | 3, 3 | 0, 5 || 背叛 | 5, 0 | 1, 1 | 那么针对以上的规则，甲理性思考会依据对方的选择来判断自己的处境： 乙背叛：那么甲选择合作就会被判5年，选择背叛就会被判1年； 乙合作：那么甲选择合作就会被判3年，选择背叛就会被判0年； 显然，无论乙怎么选，甲选择背叛都是最优解 那么就此判断在竞争中，选择背叛就一定是对自己有利的吗？不一定吧… 我们改一下游戏规则（规则二）： 审讯的结果是，| 甲\判刑时间\乙 | 合作 | 背叛| :—: | :—: | :—: || 合作 | 0，0 | 0, 10 || 背叛 | 10, 0 | 5, 5 | 那么甲再次理性思考同样会依据对方的选择来判断自己的处境： 乙背叛：那么甲选择合作就是被判10年，选择背叛就是被判5年； 乙合作：那么甲选择合作就是被判0年，选择背叛也是被判0年； 显然，无论乙怎么选，甲选择背叛还是是最优解 再次改一下规则（规则三）： 审讯的结果是，| 甲\判刑时间\乙 |合作| 背叛||:-:|:-:|:-:||合作 |0，0 |0, 10||背叛 |10, 0 |15, 15| 那么甲再次理性思考还是会依据对方的选择来判断自己的处境： 乙背叛：那么甲选择合作就是被判10年，选择背叛就是被判15年； 乙合作：那么甲选择合作就是被判0年，选择背叛也是被判0年； 显然，无论乙怎么选，甲选择背叛就不再是最优解了 所以说游戏规则会改变囚徒困境的结果…？ 思考假设第三条规则不那么合理，那么什么样的规则才是合理的呢？市场行为中有多方参与，比简单的两者博弈要复杂很多… 即使如此，囚徒困境的模型还是有一些指导意义的]]></content>
      <categories>
        <category>经济学原理</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>囚徒困境</tag>
        <tag>金融知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django安装与使用]]></title>
    <url>%2F2018%2F08%2F30%2FDjango%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一、Django简介Django是一个开源的web开发框架，该框架使用的是python语言。其集成了所有web开发需要的组件，开发测试速度极快，所以又被称为all-in-one类型的web开发框架。此外，Django还有Secure、Scalable、Maintainable等特性。Django于2017年发布2.0版本。 这里列出了很多Django的特点/优点；Django早在2003-2005年间被一个新闻网站的开发团队开发出来，于2005年7月开源，并命名为Django；可以推测出，Django在做文本型的网站开发上是有优势的，比如：博客、图书馆等。 二、Django安装Step1.安装python安装python会涉及版本的选择问题，这里我选择的是python3，因为python2和python3的语法略有不同，python3没有做向下兼容，而python2又将不再被官方更新维护了，所以对于我这种新手还是学学python3吧^_^。 python的官方网站提供了多种平台和版本的下载 对于python3的安装，我选择的是anaconda，anaconda是一个开源的python发行版，里面包含很多常用模块，安装这个省去了后续很多模块安装的麻烦；当然，如果想多了解python也可以使用python安装包进行安装。 anaconda安装过程123wget http://repo.continuum.io/archive/Anaconda3-5.2.0-Linux-x86_64.sh #在官网下载可以下3.6的版本（2018.08.30）sh Anaconda3-5.2.0-Linux-x86_64.sh #sh可以改为bash，安装的最后会让你选择安装微软的一款IDE产品，可以选择nosource ~/.bashrc #刷新一下环境变量 输入命令测试一下，出现Anaconda，Inc，成功12345zhuz@qwerty:~$ python3Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; windows下安装相对简单，不再赘述。 注意1.anaconda自带了Jupyter和Spyder，前者是notebook，后者是IDE，都挺好用的；2.Linux自带了python，如果自带的是python2.7，也可以考虑安装一个python3或者anaconda，但是需要解决一下版本管理问题；3.windows系统下，需要在安装好python后添加路径至环境变量，这样就可以在命令行内使用了 Step2.安装Django模块 2.1.使用pip或conda安装pip和conda安装方法是一样的12pip install django #pip是python的安装包管理工具,类似于yum和Centos的关系conda install django #conda是anaconda的安装包管理工具 如果使用pip3安装的时候提示pip3版本过低，需要先更新pip3的版本1pip3 install --upgrade pip #注意不是pip3 install --upgrade pip3 2.2.使用pycharm安装pycharm是一款IDE，由捷克公司JetBrains开发，也是python的主流IDE，其内置了很多功能，使用方便。打开pycharm，依次点击file-&gt;settings，出现如下界面，点击+号按钮，搜索框输入django，选中出现的模块包，右侧便会出现相应的模块信息，接下来点击Install Package即可，如下图所示: 注意1.windows系统下，需要在安装好Django后添加环境变量2.如果使用的是pycharm安装Django，则需要另外添加anaconda/pkgs/django-2.0.5-py36hd476221_0/Scripts到环境变量，这样比较麻烦，不如用conda来安装；3.conda只能安装python的官方包 2.3.添加环境变量Linux下已经自动添加了环境变量；windows10下添加环境变量的方法此电脑-&gt;右键属性-&gt;高级系统设置-&gt;高级-&gt;环境变量-&gt;用户变量中双击Path-&gt;新建如下图所示： 图中红色矩形框即为Anaconda在本机上的路径，这里需要添加上面的3个路径 三、Django实践这里使用Django创建一个简单的web项目，一方面是学习一下Django的框架，另一方面测试一下Django是否可用。 框架理论Django框架是MTV模式（model+template+view），和MVC的模式基本一样，可以参考阮一峰的博客学习一下下面直接看图： 图中显示了HTTP Request到HTTP Response的过程，首先通过URLS来找到View的路径，而View是由Template（比如一个html模板）+data合并得到的，data是由Model得来（所以Model是用来操作数据库的）。具体说来，Django分为几大块（摘自书签1）： URLs: While it is possible to process requests from every single URL via a single function, it is much more maintainable to write a separate view function to handle each resource. A URL mapper is used to redirect HTTP requests to the appropriate view based on the request URL. The URL mapper can also match particular patterns of strings or digits that appear in an URL, and pass these to a view function as data. View: A view is a request handler function, which receives HTTP requests and returns HTTP responses. Views access the data needed to satisfy requests via models, and delegate the formatting of the response to templates. Models: Models are Python objects that define the structure of an application’s data, and provide mechanisms to manage (add, modify, delete) and query records in the database. Templates: A template is a text file defining the structure or layout of a file (such as an HTML page), with placeholders used to represent actual content. A view can dynamically create an HTML page using an HTML template, populating it with data from a model. A template can be used to define the structure of any type of file; it doesn’t have to be HTML! 项目测试pycharm新建一个项目：依次点击file-&gt;New Project-&gt;Django-&gt;Location(命名)-&gt;Create即可命令行新建一个项目：12python3 -m django --version #先看一下版本django-admin startproject mysite #创建一个名为mysite的项目 看一下项目的目录：1234567891011zhuz@qwerty:~/Just_test$ tree mysite/mysite/├── manage.py└── mysite ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py1 directory, 5 fileszhuz@qwerty:~/Just_test$ 创建一个app1python3 manage.py startapp catalog 看一下app的目录123456789101112zhuz@qwerty:~/Just_test/mysite$ tree catalog/catalog/├── admin.py├── apps.py├── __init__.py├── migrations│ └── __init__.py├── models.py├── tests.py└── views.py1 directory, 7 files 项目 V.S. 应用应用（app）是一个专门做某件事的网络应用程序——比如博客系统，或者公共记录的数据库，或者简单的投票程序。项目（project）则是一个网站使用的配置和应用的集合。项目可以包含很多个应用；应用可以被很多个项目使用。 在/mysite/mysite/setting.py文件内“注册”一下刚刚创建的app，写入app的Config路径：123456789INSTALLED_APPS = [ 'polls.apps.PollsConfig', 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'catalog.apps.CatalogConfig', #CatalogConfig在catalog下的apps.py文件内，这个文件下app的名字已经写好了] 看到setting.py中的DATABASES默认使用的是sqlite3，这里就不用改了；需要改的是时区，还是在setting.py文件内，找到TIME_ZONE修改：1TIME_ZONE = 'Asia/Shanghai' 接下来写一下URL映射，我们将project中的url导向app自己的url，打开mysite/mysite/urls.py写入url的相对路径：123456from django.urls import path, include #默认没有添加includeurlpatterns = [ path('admin/', admin.site.urls), #原本自带的信息 path('catalog/', include('catalog.urls')), #app的相对路径 path('', RedirectView.as_view(url='/catalog/', permanent=True)),] + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) 这样一来，我们就需要在catalog这个app下新建一个urls.py文件1234567from django.urls import path from catalog import views #导入的这两个包以后会用到的urlpatterns = [] OK啦，接下来可以测试运行一下了12python3 manage.py makemigrationspython3 manage.py migrate migrate：迁移是非常强大的功能，它能让你在开发过程中持续的改变数据库结构而不需要重新删除和创建表 - 它专注于使数据库平滑升级而不会丢失数据。 运行1python3 manage.py runserver 接下来就可以访问http://127.0.0.1:8000/了，注意Chrome浏览器使用时，需要先检查一下代理，有些同学在翻墙的时候将代理端口改了一下导致不能连接… 生产环境下web搭建一般会需要LEMP(LNMP)或者LAMP环境，即由Nginx或者Apache作为前端提供http服务，mysql提供数据库服务；但Django自带了一个轻量级的webserver进行开发调试，如需调整为生产环境，可以调换自带的webserver 四、总结 1.Django是一个python的web开发框架，因此需要先搭建好python环境； 2.可以使用Anaconda安装python环境，需要修改一下系统的环境变量； 3.windows下使用pycharm添加的Django包需要单独添加环境变量，所以不建议这样安装； 4.Django自带轻量级webserver，所以无需其他组件即可搭建web app； 五、书签 Mozilla Django Tutorial Django官方中文文档 Django测试与生产环境讨论1 Django测试与生产环境讨论2 MVC模式]]></content>
      <categories>
        <category>python</category>
        <category>Web Framework</category>
      </categories>
      <tags>
        <tag>web 框架</tag>
        <tag>python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单机版SuSe搭建Confluence Wiki]]></title>
    <url>%2F2018%2F08%2F15%2F%E5%8D%95%E6%9C%BA%E7%89%88SuSe%E6%90%AD%E5%BB%BAConfluence-Wiki%2F</url>
    <content type="text"><![CDATA[单机 SuSe confluence Wiki Wiki，作为知识管理的工具，实现团队成员之间的协作和知识共享。下面主要介绍三部分内容： 一.安装过程主要参考的博客地址这篇博客每一个步骤都讲的非常清楚，按照步骤来，肯定没有问题。可能出现的问题我将写在第二部分里面。 二.安装过程的注意事项安装软件之前需要添加SuSe的源，尽量避免下载源码自己编译；另外，如果每次都让管理员那边挂载CD源，效率也会比较低。 下载配置SuSe源 点击这里即可进入软件源镜像站点选择一个镜像地址，推荐国内的USTC源：）建议同时下载leap和tumbleweed镜像，每个镜像大小大概4G多一点 1.将下载好的iso文件上传至目标主机，低于4G的文件可以使用sz命令（前提是lszrz软件已经安装好了），超过4G的文件需要使用ftp进行上传，注意ftp端口的设置 鉴于公司网络安全方面的设置，我习惯用自己的电脑连接外网，公司电脑连接内网，这样查询资料或者下载文件的同时也可以使用内网比较方便。这样就会涉及到两台电脑传输数据的问题，如果公司电脑USB有加密传输设置则建议使用网线连接进行文件传输。另外，查询资料建议使用Google。 2.挂载和配置Suse源1234mkdir -p /mnt/localsuse01 #新建一个存放文件的挂载点mount -o loop imagefilename.iso /mnt/localsuse01 #挂载到刚刚建立的文件夹zypper ar file:///mnt/localsuse01 localsuse01 #添加源zypper lr #查看添加的源 这样的设置会导致电脑重启后需要重新手动挂载，所以可以设置成开机自动挂载。 mysql安装和配置 1.使用suse安装软件12zypper se mysql #查看源里面是否有mysql的包zypper install mysql #或者mariadb 2.安装完成后，启动mysql服务systemctl start mariadb或者systemctl start mysqld3.登录mysql：mysql -uname -p先设置数据库密码按照参考的博客输入内容：1234create database confluence default character set utf8;grant all on confluence.* to 'confluenceuser'@'%' identified by 'confluencepasswd' with grant option;grant all on confluence.* to 'confluenceuser'@localhost identified by 'confluencepasswd' with grant option;flush privileges; 修改mysql的配置文件，SuSe默认安装mysql到/usr/share/mysql文件夹，12zhuz@qwerty:~$ mysql --help|grep 'my.cnf'#查看默认配置文件的位置/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf #这个是按照优先级排列的 所以在/etc/my.cnf中添加：binlog_format=mixed4.重启mysql服务：12service mariadb stopservice mariadb start 关闭防火墙 1SuSEfirewall2 stop 配置VNC 由于后续安装步骤需要用到windowX图形界面服务，而我们是通过CRT或者putty远程连接登录服务器进行操作的，这里推荐使用VNC viewer在服务器电脑上安装vnc服务，并开启即可使用，其间可能会遇到各式各样的问题，需要自行Google一下 正式安装confluence这里的安装部分全程比较简单，按照前面提到的blog内容step by step即可成功，需要注意的是安装的目录可以自行选择。再贴下blog地址https://segmentfault.com/a/1190000008753391#articleHeader10 三.运行维护1.安装后的文件位于/confluence/atlassian/confluence文件夹下，将该目录下的bin目录加入系统的环境变量echo &#39;export PATH=$PATH:/confluence/atlassian/confluence/bin&#39; &gt;&gt; /etc/profile2.由于Wiki服务没有手动加入守护进程，所以可能会由于一些原因导致其停止工作，比如电脑重启，这时需要重启Wiki服务：123sudo systemctl start mariadb #1.启动mysqlSuSEfirewall2 stop #2.关闭防火墙start_up.sh #3.最后开启wiki 四.书签CentOS7搭建Confluence Wikihttps://segmentfault.com/a/1190000008753391#articleHeader10]]></content>
      <categories>
        <category>Linux软件安装</category>
      </categories>
      <tags>
        <tag>Confluence Wiki</tag>
        <tag>Linux</tag>
        <tag>Suse</tag>
      </tags>
  </entry>
</search>
